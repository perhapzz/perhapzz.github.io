<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>计算机网络笔记 | perhapzz</title>
<meta name="keywords" content="basics">
<meta name="description" content="计算机网络 基础篇 1. TCP/IP 网络模型有哪几层？ 应用层 我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。
应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。
传输层 给应用层提供网络支持的。
有两个传输协议，分别是 TCP 和 UDP。
TCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。
UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）
网络层 传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。
网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。
  寻址   我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。
因此，需要将 IP 地址分成两种意义：">
<meta name="author" content="">
<link rel="canonical" href="https://perhapzz.github.io/posts/computernetwork/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.2c5d624023ca4f39285dc8ad242509c565a0c0e820fc61724b2a58620dfdafbe.css" integrity="sha256-LF1iQCPKTzkoXcitJCUJxWWgwOgg/GFySypYYg39r74=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://perhapzz.github.io/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://perhapzz.github.io/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://perhapzz.github.io/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://perhapzz.github.io/favicon/apple-touch-icon.png">
<link rel="mask-icon" href="https://perhapzz.github.io/favicon/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="计算机网络笔记" />
<meta property="og:description" content="计算机网络 基础篇 1. TCP/IP 网络模型有哪几层？ 应用层 我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。
应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。
传输层 给应用层提供网络支持的。
有两个传输协议，分别是 TCP 和 UDP。
TCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。
UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）
网络层 传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。
网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。
  寻址   我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。
因此，需要将 IP 地址分成两种意义：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://perhapzz.github.io/posts/computernetwork/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-24T22:31:05+08:00" />
<meta property="article:modified_time" content="2022-12-24T22:31:05+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="计算机网络笔记"/>
<meta name="twitter:description" content="计算机网络 基础篇 1. TCP/IP 网络模型有哪几层？ 应用层 我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。
应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。
传输层 给应用层提供网络支持的。
有两个传输协议，分别是 TCP 和 UDP。
TCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。
UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）
网络层 传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。
网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。
  寻址   我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。
因此，需要将 IP 地址分成两种意义："/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://perhapzz.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "计算机网络笔记",
      "item": "https://perhapzz.github.io/posts/computernetwork/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "计算机网络笔记",
  "name": "计算机网络笔记",
  "description": "计算机网络 基础篇 1. TCP/IP 网络模型有哪几层？ 应用层 我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。\n应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。\n传输层 给应用层提供网络支持的。\n有两个传输协议，分别是 TCP 和 UDP。\nTCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。\nUDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）\n网络层 传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。\n网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。\n  寻址   我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。\n因此，需要将 IP 地址分成两种意义：",
  "keywords": [
    "basics"
  ],
  "articleBody": "计算机网络 基础篇 1. TCP/IP 网络模型有哪几层？ 应用层 我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。\n应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。\n传输层 给应用层提供网络支持的。\n有两个传输协议，分别是 TCP 和 UDP。\nTCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。\nUDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）\n网络层 传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。\n网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。\n  寻址   我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。\n因此，需要将 IP 地址分成两种意义：\n 一个是网络号，负责标识该 IP 地址是属于哪个「子网」的； 一个是主机号，负责标识同一「子网」下的不同主机；  怎么分的呢？这需要配合子网掩码才能算出 IP 地址 的网络号和主机号。\n举个例子，比如 10.100.122.0/24，后面的/24表示就是 255.255.255.0 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，大家数数一共多少个1？不用数了，是 24 个1，为了简化子网掩码的表示，用/24代替255.255.255.0。\n知道了子网掩码，该怎么计算出网络地址和主机地址呢？\n将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号；将 255.255.255.0 取反后与IP地址进行进行按位与运算，就可以得到主机号。\n（掩码23、24、25如何区分呢？）\n 路由   除了寻址能力， IP 协议还有另一个重要的能力就是路由。实际场景中，两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步走哪条路径。（怎么个路由算法？）\n路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。\n所以，IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘。\n网络接口层 生成了 IP 头部之后，接下来要交给网络接口层（Link Layer）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。\n以太网 IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。\n什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。\n以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。\nMAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。\n所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。\n总结 综上所述，TCP/IP 网络通常是由上到下分成 4 层，分别是应用层，传输层，网络层和网络接口层。\n每一层的封装格式：\n网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\n2. 键入网址到网页显示，期间发生了什么？ HTTP —— 孤独小弟 HTTP 请求信息 对 URL 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来根据这些信息来生成 HTTP 请求消息。\nDNS —— 真实地址查询 通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。\n但在发送之前，还有一项工作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。\n比如我们打电话的时候，必须要知道对方的电话号码，但由于电话号码难以记忆，所以通常我们会将对方电话号 + 姓名保存在通讯录里。所以，有一种服务器就专门保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。\n域名的层级关系 DNS 中的域名都是用句点来分隔的，比如 www.server.com，这里的句点代表了不同层次之间的界限。在域名中，越靠右的位置表示其层级越高。实际上域名最后还有一个点，比如 www.server.com.，这个最后的一个点代表根域名。\n也就是，. 根域是在最顶层，它的下一层就是 .com 顶级域，再下面是 server.com。\n所以域名的层级关系类似一个树状结构：\n 根 DNS 服务器（.） 顶级域 DNS 服务器（.com） 权威 DNS 服务器（server.com）  根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。（根域DNS服务器的信息是不是最少？因为它的信息是其他服务器的子集？）\n因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。\n域名解析的工作流程  客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。” 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？” 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。  DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似，只指路不带路。\n并不是每次解析域名都要经过那么多的步骤，浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。\n协议栈 —— 指南好帮手 通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。\n协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。\n应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。\n协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。\n此外 IP 中还包括 ICMP 协议和 ARP 协议。\n ICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。 ARP 用于根据 IP 地址查询相应的以太网 MAC 地址。  IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。\nTCP —— 可靠传输 HTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。\nTCP 包头格式 我们先看看 TCP 报文头部的格式：\n首先，源端口号和目标端口号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。\n接下来有包的序号，这个是为了解决包乱序的问题。\n还有应该有的是确认号，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决丢包的问题。\n接下来还有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。\n还有一个重要的就是窗口大小。TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。\n除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。\n三次握手 在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。\n这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。\n 一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。 然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。 服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。 客户端收到服务端发送的 SYN 和 ACK 之后，发送对 SYN 确认的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。 服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。  所以三次握手目的是保证双方都有发送和接收的能力。\nTCP 分割数据 如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。\n MTU：一个网络包的最大长度，以太网中一般为 1500 字节。 MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。  数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。 TCP 报文生成 TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 80， HTTPS 默认端口号是 443）。\n在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。\n至此，网络包的报文如下图。\nIP —— 远程定位 TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。\nIP 包头格式 在 IP 协议里面需要有源地址 IP 和 目标地址 IP：\n 源地址IP，即是客户端输出的 IP 地址； 目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。  因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP。\nIP 报文生成 至此，网络包的报文如下图。\nMAC —— 两点传输 生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。\nMAC 包头格式 MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。\n在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。\n一般在 TCP/IP 通信里，MAC 包头的协议类型只使用：\n 0800 ： IP 协议 0806 ： ARP 协议  MAC 发送方和接收方如何确认? 发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。\n接收方的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。\n所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。（发给路由器的IP地址？）\n既然知道要发给谁，按如何获取对方的 MAC 地址呢？ 不知道对方 MAC 地址？不知道就喊呗。\n此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。\nARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。\n然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。\n如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。（如果不在同一个子网呢？）\n在后续操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。\n也就是说，在发包时：\n 先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。 而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。  MAC 报文生成 至此，网络包的报文如下图。\n网卡 —— 出口 网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。\n负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。\n网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。\n 起始帧分界符是一个用来表示包起始位置的标记 末尾的 FCS（帧校验序列）用来检查包传输过程是否有损坏  最后网卡会将包转为电信号，通过网线发送出去。\n交换机 —— 送别者 交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。\n交换机的包接收操作 首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。\n然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。\n计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。\n将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。\n交换机的 MAC 地址表主要包含两个信息：\n 一个是设备的 MAC 地址， 另一个是该设备连接在交换机的哪个端口上。  所以，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。\n当 MAC 地址表找不到指定的 MAC 地址会怎么样？ 地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。\n这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。\n这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。\n有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”\n其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。\n局域网中每秒可以传输上千个包，多出一两个包并无大碍。\n此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。\n以下两个属于广播地址：\n MAC 地址中的 FF:FF:FF:FF:FF:FF IP 地址中的 255.255.255.255  路由器 —— 出境大门 路由器与交换机的区别 网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。\n这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。\n不过在具体的操作过程上，路由器和交换机是有区别的。\n 因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址； 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。  路由器基本原理 路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。\n当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。\n路由器的包接收操作 首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。\n如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。\n总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。\n查询路由表确定输出端口 完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。\nMAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。\n转发操作分为几个阶段，首先是查询路由表判断转发目标。\n判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。\n路由匹配和前面讲的一样，每个条目的子网掩码和目标 IP 做 \u0026 与运算后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。\n实在找不到匹配路由时，就会选择默认路由，路由表中子网掩码为 0.0.0.0 的记录表示「默认路由」。\n路由器的发送操作 接下来就会进入包的发送操作。\n首先，我们需要根据路由表的网关列判断对方的地址。\n 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。  知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。\n路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。\n接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进制）表示 IP 协议。\n网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。\n发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。\n接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。\n 不知你发现了没有，在网络包传输的过程中，源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，因为需要 MAC 地址在以太网内进行两个设备之间的包传输。  服务器 与 客户端 —— 相互扒皮 数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。\n接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。\n于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。\n于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。\n服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。\nHTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。\n穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。\n最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。\n客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！\n于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！\n最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。HTTP篇\n3. Linux 系统是如何收发网络包的？ 网络模型 国际标准化组织制定了开放式系统互联通信参考模型（Open System Interconnection Reference Model），也就是 OSI 网络模型，该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。\n每一层负责的职能都不同，如下：\n 应用层，负责给应用程序提供统一的接口； 表示层，负责把数据转换成兼容另一个系统能识别的格式； 会话层，负责建立、管理和终止表示层实体之间的通信会话； 传输层，负责端到端的数据传输； 网络层，负责数据的路由、转发、分片； 数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址； 物理层，负责在物理网络中传输数据帧；  由于 OSI 模型实在太复杂，提出的也只是概念理论上的分层，并没有提供具体的实现方案。\n我们比较常见，也比较实用的是四层模型，即 TCP/IP 网络模型，Linux 系统正是按照这套网络模型来实现网络协议栈的。\nTCP/IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下：\n 应用层：负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等; 传输层：负责端到端的通信，比如 TCP、UDP 等； 网络层：负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等； 网络接口层：负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等；  TCP/IP 网络模型相比 OSI 网络模型简化了不少，也更加易记，它们之间的关系如下图：\nLinux 网络协议栈 从下面这张图可以看到应用层数据在每一层的封装格式。\n其中：\n 传输层，给应用数据前面增加了 TCP 头； 网络层，给 TCP 数据包前面增加了 IP 头； 网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；  知道了 TCP/IP 网络模型，以及网络包的封装原理后，那么 Linux 网络协议栈就类似于 TCP/IP 的四层结构：\n从上图的的网络协议栈，你可以看到：\n 应用程序需要通过系统调用，来跟 Socket 层进行数据交互； Socket 层的下面就是传输层、网络层和网络接口层； 最下面的一层，则是网卡驱动程序和硬件网卡设备；  Linux 接收网络包的流程 网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。\nLinux 内核在 2.6 版本中引入了 NAPI 机制，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是不采用中断的方式读取数据，而是首先采用中断唤醒数据接收的服务程序，然后 poll 的方法来轮询数据。\n因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。\n硬件中断处理函数会做如下的事情：\n 需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。 接着，发起「软中断」，然后恢复刚才屏蔽的中断。  至此，硬件中断处理函数的工作就已经完成。\n硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。\n软中断的处理 内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。\nksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。\n网络协议栈 首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。\n到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。\n传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。\n最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。\n至此，一个网络包的接收过程就已经结束了，你也可以从下图左边部分看到网络包接收的流程，右边部分刚好反过来，它是网络包发送的流程。\nLinux 发送网络包的流程 如上图的右半部分，发送网络包的流程正好和接收流程相反。\n首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。\n接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP/IP 协议栈从上到下逐层处理。\n如果使用的是 TCP 传输协议发送数据，那么先拷贝一个新的 sk_buff 副本 ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。\n接着，对 sk_buff 填充 TCP 头。这里提一下，sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。\n你可能会好奇，为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。\n于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 data 的指针，比如：\n 当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb-data 的值，来逐步剥离协议首部。 当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb-data 的值来增加协议首部。  你可以从下面这张图看到，当发送报文时，data 指针的移动过程。\n至此，传输层的工作也就都完成了。\n然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、netfilter 过滤、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。\n网络接口层会通过 ARP 协议获得下一跳的 MAC 地址，然后对 sk_buff 填充帧头和帧尾，接着将 sk_buff 放到网卡的发送队列中。\n这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。\n当数据发送完成以后，其实工作并没有结束，因为内存还没有清理。当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。\n最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。\n发送网络数据的时候，涉及几次内存拷贝操作？ 第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。\n第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。\n第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。\nHTTP 篇 HTTP 是什么？ HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。HTTP的名字「超文本协议传输」，它可以拆成三个部分：\n 超文本 传输 协议  协议 HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。\n传输 HTTP 协议是一个双向协议。HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。\n超文本 「超文本」就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。\n总结 HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。\nGET 和 POST 根据 RFC 规范，GET 的语义是从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。\n根据 RFC 规范，POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。\nGET 和 POST 方法都是安全和幂等的吗？ 先说明下安全和幂等的概念：\n 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。  如果从 RFC 规范定义的语义来看：\n GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。  小结：\nGET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。\nPOST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。\nHTTP 缓存技术 避免发送 HTTP 请求的方法就是通过缓存技术，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。\nHTTP 缓存有两种实现方式，分别是强制缓存和协商缓存。\n强制缓存 强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。\n如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。\n强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：\n Cache-Control， 是一个相对时间； Expires，是一个绝对时间；  如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control的优先级高于 Expires 。\nCache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：\n 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。  协商缓存 当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。\n上图就是一个协商缓存的过程，所以协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。\n协商缓存可以基于两种头部来实现。\n第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是：\n 响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。  第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是：\n 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。  第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。\n如果在第一次请求资源的时候，服务端返回的 HTTP 响应头部同时有 Etag 和 Last-Modified 字段，那么客户端再下一次请求的时候，如果带上了 ETag 和 Last-Modified 字段信息给服务端，这时 Etag 的优先级更高，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。\n**为什么 ETag 的优先级更高？**这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：\n 在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求； 可能有些文件是在秒级以内修改的，If-Modified-Since 能检查到的粒度是秒级的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次； 有些服务器不能精确获取文件的最后修改时间。  注意，协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。\n下图是强制缓存和协商缓存的工作流程（客户端）：\n当使用 ETag 字段实现的协商缓存的过程：\n  当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；\n  当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：\n 如果没有过期，则直接使用本地缓存； 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；    服务器再次收到请求后，\n会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：\n 如果值相等，则返回 304 Not Modified，不会返回资源； 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；    如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。\n  HTTP 特性 到目前为止，HTTP 常见到版本有 HTTP/1.1，HTTP/2.0，HTTP/3.0，不同版本的 HTTP 特性是不一样的。\n这里先用 HTTP/1.1 版本给大家介绍，其他版本的后续也会介绍。\nHTTP/1.1 的优点有哪些？ HTTP 最凸出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。\n1. 简单\nHTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。\n2. 灵活和易于扩展\nHTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。\n同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化，比如：\n HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层； HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。  3. 应用广泛和跨平台\n互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有跨平台的优越性。\nHTTP/1.1 的缺点有哪些？ HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。\n1. 无状态双刃剑\n无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。\n无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。\n例如登录-添加购物车-下单-结算-支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。\n这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！\n对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。\nCookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。\n相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了。\n2. 明文传输双刃剑\n明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。\n但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那你号没了。\n3. 不安全\nHTTP 比较严重的缺点就是不安全：\n 通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏，那你号没了。 不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多，那你钱没了。 无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告，视觉污染，眼没了。  HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。\nHTTP 与 HTTPS HTTP 与 HTTPS 有哪些区别？  HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。  HTTPS 解决了 HTTP 的哪些问题？ HTTP 由于是明文传输，所以安全上存在以下三个风险：\n 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。  HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险：\n 信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。 身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。  可见，只要自身不做「恶」，SSL/TLS 协议是能保证通信是安全的。\nHTTPS 是如何解决上面的三个风险的？  混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。  1. 混合加密\n通过混合加密的方式可以保证信息的机密性，解决了窃听的风险。\nHTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式：\n 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。  采用「混合加密」的方式的原因：\n 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。  2. 摘要算法 + 数字签名\n为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。\n对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。\n那么，在计算机里会用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容。\n通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。\n计算机里会用非对称加密算法来判断，共有两个密钥：\n 一个是公钥，这个是可以公开给所有人的； 一个是私钥，这个必须由本人管理，不可泄露。  这两个密钥可以双向加解密的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。\n流程的不同，意味着目的也不相同：\n 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。  一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。\n所以非对称加密的用途主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份，我们常说的数字签名算法，就是用的是这种方式，不过私钥加密内容不是内容本身，而是对内容的哈希值加密。\n私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。\n3. 数字证书\n前面我们知道：\n 可以通过哈希算法来保证消息的完整性； 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；  但是这还远远不够，还缺少身份验证的环节，万一公钥是被伪造的呢？\n我们需要通过一个权威机构来证明公钥是合法的，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。\n通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。\nHTTPS 是如何建立连接的？其间交互了什么？ SSL/TLS 协议基本流程：\n 客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。  前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。\nTLS 的「握手阶段」涉及四次通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：RSA 算法和 ECDHE 算法。\n基于 RSA 算法的 TLS 握手过程比较容易理解，所以这里先用这个给大家展示 TLS 握手过程，如下图：\nTLS 协议建立的详细流程：\n1. ClientHello\n首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。\n在这一步，客户端主要向服务器发送以下信息：\n（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。\n（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。\n（3）客户端支持的密码套件列表，如 RSA 加密算法。\n2. SeverHello\n服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello。服务器回应的内容有如下内容：\n（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。\n（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。\n（3）确认的密码套件列表，如 RSA 加密算法。\n（4）服务器的数字证书。\n3.客户端回应\n客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。\n如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：\n（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。\n（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。\n上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。\n服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。\n4. 服务器的最后回应\n服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。\n然后，向客户端发送最后的信息：\n（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。\n至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。\n客户端校验数字证书的流程是怎样的？ 如下图图所示，为数字证书签发和验证流程：\nCA 签发证书的过程，如上图左边部分：\n 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书；  客户端校验服务端的数字证书的过程，如上图右边部分：\n 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。  但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：\n对于这种三级层级关系的证书的验证过程如下：\n 客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。 “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。  在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。\n总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。\n最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？\n这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。\nHTTPS 的应用数据是如何保证完整性的？ TLS 在实现上分为握手协议和记录协议两层：\n TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）； TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；  TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：\n具体过程如下：\n 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。 接下来，经过压缩的片段会被加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。  记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。\n如果你想详细了解记录协议是如何分片、压缩、计算 MAC 值、分组加密，可以看这篇：理解SSL/TLS系列 (四) 记录协议\nHTTP/1.1、HTTP/2、HTTP/3 演变 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？ HTTP/1.1 相比 HTTP/1.0 性能上的改进：\n 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。  但 HTTP/1.1 还是有性能瓶颈：\n 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应。  HTTP/2 做了什么优化？ HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。\n那 HTTP/2 相比 HTTP/1.1 性能上的改进：\n 头部压缩 二进制格式 并发传输 服务器主动推送资源  1. 头部压缩\nHTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。\n这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n2. 二进制格式\nHTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。\n这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。\n3. 并发传输\n我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了队头阻塞的问题。\n而 HTTP/2 就很牛逼了，引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。\n从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。\n针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。\n4、服务器推送\nHTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。\n客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。\nHTTP/2 有什么缺陷？ HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。\nHTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。\n一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。\nHTTP/3 做了哪些优化？ 前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：\n HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。 HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。  HTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！\nUDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。\nQUIC 有以下 3 个特点。\n 无队头阻塞 更快的连接建立 连接迁移  1、无队头阻塞\nQUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。\nQUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。\n所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。\n2、更快的连接建立\n对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。\nHTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。\n但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：\n甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。\n如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）\n3、连接迁移\n基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。\n那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。\n而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。\n所以， QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。\nQUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。\nHTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。\nTCP篇 什么是 TCP ？ TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。\n 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。  TCP 头格式有哪些？ 序列号：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来解决网络包乱序问题。\n确认应答号：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决丢包的问题。\n控制位：\n ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。 RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接。 SYN：该位为 1 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。 FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。  UDP 和 TCP 有什么区别呢？分别的应用场景是？ UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。\nUDP 协议真的非常简单，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：\n 目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。 包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。 校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。  TCP 和 UDP 区别：\n1. 连接\n TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。  2. 服务对象\n TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信  3. 可靠性\n TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。 UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：如何基于 UDP 协议实现可靠传输？  4. 拥塞控制、流量控制\n TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。  5. 首部开销\n TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。  6. 传输方式\n TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。  7. 分片不同\n TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。  TCP 和 UDP 应用场景：\n由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：\n FTP 文件传输； HTTP / HTTPS；  由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：\n 包总量较少的通信，如 DNS 、SNMP 等； 视频、音频等多媒体通信； 广播通信；  TCP 连接建立 TCP 三次握手过程是怎样的？ TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图：\n 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态   客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。   服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。   客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。  从上面的过程可以发现第三次握手是可以携带数据的，前两次握手是不可以携带数据的，这也是面试常问的题。\n一旦完成三次握手，双方都处于 ESTABLISHED 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。\n为什么是三次握手？不是两次、四次？ 在前面我们知道了什么是 TCP 连接：\n 用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。  所以，重要的是为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。\n接下来，以三个方面分析三次握手的原因：\n 三次握手才可以阻止重复历史连接的初始化（主要原因） 三次握手才可以同步双方的初始序列号 三次握手才可以避免资源浪费  原因一：避免历史连接\n我们来看看 RFC 793 指出的 TCP 连接使用三次握手的首要原因：\nThe principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.\n简单来说，三次握手的首要原因是为了防止旧的重复连接初始化造成混乱。\n我们考虑一个场景，客户端先发送了 SYN（seq = 90） 报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100） 报文（注意！不是重传 SYN，重传的 SYN 的序列号是一样的）。\n看看三次握手是如何阻止历史连接的：\n客户端连续发送多次 SYN （都是同一个四元组）建立连接的报文，在网络拥堵情况下：\n 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个 SYN + ACK 报文给客户端，此报文中的确认号是 91（90+1）。 客户端收到后，发现自己期望收到的确认号应该是 100+1，而不是 90 + 1，于是就会回 RST 报文。 服务端收到 RST 报文后，就会释放连接。 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。  上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的最主要原因就是防止「历史连接」初始化了连接。\n如果是两次握手连接，就无法阻止历史连接，主要是因为在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费。（就是说首先发起连接是由客户端发起，最后确认连接还是要客户端确认）\n（但是这样的情况还是比较少见的吧？为什么不直接两次握手，如果遇到这种情况再由客户端把服务端把连接中断？）\n原因二：同步双方初始序列号\nTCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：\n 接收方可以去除重复的数据； 接收方可以根据数据包的序列号按序接收； 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；  可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。\n四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。\n而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。\n原因三：避免资源浪费\n如果只有「两次握手」，当客户端发生的 SYN 报文在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接，这会造成什么情况呢？\n如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**即两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 SYN 报文，而造成重复分配资源。\n（哦原来是服务端比较牛，资源比较珍贵，不会轻易建立连接，需要舔狗客户端多舔两口才行）\n小结\nTCP 建立连接时，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。\n不使用「两次握手」和「四次握手」的原因：\n 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号； 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。  为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？ 主要原因有两个方面：\n 为了防止历史报文被下一个相同四元组的连接接收（主要方面）； 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；  既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？  MTU：一个网络包的最大长度，以太网中一般为 1500 字节； MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；  如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？\n当 IP 层有一个超过 MTU 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。\n这看起来井然有序，但这存在隐患的，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。\n因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。\n当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。\n因此，可以得知由 IP 层进行分片传输，是非常没有效率的。\n所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。\n经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。\nTCP 连接断开 TCP 四次挥手 TCP 断开连接是通过四次挥手方式，双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：\n 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。  你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。\n这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。\n（相当于服务端要发还 SYN+ACK ，但由于数据可能还没发送或者处理完，所以需要分开发送，因此是四次）\nSocket 编程  服务端和客户端初始化 socket，得到文件描述符； 服务端调用 bind，将 socket 绑定在指定的 IP 地址和端口; 服务端调用 listen，进行监听； 服务端调用 accept，等待客户端连接； 客户端调用 connect，向服务端端的地址和端口发起连接请求； 服务端 accept 返回用于传输的 socket 的文件描述符； 客户端调用 write 写入数据；服务端调用 read 读取数据； 客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。  这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。\n所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。\n成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。\n客户端连接服务端时，发送了什么？  客户端的协议栈向服务端端发送了 SYN 包，并告诉服务端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态； 服务端端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务端也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务端端进入 SYN_RCVD 状态； 客户端协议栈收到 ACK 之后，使得应用程序从 connect 调用返回，表示客户端到服务端端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务端端的 SYN 包进行应答，应答数据为 server_isn+1； ACK 应答包到达服务端端后，服务端端的 TCP 连接进入 ESTABLISHED 状态，同时服务端端协议栈使得 accept 阻塞调用返回，这个时候服务端端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。  从上面的描述过程，我们可以得知客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。\n客户端调用 close 了，连接是断开的流程是什么？ 我们看看客户端主动调用了 close，会发生什么？\n 客户端调用 close，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态； 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，应用程序可以通过 read 调用来感知这个 FIN 包。这个 EOF 会被放在已排队等候的其他已接收的数据之后，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态； 接着，当处理完数据后，自然就会读到 EOF，于是也调用 close 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态； 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态； 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态； 客户端经过 2MSL 时间之后，也进入 CLOSE 状态；  同时开，同时关是什么东东？ TCP重传、滑动窗口、流量控制、拥塞控制 TCP 是一个可靠传输的协议，是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。\n重传机制 超时重传 TCP 会在以下两种情况发生超时重传：\n 数据包丢失 确认应答丢失  RTT 指的是数据发送时刻到接收到确认的时刻的差值，也就是包的往返时间。\n超时重传时间是以 RTO （Retransmission Timeout 超时重传时间）表示。\n假设在重传的情况下，超时时间 RTO 「较长或较短」时，会发生什么事情呢？\n有两种超时时间不同的情况：\n 当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差； 当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。  结论：超时重传时间 RTO 的值应该略大于报文往返 RTT 的值\n但实际上「报文往返 RTT 的值」是经常变化的，所以「超时重传时间 RTO 的值」应该是一个动态变化的值。\n估计往返时间，通常需要采样以下两个：\n 需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。  每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。\n超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？于是就可以用「快速重传」机制来解决超时重发的时间等待。\n快速重传 TCP 还有另外一种快速重传（Fast Retransmit）机制，它不以时间为驱动，而是以数据驱动重传。\n在上图，发送方发出了 1，2，3，4，5 份数据：\n 第一份 Seq1 先送到了，于是就 Ack 回 2； 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2； 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到； 发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。 最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。  所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。\n快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传一个，还是重传所有的问题。\nSACK方法 还有一种实现重传机制的方式叫：SACK（ Selective Acknowledgment）， 选择性确认。\n这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将已收到的数据的信息发送给「发送方」，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。\nDuplicate SACK Duplicate SACK 又称 D-SACK，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。\n1. 网络延时\n 数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。 而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」； 所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。  2. ACK丢包\n 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499） 于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK。 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。  可见，D-SACK 有这么几个好处：\n 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了; 可以知道是不是「发送方」的数据包被网络延迟了; 可以知道网络中是不是把「发送方」的数据包给复制了;  滑动窗口 我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。\n所以，这样的传输方式有一个缺点：数据包的往返时间越长，通信的效率就越低。\n为解决这个问题，TCP 引入了窗口这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。\n那么有了窗口，就可以指定窗口大小，窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。\n窗口大小由哪一方决定？\nTCP 头里有一个字段叫 Window，也就是窗口大小。\n这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。\n所以，通常窗口的大小是由接收方的窗口大小来决定的。\n发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。\n接收窗口和发送窗口的大小是相等的吗？\n并不是完全相等，接收窗口的大小是约等于发送窗口的大小的。\n因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。\n流量控制 **TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**流量控制是避免「发送方」的数据填满「接收方」的缓存。\n下面举个栗子，为了简单起见，假设以下场景：\n 客户端是接收方，服务端是发送方 假设接收窗口和发送窗口相同，都为 200 假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响  根据上图的流量控制，说明下每个过程：\n 客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。 服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 Usable 减少为 120 字节，同时 SND.NXT 指针也向右偏移 80 字节后，指向 321，这意味着下次发送数据的时候，序列号是 321。 客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，RCV.NXT 也就指向 321，这意味着客户端期望的下一个报文的序列号是 321，接着发送确认报文给服务端。 服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。 客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，RCV.NXT 也就指向 441，接着发送确认报文给服务端。 服务端收到对 80 字节数据的确认报文后，SND.UNA 指针往右偏移后指向 321，于是可用窗口 Usable 增大到 80。 服务端收到对 120 字节数据的确认报文后，SND.UNA 指针往右偏移后指向 441，于是可用窗口 Usable 增大到 200。 服务端可以继续发送了，于是发送了 160 字节的数据后，SND.NXT 指向 601，于是可用窗口 Usable 减少到 40。 客户端收到 160 字节后，接收窗口往右移动了 160 字节，RCV.NXT 也就是指向了 601，接着发送确认报文给服务端。 服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 SND.UNA 指针偏移了 160 后指向 601，可用窗口 Usable 也就增大至了 200。  拥塞控制 流量控制是避免「发送方」的数据填满「接收方」的缓存，但在网络出现拥堵时，流量控制感觉不到，如果此时继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大….所以，TCP 不能忽略网络上发生的事，当网络发送拥塞时，于是就有了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络\n为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。\n拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。\n我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。\n拥塞窗口 cwnd 变化的规则：\n 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少；  其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。\n拥塞控制主要是四个算法：\n 慢启动 拥塞避免 拥塞发生 快速恢复  IP篇 源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化。\n  主机号全为 1 指定某个网络下的所有主机，用于广播。广播地址用于在同一个链路中相互连接的主机之间发送数据包。\n  在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。\n  在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发。） 。\n  主机号全为 0 指定某个网络（子网掩码时用）。\n  ",
  "wordCount" : "3251",
  "inLanguage": "en",
  "datePublished": "2022-12-24T22:31:05+08:00",
  "dateModified": "2022-12-24T22:31:05+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://perhapzz.github.io/posts/computernetwork/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "perhapzz",
    "logo": {
      "@type": "ImageObject",
      "url": "https://perhapzz.github.io/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://perhapzz.github.io" accesskey="h" title="perhapzz (Alt + H)">perhapzz</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://perhapzz.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://perhapzz.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://perhapzz.github.io">Home</a>&nbsp;»&nbsp;<a href="https://perhapzz.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      计算机网络笔记
    </h1>
    <div class="post-meta"><span title='2022-12-24 22:31:05 +0800 CST'>December 24, 2022</span>

</div>
  </header> 
  <div class="post-content"><h1 id="计算机网络">计算机网络<a hidden class="anchor" aria-hidden="true" href="#计算机网络">#</a></h1>
<h2 id="基础篇">基础篇<a hidden class="anchor" aria-hidden="true" href="#基础篇">#</a></h2>
<h3 id="1-tcpip-网络模型有哪几层">1. TCP/IP 网络模型有哪几层？<a hidden class="anchor" aria-hidden="true" href="#1-tcpip-网络模型有哪几层">#</a></h3>
<h4 id="应用层">应用层<a hidden class="anchor" aria-hidden="true" href="#应用层">#</a></h4>
<p>我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。</p>
<p>应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。</p>
<h4 id="传输层">传输层<a hidden class="anchor" aria-hidden="true" href="#传输层">#</a></h4>
<p>给应用层提供网络支持的。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251047047.png" alt="img"  />
</p>
<p>有两个传输协议，分别是 TCP 和 UDP。</p>
<p>TCP 的全称叫传输控制协议（<em>Transmission Control Protocol</em>），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如<strong>流量控制、超时重传、拥塞控制</strong>等，这些都是为了保证数据包能可靠地传输给对方。</p>
<p>UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）</p>
<h4 id="网络层">网络层<a hidden class="anchor" aria-hidden="true" href="#网络层">#</a></h4>
<p>传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是<strong>网络层</strong>（<em>Internet Layer</em>）。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251046107.png" alt="img"  />
</p>
<p>网络层最常使用的是 IP 协议（<em>Internet Protocol</em>），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会<strong>再次进行分片</strong>，得到一个即将发送到网络的 IP 报文。</p>
<ol>
<li>
<h5 id="寻址">寻址<a hidden class="anchor" aria-hidden="true" href="#寻址">#</a></h5>
</li>
</ol>
<p>我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。</p>
<p>因此，需要将 IP 地址分成两种意义：</p>
<ul>
<li>一个是<strong>网络号</strong>，负责标识该 IP 地址是属于哪个「子网」的；</li>
<li>一个是<strong>主机号</strong>，负责标识同一「子网」下的不同主机；</li>
</ul>
<p>怎么分的呢？这需要配合<strong>子网掩码</strong>才能算出 IP 地址 的网络号和主机号。</p>
<p>举个例子，比如 10.100.122.0/24，后面的<code>/24</code>表示就是 <code>255.255.255.0</code> 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，大家数数一共多少个1？不用数了，是 24 个1，为了简化子网掩码的表示，用/24代替255.255.255.0。</p>
<p>知道了子网掩码，该怎么计算出网络地址和主机地址呢？</p>
<p>将 10.100.122.2 和 255.255.255.0 进行<strong>按位与运算</strong>，就可以得到网络号；将 255.255.255.0 取反后与IP地址进行进行<strong>按位与运算</strong>，就可以得到主机号。</p>
<p>（掩码23、24、25如何区分呢？）</p>
<ol start="2">
<li>
<h5 id="路由">路由<a hidden class="anchor" aria-hidden="true" href="#路由">#</a></h5>
</li>
</ol>
<p>除了寻址能力， IP 协议还有另一个重要的能力就是<strong>路由</strong>。实际场景中，两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步走哪条路径。（怎么个路由算法？）</p>
<p>路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251138100.jpg" alt="IP地址的网络号"  />
</p>
<p>所以，<strong>IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘</strong>。</p>
<h4 id="网络接口层">网络接口层<a hidden class="anchor" aria-hidden="true" href="#网络接口层">#</a></h4>
<p>生成了 IP 头部之后，接下来要交给<strong>网络接口层</strong>（<em>Link Layer</em>）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251142988.png" alt="img"  />
</p>
<h4 id="以太网">以太网<a hidden class="anchor" aria-hidden="true" href="#以太网">#</a></h4>
<p>IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251553563.png" alt="img"  />
</p>
<p>什么是以太网呢？电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。以太网就是一种在「局域网」内，把附近的设备连接起来，使它们之间可以进行通讯的技术。</p>
<p>以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。</p>
<p>MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。</p>
<p>所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。</p>
<h4 id="总结">总结<a hidden class="anchor" aria-hidden="true" href="#总结">#</a></h4>
<p>综上所述，TCP/IP 网络通常是由上到下分成 4 层，分别是<strong>应用层，传输层，网络层和网络接口层</strong>。</p>
<p>每一层的封装格式：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251555909.png" alt="img"  />
</p>
<p>网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。</p>
<h3 id="2-键入网址到网页显示期间发生了什么">2. 键入网址到网页显示，期间发生了什么？<a hidden class="anchor" aria-hidden="true" href="#2-键入网址到网页显示期间发生了什么">#</a></h3>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251850274.jpg" alt="简单的网络模型"  />
</p>
<h4 id="http--孤独小弟">HTTP —— 孤独小弟<a hidden class="anchor" aria-hidden="true" href="#http--孤独小弟">#</a></h4>
<h5 id="http-请求信息">HTTP 请求信息<a hidden class="anchor" aria-hidden="true" href="#http-请求信息">#</a></h5>
<p>对 <code>URL</code> 进行解析之后，浏览器确定了 Web 服务器和文件名，接下来根据这些信息来生成 HTTP 请求消息。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251907438.jpg" alt="HTTP 的消息格式"  />
</p>
<h4 id="dns--真实地址查询">DNS —— 真实地址查询<a hidden class="anchor" aria-hidden="true" href="#dns--真实地址查询">#</a></h4>
<p>通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 <code>Web</code> 服务器。</p>
<p>但在发送之前，还有一项工作需要完成，那就是<strong>查询服务器域名对应的 IP 地址</strong>，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。</p>
<p>比如我们打电话的时候，必须要知道对方的电话号码，但由于电话号码难以记忆，所以通常我们会将对方电话号 + 姓名保存在通讯录里。所以，有一种服务器就专门保存了 <code>Web</code> 服务器域名与 <code>IP</code> 的对应关系，它就是 <code>DNS</code> 服务器。</p>
<h5 id="域名的层级关系">域名的层级关系<a hidden class="anchor" aria-hidden="true" href="#域名的层级关系">#</a></h5>
<p>DNS 中的域名都是用<strong>句点</strong>来分隔的，比如 <code>www.server.com</code>，这里的句点代表了不同层次之间的<strong>界限</strong>。在域名中，<strong>越靠右</strong>的位置表示其层级<strong>越高</strong>。实际上域名最后还有一个点，比如 <code>www.server.com.</code>，这个最后的一个点代表根域名。</p>
<p>也就是，<code>.</code> 根域是在最顶层，它的下一层就是 <code>.com</code> 顶级域，再下面是 <code>server.com</code>。</p>
<p>所以域名的层级关系类似一个树状结构：</p>
<ul>
<li>根 DNS 服务器（.）</li>
<li>顶级域 DNS 服务器（.com）</li>
<li>权威 DNS 服务器（server.com）</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251913481.jpg" alt="DNS 树状结构"  />
</p>
<p>根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。（根域DNS服务器的信息是不是最少？因为它的信息是其他服务器的子集？）</p>
<p>因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。</p>
<h5 id="域名解析的工作流程">域名解析的工作流程<a hidden class="anchor" aria-hidden="true" href="#域名解析的工作流程">#</a></h5>
<ol>
<li>客户端首先会发出一个 DNS 请求，问 <a href="https://www.server.com">www.server.com</a> 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。</li>
<li>本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 <a href="https://www.server.com">www.server.com</a>，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 <a href="https://www.server.com">www.server.com</a> 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。</li>
<li>根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”</li>
<li>本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 <a href="https://www.server.com">www.server.com</a> 的 IP 地址吗？”</li>
<li>顶级域名服务器说：“我给你负责 <a href="https://www.server.com">www.server.com</a> 区域的权威 DNS 服务器的地址，你去问它应该能问到”。</li>
<li>本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li>
<li>权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。</li>
<li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li>
</ol>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251943488.jpg" alt="域名解析的工作流程"  />
</p>
<p>DNS 域名解析的过程蛮有意思的，整个过程就和我们日常生活中找人问路的过程类似，<strong>只指路不带路</strong>。</p>
<p>并不是每次解析域名都要经过那么多的步骤，浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。</p>
<h4 id="协议栈--指南好帮手">协议栈 —— 指南好帮手<a hidden class="anchor" aria-hidden="true" href="#协议栈--指南好帮手">#</a></h4>
<p>通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的<strong>协议栈</strong>。</p>
<p>协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251945261.jpg" alt="img"  />
</p>
<p>应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。</p>
<p>协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。</p>
<p>此外 IP 中还包括 <code>ICMP</code> 协议和 <code>ARP</code> 协议。</p>
<ul>
<li><code>ICMP</code> 用于告知网络包传送过程中产生的错误以及各种控制信息。</li>
<li><code>ARP</code> 用于根据 IP 地址查询相应的以太网 MAC 地址。</li>
</ul>
<p>IP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。</p>
<h4 id="tcp--可靠传输">TCP —— 可靠传输<a hidden class="anchor" aria-hidden="true" href="#tcp--可靠传输">#</a></h4>
<p>HTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。</p>
<h5 id="tcp-包头格式">TCP 包头格式<a hidden class="anchor" aria-hidden="true" href="#tcp-包头格式">#</a></h5>
<p>我们先看看 TCP 报文头部的格式：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212251954790.jpg" alt="TCP 包头格式"  />
</p>
<p>首先，<strong>源端口号</strong>和<strong>目标端口</strong>号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。</p>
<p>接下来有包的<strong>序</strong>号，这个是为了解决包乱序的问题。</p>
<p>还有应该有的是<strong>确认号</strong>，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决丢包的问题。</p>
<p>接下来还有一些<strong>状态位</strong>。例如 <code>SYN</code> 是发起一个连接，<code>ACK</code> 是回复，<code>RST</code> 是重新连接，<code>FIN</code> 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。</p>
<p>还有一个重要的就是<strong>窗口大小</strong>。TCP 要做<strong>流量控制</strong>，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。</p>
<p>除了做流量控制以外，TCP还会做<strong>拥塞控制</strong>，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。</p>
<h5 id="三次握手">三次握手<a hidden class="anchor" aria-hidden="true" href="#三次握手">#</a></h5>
<p>在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为<strong>三次握手</strong>。</p>
<p>这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252001748.png" alt="TCP 三次握手"  />
</p>
<ul>
<li>一开始，客户端和服务端都处于 <code>CLOSED</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态。</li>
<li>然后客户端主动发起连接 <code>SYN</code>，之后处于 <code>SYN-SENT</code> 状态。</li>
<li>服务端收到发起的连接，返回 <code>SYN</code>，并且 <code>ACK</code> 客户端的 <code>SYN</code>，之后处于 <code>SYN-RCVD</code> 状态。</li>
<li>客户端收到服务端发送的 <code>SYN</code> 和 <code>ACK</code> 之后，发送对 <code>SYN</code> 确认的 <code>ACK</code>，之后处于 <code>ESTABLISHED</code> 状态，因为它一发一收成功了。</li>
<li>服务端收到 <code>ACK</code> 的 <code>ACK</code> 之后，处于 <code>ESTABLISHED</code> 状态，因为它也一发一收了。</li>
</ul>
<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>
<h5 id="tcp-分割数据">TCP 分割数据<a hidden class="anchor" aria-hidden="true" href="#tcp-分割数据">#</a></h5>
<p>如果 HTTP 请求消息比较长，超过了 <code>MSS</code> 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252004728.jpg" alt="MTU 与 MSS"  />
</p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节。</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。</li>
</ul>
<p>数据会被以 <code>MSS</code> 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。
<img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252004268.jpg" alt="数据包分割"  />
</p>
<h5 id="tcp-报文生成">TCP 报文生成<a hidden class="anchor" aria-hidden="true" href="#tcp-报文生成">#</a></h5>
<p>TCP 协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是 Web 服务器监听的端口（HTTP 默认端口号是 <code>80</code>， HTTPS 默认端口号是 <code>443</code>）。</p>
<p>在双方建立了连接后，TCP 报文中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报文之后，就需交给下面的网络层处理。</p>
<p>至此，网络包的报文如下图。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252006591.jpg" alt="TCP 层报文"  />
</p>
<h4 id="ip--远程定位">IP —— 远程定位<a hidden class="anchor" aria-hidden="true" href="#ip--远程定位">#</a></h4>
<p>TCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成<strong>网络包</strong>发送给通信对象。</p>
<h5 id="ip-包头格式">IP 包头格式<a hidden class="anchor" aria-hidden="true" href="#ip-包头格式">#</a></h5>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252008596.jpg" alt="IP 包头格式"  />
</p>
<p>在 IP 协议里面需要有<strong>源地址 IP</strong> 和 <strong>目标地址 IP</strong>：</p>
<ul>
<li>源地址IP，即是客户端输出的 IP 地址；</li>
<li>目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。</li>
</ul>
<p>因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的<strong>协议号</strong>，要填写为 <code>06</code>（十六进制），表示协议为 TCP。</p>
<h5 id="ip-报文生成">IP 报文生成<a hidden class="anchor" aria-hidden="true" href="#ip-报文生成">#</a></h5>
<p>至此，网络包的报文如下图。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252045667.jpg" alt="IP 层报文"  />
</p>
<h4 id="mac--两点传输">MAC —— 两点传输<a hidden class="anchor" aria-hidden="true" href="#mac--两点传输">#</a></h4>
<p>生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 <strong>MAC 头部</strong>。</p>
<h5 id="mac-包头格式">MAC 包头格式<a hidden class="anchor" aria-hidden="true" href="#mac-包头格式">#</a></h5>
<p>MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252046718.jpg" alt="MAC 包头格式"  />
</p>
<p>在 MAC 包头里需要<strong>发送方 MAC 地址</strong>和<strong>接收方目标 MAC 地址</strong>，用于<strong>两点之间的传输</strong>。</p>
<p>一般在 TCP/IP 通信里，MAC 包头的<strong>协议类型</strong>只使用：</p>
<ul>
<li><code>0800</code> ： IP 协议</li>
<li><code>0806</code> ： ARP 协议</li>
</ul>
<h5 id="mac-发送方和接收方如何确认">MAC 发送方和接收方如何确认?<a hidden class="anchor" aria-hidden="true" href="#mac-发送方和接收方如何确认">#</a></h5>
<p><strong>发送方</strong>的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。</p>
<p><strong>接收方</strong>的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。</p>
<p>所以先得搞清楚应该把包发给谁，这个只要查一下<strong>路由表</strong>就知道了。在路由表中找到相匹配的条目，然后把包发给 <code>Gateway</code> 列中的 IP 地址就可以了。（发给路由器的IP地址？）</p>
<h5 id="既然知道要发给谁按如何获取对方的-mac-地址呢">既然知道要发给谁，按如何获取对方的 MAC 地址呢？<a hidden class="anchor" aria-hidden="true" href="#既然知道要发给谁按如何获取对方的-mac-地址呢">#</a></h5>
<p>不知道对方 MAC 地址？不知道就喊呗。</p>
<p>此时就需要 <code>ARP</code> 协议帮我们找到路由器的 MAC 地址。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252056644.jpg" alt="ARP 广播"  />
</p>
<p>ARP 协议会在以太网中以<strong>广播</strong>的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。</p>
<p>然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。</p>
<p>如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。（如果不在同一个子网呢？）</p>
<p>在后续操作系统会把本次查询结果放到一块叫做 <strong>ARP 缓存</strong>的内存空间留着以后用，不过缓存的时间就几分钟。</p>
<p>也就是说，在发包时：</p>
<ul>
<li>先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。</li>
<li>而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。</li>
</ul>
<h5 id="mac-报文生成">MAC 报文生成<a hidden class="anchor" aria-hidden="true" href="#mac-报文生成">#</a></h5>
<p>至此，网络包的报文如下图。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252058979.jpg" alt="MAC 层报文"  />
</p>
<h4 id="网卡--出口">网卡 —— 出口<a hidden class="anchor" aria-hidden="true" href="#网卡--出口">#</a></h4>
<p>网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将<strong>数字信息转换为电信号</strong>，才能在网线上传输，也就是说，这才是真正的数据发送过程。</p>
<p>负责执行这一操作的是<strong>网卡</strong>，要控制网卡还需要靠<strong>网卡驱动程序</strong>。</p>
<p>网卡驱动获取网络包之后，会将其<strong>复制</strong>到网卡内的缓存区中，接着会在其<strong>开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212252116437.png" alt="数据包"  />
</p>
<ul>
<li>起始帧分界符是一个用来表示包起始位置的标记</li>
<li>末尾的 <code>FCS</code>（帧校验序列）用来检查包传输过程是否有损坏</li>
</ul>
<p>最后网卡会将包转为电信号，通过网线发送出去。</p>
<h4 id="交换机--送别者">交换机 —— 送别者<a hidden class="anchor" aria-hidden="true" href="#交换机--送别者">#</a></h4>
<p>交换机的设计是将网络包<strong>原样</strong>转发到目的地。交换机工作在 MAC 层，也称为<strong>二层网络设备</strong>。</p>
<h5 id="交换机的包接收操作">交换机的包接收操作<a hidden class="anchor" aria-hidden="true" href="#交换机的包接收操作">#</a></h5>
<p>首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。</p>
<p>然后通过包末尾的 <code>FCS</code> 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。</p>
<p>计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<p>将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。</p>
<p>交换机的 MAC 地址表主要包含两个信息：</p>
<ul>
<li>一个是设备的 MAC 地址，</li>
<li>另一个是该设备连接在交换机的哪个端口上。</li>
</ul>
<p>所以，<strong>交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口</strong>。</p>
<h5 id="当-mac-地址表找不到指定的-mac-地址会怎么样">当 MAC 地址表找不到指定的 MAC 地址会怎么样？<a hidden class="anchor" aria-hidden="true" href="#当-mac-地址表找不到指定的-mac-地址会怎么样">#</a></h5>
<p>地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。</p>
<p>这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。</p>
<p>这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后<strong>只有相应的接收者才接收包，而其他设备则会忽略这个包</strong>。</p>
<p>有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”</p>
<p>其实完全不用过于担心，因为发送了包之后目标设备会作出<strong>响应</strong>，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。</p>
<p>局域网中每秒可以传输上千个包，多出一两个包并无大碍。</p>
<p>此外，如果接收方 MAC 地址是一个<strong>广播地址</strong>，那么交换机会将包发送到除源端口之外的所有端口。</p>
<p>以下两个属于广播地址：</p>
<ul>
<li>MAC 地址中的 <code>FF:FF:FF:FF:FF:FF</code></li>
<li>IP 地址中的 <code>255.255.255.255</code></li>
</ul>
<h4 id="路由器--出境大门">路由器 —— 出境大门<a hidden class="anchor" aria-hidden="true" href="#路由器--出境大门">#</a></h4>
<h5 id="路由器与交换机的区别">路由器与交换机的区别<a hidden class="anchor" aria-hidden="true" href="#路由器与交换机的区别">#</a></h5>
<p>网络包经过交换机之后，现在到达了<strong>路由器</strong>，并在此被转发到下一个路由器或目标设备。</p>
<p>这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。</p>
<p>不过在具体的操作过程上，路由器和交换机是有区别的。</p>
<ul>
<li>因为<strong>路由器</strong>是基于 IP 设计的，俗称<strong>三层</strong>网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；</li>
<li>而<strong>交换机</strong>是基于以太网设计的，俗称<strong>二层</strong>网络设备，交换机的端口不具有 MAC 地址。</li>
</ul>
<h5 id="路由器基本原理">路由器基本原理<a hidden class="anchor" aria-hidden="true" href="#路由器基本原理">#</a></h5>
<p>路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。</p>
<p>当转发包时，首先路由器端口会接收发给自己的以太网包，然后<strong>路由表</strong>查询转发目标，再由相应的端口作为发送方将以太网包发送出去。</p>
<h5 id="路由器的包接收操作">路由器的包接收操作<a hidden class="anchor" aria-hidden="true" href="#路由器的包接收操作">#</a></h5>
<p>首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 <code>FCS</code> 进行错误校验。</p>
<p>如果没问题则检查 MAC 头部中的<strong>接收方 MAC 地址</strong>，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。</p>
<p>总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。</p>
<h5 id="查询路由表确定输出端口">查询路由表确定输出端口<a hidden class="anchor" aria-hidden="true" href="#查询路由表确定输出端口">#</a></h5>
<p>完成包接收操作之后，路由器就会<strong>去掉</strong>包开头的 MAC 头部。</p>
<p><strong>MAC 头部的作用就是将包送达路由器</strong>，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会<strong>被丢弃</strong>。</p>
<p>接下来，路由器会根据 MAC 头部后方的 <code>IP</code> 头部中的内容进行包的转发操作。</p>
<p>转发操作分为几个阶段，首先是查询<strong>路由表</strong>判断转发目标。</p>
<p>判断转发目标的第一步，就是根据包的接收方 IP 地址查询路由表中的目标地址栏，以找到相匹配的记录。</p>
<p>路由匹配和前面讲的一样，每个条目的子网掩码和目标 IP 做 <strong>&amp; 与运算</strong>后，得到的结果与对应条目的目标地址进行匹配，如果匹配就会作为候选转发目标，如果不匹配就继续与下个条目进行路由匹配。</p>
<p>实在找不到匹配路由时，就会选择<strong>默认路由</strong>，路由表中子网掩码为 <code>0.0.0.0</code> 的记录表示「默认路由」。</p>
<h5 id="路由器的发送操作">路由器的发送操作<a hidden class="anchor" aria-hidden="true" href="#路由器的发送操作">#</a></h5>
<p>接下来就会进入包的<strong>发送操作</strong>。</p>
<p>首先，我们需要根据<strong>路由表的网关列</strong>判断对方的地址。</p>
<ul>
<li>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，<strong>还未抵达终点</strong>，还需继续需要路由器转发。</li>
<li>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明<strong>已抵达终点</strong>。</li>
</ul>
<p>知道对方的 IP 地址之后，接下来需要通过 <code>ARP</code> 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。</p>
<p>路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。</p>
<p>接下来是<strong>发送方 MAC 地址字段，这里填写输出端口的 MAC 地址</strong>。还有一个以太类型字段，填写 <code>0800</code> （十六进制）表示 IP 协议。</p>
<p>网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。</p>
<p>发送出去的网络包会通过<strong>交换机</strong>到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。</p>
<p>接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。</p>
<ul>
<li>不知你发现了没有，在网络包传输的过程中，<strong>源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址</strong>，因为需要 MAC 地址在以太网内进行<strong>两个设备</strong>之间的包传输。</li>
</ul>
<h4 id="服务器-与-客户端--相互扒皮">服务器 与 客户端 —— 相互扒皮<a hidden class="anchor" aria-hidden="true" href="#服务器-与-客户端--相互扒皮">#</a></h4>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261525582.jpg" alt="网络分层模型"  />
</p>
<p>数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。</p>
<p>接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。</p>
<p>于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。</p>
<p>于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。</p>
<p>服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。</p>
<p>HTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。</p>
<p>穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。</p>
<p>最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。</p>
<p>客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！</p>
<p>于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！</p>
<p>最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。HTTP篇</p>
<h3 id="3-linux-系统是如何收发网络包的">3. Linux 系统是如何收发网络包的？<a hidden class="anchor" aria-hidden="true" href="#3-linux-系统是如何收发网络包的">#</a></h3>
<h4 id="网络模型">网络模型<a hidden class="anchor" aria-hidden="true" href="#网络模型">#</a></h4>
<p>国际标准化组织制定了开放式系统互联通信参考模型（<em>Open System Interconnection Reference Model</em>），也就是 OSI 网络模型，该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。</p>
<p>每一层负责的职能都不同，如下：</p>
<ul>
<li>应用层，负责给应用程序提供统一的接口；</li>
<li>表示层，负责把数据转换成兼容另一个系统能识别的格式；</li>
<li>会话层，负责建立、管理和终止表示层实体之间的通信会话；</li>
<li>传输层，负责端到端的数据传输；</li>
<li>网络层，负责数据的路由、转发、分片；</li>
<li>数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；</li>
<li>物理层，负责在物理网络中传输数据帧；</li>
</ul>
<p>由于 OSI 模型实在太复杂，提出的也只是概念理论上的分层，并没有提供具体的实现方案。</p>
<p>我们比较常见，也比较实用的是四层模型，即 TCP/IP 网络模型，Linux 系统正是按照这套网络模型来实现网络协议栈的。</p>
<p>TCP/IP 网络模型共有 4 层，分别是应用层、传输层、网络层和网络接口层，每一层负责的职能如下：</p>
<ul>
<li>应用层：负责向用户提供一组应用程序，比如 HTTP、DNS、FTP 等;</li>
<li>传输层：负责端到端的通信，比如 TCP、UDP 等；</li>
<li>网络层：负责网络包的封装、分片、路由、转发，比如 IP、ICMP 等；</li>
<li>网络接口层：负责网络包在物理网络中的传输，比如网络包的封帧、 MAC 寻址、差错检测，以及通过网卡传输网络帧等；</li>
</ul>
<p>TCP/IP 网络模型相比 OSI 网络模型简化了不少，也更加易记，它们之间的关系如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261535915.png" alt="img"  />
</p>
<h4 id="linux-网络协议栈">Linux 网络协议栈<a hidden class="anchor" aria-hidden="true" href="#linux-网络协议栈">#</a></h4>
<p>从下面这张图可以看到应用层数据在每一层的封装格式。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261538083.png" alt="img"  />
</p>
<p>其中：</p>
<ul>
<li>传输层，给应用数据前面增加了 TCP 头；</li>
<li>网络层，给 TCP 数据包前面增加了 IP 头；</li>
<li>网络接口层，给 IP 数据包前后分别增加了帧头和帧尾；</li>
</ul>
<p>知道了 TCP/IP 网络模型，以及网络包的封装原理后，那么 Linux 网络协议栈就类似于 TCP/IP 的四层结构：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261557444.png" alt="img"  />
</p>
<p>从上图的的网络协议栈，你可以看到：</p>
<ul>
<li>应用程序需要通过系统调用，来跟 Socket 层进行数据交互；</li>
<li>Socket 层的下面就是传输层、网络层和网络接口层；</li>
<li>最下面的一层，则是网卡驱动程序和硬件网卡设备；</li>
</ul>
<h4 id="linux-接收网络包的流程">Linux 接收网络包的流程<a hidden class="anchor" aria-hidden="true" href="#linux-接收网络包的流程">#</a></h4>
<p>网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。</p>
<p>Linux 内核在 2.6 版本中引入了 <strong>NAPI 机制</strong>，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是<strong>不采用中断的方式读取数据</strong>，而是首先采用中断唤醒数据接收的服务程序，然后 <code>poll</code> 的方法来轮询数据。</p>
<p>因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。</p>
<p>硬件中断处理函数会做如下的事情：</p>
<ul>
<li>需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。</li>
<li>接着，发起「软中断」，然后恢复刚才屏蔽的中断。</li>
</ul>
<p>至此，硬件中断处理函数的工作就已经完成。</p>
<p>硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。</p>
<h5 id="软中断的处理">软中断的处理<a hidden class="anchor" aria-hidden="true" href="#软中断的处理">#</a></h5>
<p>内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。</p>
<p>ksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。</p>
<h5 id="网络协议栈">网络协议栈<a hidden class="anchor" aria-hidden="true" href="#网络协议栈">#</a></h5>
<p>首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。</p>
<p>到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。</p>
<p>传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。</p>
<p>最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。</p>
<p>至此，一个网络包的接收过程就已经结束了，你也可以从下图左边部分看到网络包接收的流程，右边部分刚好反过来，它是网络包发送的流程。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261631552.png" alt="img"  />
</p>
<h4 id="linux-发送网络包的流程">Linux 发送网络包的流程<a hidden class="anchor" aria-hidden="true" href="#linux-发送网络包的流程">#</a></h4>
<p>如上图的右半部分，发送网络包的流程正好和接收流程相反。</p>
<p>首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，<strong>将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区</strong>。</p>
<p>接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP/IP 协议栈从上到下逐层处理。</p>
<p>如果使用的是 TCP 传输协议发送数据，那么<strong>先拷贝一个新的 sk_buff 副本</strong> ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。</p>
<p>接着，对 sk_buff 填充 TCP 头。这里提一下，sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。</p>
<p>你可能会好奇，为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。</p>
<p>于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 <code>data</code> 的<strong>指针</strong>，比如：</p>
<ul>
<li>当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb-&gt;data 的值，来逐步剥离协议首部。</li>
<li>当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb-&gt;data 的值来增加协议首部。</li>
</ul>
<p>你可以从下面这张图看到，当发送报文时，data 指针的移动过程。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261650498.jpg" alt="img"  />
</p>
<p>至此，传输层的工作也就都完成了。</p>
<p>然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、netfilter 过滤、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。</p>
<p>网络接口层会通过 ARP 协议获得下一跳的 MAC 地址，然后对 sk_buff 填充帧头和帧尾，接着将 sk_buff 放到网卡的发送队列中。</p>
<p>这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。</p>
<p>当数据发送完成以后，其实工作并没有结束，因为内存还没有清理。当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。</p>
<p>最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。</p>
<h5 id="发送网络数据的时候涉及几次内存拷贝操作">发送网络数据的时候，涉及几次内存拷贝操作？<a hidden class="anchor" aria-hidden="true" href="#发送网络数据的时候涉及几次内存拷贝操作">#</a></h5>
<p>第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。</p>
<p>第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。</p>
<p>第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。</p>
<h2 id="http-篇">HTTP 篇<a hidden class="anchor" aria-hidden="true" href="#http-篇">#</a></h2>
<h3 id="http-是什么">HTTP 是什么？<a hidden class="anchor" aria-hidden="true" href="#http-是什么">#</a></h3>
<p>HTTP 是超文本传输协议，也就是<strong>H</strong>yperText <strong>T</strong>ransfer <strong>P</strong>rotocol。HTTP的名字「超文本协议传输」，它可以拆成三个部分：</p>
<ul>
<li>超文本</li>
<li>传输</li>
<li>协议</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212261658038.png" alt="三个部分"  />
</p>
<h4 id="协议">协议<a hidden class="anchor" aria-hidden="true" href="#协议">#</a></h4>
<p>HTTP 是一个用在计算机世界里的<strong>协议</strong>。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（<strong>两个以上的参与者</strong>），以及相关的各种控制和错误处理方式（<strong>行为约定和规范</strong>）。</p>
<h4 id="传输">传输<a hidden class="anchor" aria-hidden="true" href="#传输">#</a></h4>
<p>HTTP 协议是一个<strong>双向协议</strong>。HTTP 是一个在计算机世界里专门用来在<strong>两点之间传输数据</strong>的约定和规范。</p>
<h4 id="超文本">超文本<a hidden class="anchor" aria-hidden="true" href="#超文本">#</a></h4>
<p>「超文本」就是<strong>超越了普通文本的文本</strong>，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。</p>
<h4 id="总结-1">总结<a hidden class="anchor" aria-hidden="true" href="#总结-1">#</a></h4>
<p><strong>HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。</strong></p>
<h3 id="get-和-post">GET 和 POST<a hidden class="anchor" aria-hidden="true" href="#get-和-post">#</a></h3>
<p>根据 RFC 规范，<strong>GET 的语义是从服务器获取指定的资源</strong>，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。</p>
<p>根据 RFC 规范，<strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。</p>
<h4 id="get-和-post-方法都是安全和幂等的吗">GET 和 POST 方法都是安全和幂等的吗？<a hidden class="anchor" aria-hidden="true" href="#get-和-post-方法都是安全和幂等的吗">#</a></h4>
<p>先说明下安全和幂等的概念：</p>
<ul>
<li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。</li>
<li>所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li>
</ul>
<p>如果从 RFC 规范定义的语义来看：</p>
<ul>
<li><strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，<strong>可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签</strong>。</li>
<li><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。所以，<strong>浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签</strong>。</li>
</ul>
<p>小结：</p>
<p>GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。</p>
<p>POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。</p>
<h3 id="http-缓存技术">HTTP 缓存技术<a hidden class="anchor" aria-hidden="true" href="#http-缓存技术">#</a></h3>
<p>避免发送 HTTP 请求的方法就是通过<strong>缓存技术</strong>，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。</p>
<p>HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。</p>
<h4 id="强制缓存">强制缓存<a hidden class="anchor" aria-hidden="true" href="#强制缓存">#</a></h4>
<p>强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p>
<p>如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212271413704.png" alt="img"  />
</p>
<p>强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：</p>
<ul>
<li><code>Cache-Control</code>， 是一个相对时间；</li>
<li><code>Expires</code>，是一个绝对时间；</li>
</ul>
<p>如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，<strong>Cache-Control的优先级高于 Expires</strong> 。</p>
<p>Cache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：</p>
<ul>
<li>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小；</li>
<li>浏览器再次请求访问服务器中的该资源时，会先<strong>通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期</strong>，如果没有，则使用该缓存，否则重新请求服务器；</li>
<li>服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。</li>
</ul>
<h4 id="协商缓存">协商缓存<a hidden class="anchor" aria-hidden="true" href="#协商缓存">#</a></h4>
<p>当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 <code>304</code>，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212271429206.png" alt="img"  />
</p>
<p>上图就是一个协商缓存的过程，所以<strong>协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。</p>
<p>协商缓存可以基于两种头部来实现。</p>
<p>第一种：请求头部中的 <code>If-Modified-Since</code> 字段与响应头部中的 <code>Last-Modified</code> 字段实现，这两个字段的意思是：</p>
<ul>
<li>响应头部中的 <code>Last-Modified</code>：标示这个响应资源的最后修改时间；</li>
<li>请求头部中的 <code>If-Modified-Since</code>：当资源过期了，发现响应头中具有 <code>Last-Modified</code> 声明，则再次发起请求的时候带上 <code>Last-Modified</code> 的时间，服务器收到请求后发现有 <code>If-Modified-Since</code> 则与被请求资源的最后修改时间进行对比（<code>Last-Modified</code>），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。</li>
</ul>
<p>第二种：请求头部中的 <code>If-None-Match</code> 字段与响应头部中的 <code>ETag</code> 字段，这两个字段的意思是：</p>
<ul>
<li>响应头部中 <code>Etag</code>：唯一标识响应资源；</li>
<li>请求头部中的 <code>If-None-Match</code>：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。</li>
</ul>
<p>第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。</p>
<p>如果在第一次请求资源的时候，服务端返回的 HTTP 响应头部同时有 Etag 和 Last-Modified 字段，那么客户端再下一次请求的时候，如果带上了 ETag 和 Last-Modified 字段信息给服务端，<strong>这时 Etag 的优先级更高</strong>，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。</p>
<p>**为什么 ETag 的优先级更高？**这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：</p>
<ol>
<li>在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求；</li>
<li>可能有些文件是在秒级以内修改的，<code>If-Modified-Since</code> 能检查到的粒度是秒级的，使用 Etag就能够保证这种需求下客户端在 1 秒内能刷新多次；</li>
<li>有些服务器不能精确获取文件的最后修改时间。</li>
</ol>
<p>注意，<strong>协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求</strong>。</p>
<p>下图是强制缓存和协商缓存的工作流程（客户端）：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212281659355.png" alt="img"  />
</p>
<p>当使用 ETag 字段实现的协商缓存的过程：</p>
<ul>
<li>
<p>当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的；</p>
</li>
<li>
<p>当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期：</p>
<ul>
<li>如果没有过期，则直接使用本地缓存；</li>
<li>如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识；</li>
</ul>
</li>
<li>
<p>服务器再次收到请求后，</p>
<p>会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较：</p>
<ul>
<li><strong>如果值相等，则返回 304 Not Modified，不会返回资源</strong>；</li>
<li>如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识；</li>
</ul>
</li>
<li>
<p>如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。</p>
</li>
</ul>
<h3 id="http-特性">HTTP 特性<a hidden class="anchor" aria-hidden="true" href="#http-特性">#</a></h3>
<p>到目前为止，HTTP 常见到版本有 HTTP/1.1，HTTP/2.0，HTTP/3.0，不同版本的 HTTP 特性是不一样的。</p>
<p>这里先用 HTTP/1.1 版本给大家介绍，其他版本的后续也会介绍。</p>
<h4 id="http11-的优点有哪些">HTTP/1.1 的优点有哪些？<a hidden class="anchor" aria-hidden="true" href="#http11-的优点有哪些">#</a></h4>
<p>HTTP 最凸出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。</p>
<p><em>1. 简单</em></p>
<p>HTTP 基本的报文格式就是 <code>header + body</code>，头部信息也是 <code>key-value</code> 简单文本的形式，<strong>易于理解</strong>，降低了学习和使用的门槛。</p>
<p><em>2. 灵活和易于扩展</em></p>
<p>HTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员<strong>自定义和扩充</strong>。</p>
<p>同时 HTTP 由于是工作在应用层（ <code>OSI</code> 第七层），则它<strong>下层可以随意变化</strong>，比如：</p>
<ul>
<li>HTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层；</li>
<li>HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。</li>
</ul>
<p><em>3. 应用广泛和跨平台</em></p>
<p>互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有<strong>跨平台</strong>的优越性。</p>
<h4 id="http11-的缺点有哪些">HTTP/1.1 的缺点有哪些？<a hidden class="anchor" aria-hidden="true" href="#http11-的缺点有哪些">#</a></h4>
<p>HTTP 协议里有优缺点一体的<strong>双刃剑</strong>，分别是「<strong>无状态</strong>、<strong>明文传输</strong>」，同时还有一大缺点「不安全」。</p>
<p><em>1. 无状态双刃剑</em></p>
<p>无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。</p>
<p>无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。</p>
<p>例如登录-&gt;添加购物车-&gt;下单-&gt;结算-&gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。</p>
<p>这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是<strong>酸爽</strong>！</p>
<p>对于无状态的问题，解法方案有很多种，其中比较简单的方式用 <strong>Cookie</strong> 技术。</p>
<p><code>Cookie</code> 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。</p>
<p>相当于，<strong>在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了。</strong></p>
<p><em>2. 明文传输双刃剑</em></p>
<p>明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。</p>
<p>但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于<strong>信息裸奔</strong>。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那<strong>你号没了</strong>。</p>
<p><em>3. 不安全</em></p>
<p>HTTP 比较严重的缺点就是不安全：</p>
<ul>
<li>通信使用明文（不加密），内容可能会被窃听。比如，<strong>账号信息容易泄漏，那你号没了。</strong></li>
<li>不验证通信方的身份，因此有可能遭遇伪装。比如，<strong>访问假的淘宝、拼多多，那你钱没了。</strong></li>
<li>无法证明报文的完整性，所以有可能已遭篡改。比如，<strong>网页上植入垃圾广告，视觉污染，眼没了。</strong></li>
</ul>
<p>HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。</p>
<h3 id="http-与-https">HTTP 与 HTTPS<a hidden class="anchor" aria-hidden="true" href="#http-与-https">#</a></h3>
<h4 id="http-与-https-有哪些区别">HTTP 与 HTTPS 有哪些区别？<a hidden class="anchor" aria-hidden="true" href="#http-与-https-有哪些区别">#</a></h4>
<ul>
<li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。</li>
<li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。</li>
<li>两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。</li>
<li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li>
</ul>
<h4 id="https-解决了-http-的哪些问题">HTTPS 解决了 HTTP 的哪些问题？<a hidden class="anchor" aria-hidden="true" href="#https-解决了-http-的哪些问题">#</a></h4>
<p>HTTP 由于是明文传输，所以安全上存在以下三个风险：</p>
<ul>
<li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li>
<li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li>
<li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212281833974.jpeg" alt="HTTP 与 HTTPS 网络层"  />
</p>
<p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加入了 <code>SSL/TLS</code> 协议，可以很好的解决了上述的风险：</p>
<ul>
<li><strong>信息加密</strong>：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。</li>
<li><strong>校验机制</strong>：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。</li>
<li><strong>身份证书</strong>：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。</li>
</ul>
<p>可见，只要自身不做「恶」，SSL/TLS 协议是能保证通信是安全的。</p>
<h4 id="https-是如何解决上面的三个风险的">HTTPS 是如何解决上面的三个风险的？<a hidden class="anchor" aria-hidden="true" href="#https-是如何解决上面的三个风险的">#</a></h4>
<ul>
<li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li>
<li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li>
<li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li>
</ul>
<p><em>1. 混合加密</em></p>
<p>通过<strong>混合加密</strong>的方式可以保证信息的<strong>机密性</strong>，解决了窃听的风险。</p>
<p>HTTPS 采用的是<strong>对称加密</strong>和<strong>非对称加密</strong>结合的「混合加密」方式：</p>
<ul>
<li>在通信建立前采用<strong>非对称加密</strong>的方式交换「会话秘钥」，后续就不再使用非对称加密。</li>
<li>在通信过程中全部使用<strong>对称加密</strong>的「会话秘钥」的方式加密明文数据。</li>
</ul>
<p>采用「混合加密」的方式的原因：</p>
<ul>
<li><strong>对称加密</strong>只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。</li>
<li><strong>非对称加密</strong>使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。</li>
</ul>
<p><em>2. 摘要算法 + 数字签名</em></p>
<p>为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。</p>
<p>对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。</p>
<p>那么，在计算机里会<strong>用摘要算法（哈希函数）来计算出内容的哈希值</strong>，也就是内容的「指纹」，这个<strong>哈希值是唯一的，且无法通过哈希值推导出内容</strong>。</p>
<p>通过哈希算法可以确保内容不会被篡改，<strong>但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明</strong>。</p>
<p>计算机里会用<strong>非对称加密算法</strong>来判断，共有两个密钥：</p>
<ul>
<li>一个是公钥，这个是可以公开给所有人的；</li>
<li>一个是私钥，这个必须由本人管理，不可泄露。</li>
</ul>
<p>这两个密钥可以<strong>双向加解密</strong>的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。</p>
<p>流程的不同，意味着目的也不相同：</p>
<ul>
<li><strong>公钥加密，私钥解密</strong>。这个目的是为了<strong>保证内容传输的安全</strong>，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容；</li>
<li><strong>私钥加密，公钥解密</strong>。这个目的是为了<strong>保证消息不会被冒充</strong>，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。</li>
</ul>
<p>一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。</p>
<p>所以非对称加密的用途主要在于<strong>通过「私钥加密，公钥解密」的方式，来确认消息的身份</strong>，我们常说的<strong>数字签名算法</strong>，就是用的是这种方式，不过私钥加密内容不是内容本身，而是<strong>对内容的哈希值加密</strong>。</p>
<p>私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。</p>
<p><em>3. 数字证书</em></p>
<p>前面我们知道：</p>
<ul>
<li>可以通过哈希算法来保证消息的完整性；</li>
<li>可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）；</li>
</ul>
<p>但是这还远远不够，<strong>还缺少身份验证的环节</strong>，万一公钥是被伪造的呢？</p>
<p>我们需要通过一个权威机构来证明公钥是合法的，这个权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212281849791.jpeg" alt="数子证书工作流程"  />
</p>
<p>通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。</p>
<h4 id="https-是如何建立连接的其间交互了什么">HTTPS 是如何建立连接的？其间交互了什么？<a hidden class="anchor" aria-hidden="true" href="#https-是如何建立连接的其间交互了什么">#</a></h4>
<p>SSL/TLS 协议基本流程：</p>
<ul>
<li>客户端向服务器索要并验证服务器的公钥。</li>
<li>双方协商生产「会话秘钥」。</li>
<li>双方采用「会话秘钥」进行加密通信。</li>
</ul>
<p>前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。</p>
<p>TLS 的「握手阶段」涉及<strong>四次</strong>通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：<a href="https://xiaolincoding.com/network/2_http/https_rsa.html">RSA 算法</a>和 <a href="https://xiaolincoding.com/network/2_http/https_ecdhe.html">ECDHE 算法</a>。</p>
<p>基于 RSA 算法的 TLS 握手过程比较容易理解，所以这里先用这个给大家展示 TLS 握手过程，如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212281911311.jpeg" alt="HTTPS 连接建立过程"  />
</p>
<p>TLS 协议建立的详细流程：</p>
<p><em>1. ClientHello</em></p>
<p>首先，由客户端向服务器发起加密通信请求，也就是 <code>ClientHello</code> 请求。</p>
<p>在这一步，客户端主要向服务器发送以下信息：</p>
<p>（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。</p>
<p>（2）客户端生产的随机数（<code>Client Random</code>），后面用于生成「会话秘钥」条件之一。</p>
<p>（3）客户端支持的密码套件列表，如 RSA 加密算法。</p>
<p><em>2. SeverHello</em></p>
<p>服务器收到客户端请求后，向客户端发出响应，也就是 <code>SeverHello</code>。服务器回应的内容有如下内容：</p>
<p>（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。</p>
<p>（2）服务器生产的随机数（<code>Server Random</code>），也是后面用于生产「会话秘钥」条件之一。</p>
<p>（3）确认的密码套件列表，如 RSA 加密算法。</p>
<p>（4）服务器的数字证书。</p>
<p><em>3.客户端回应</em></p>
<p>客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p>
<p>如果证书没有问题，客户端会<strong>从数字证书中取出服务器的公钥</strong>，然后使用它加密报文，向服务器发送如下信息：</p>
<p>（1）一个随机数（<code>pre-master key</code>）。该随机数会被服务器公钥加密。</p>
<p>（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p>
<p>（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。</p>
<p>上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。</p>
<p><strong>服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」</strong>。</p>
<p><em>4. 服务器的最后回应</em></p>
<p>服务器收到客户端的第三个随机数（<code>pre-master key</code>）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。</p>
<p>然后，向客户端发送最后的信息：</p>
<p>（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。</p>
<p>（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。</p>
<p>至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。</p>
<h4 id="客户端校验数字证书的流程是怎样的">客户端校验数字证书的流程是怎样的？<a hidden class="anchor" aria-hidden="true" href="#客户端校验数字证书的流程是怎样的">#</a></h4>
<p>如下图图所示，为数字证书签发和验证流程：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212281925821.png" alt="img"  />
</p>
<p>CA 签发证书的过程，如上图左边部分：</p>
<ul>
<li>首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；</li>
<li>然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；</li>
<li>最后将 Certificate Signature 添加在文件证书上，形成数字证书；</li>
</ul>
<p>客户端校验服务端的数字证书的过程，如上图右边部分：</p>
<ul>
<li>首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；</li>
<li>通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；</li>
<li>最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。</li>
</ul>
<p>但事实上，证书的验证过程中<strong>还存在一个证书信任链的问题</strong>，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212281939543.png" alt="img"  />
</p>
<p>对于这种三级层级关系的证书的验证过程如下：</p>
<ul>
<li>客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。</li>
<li>请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。</li>
<li>“GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。</li>
</ul>
<p>在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。</p>
<p>总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。</p>
<p>最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？</p>
<p><strong>这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。</strong></p>
<h4 id="https-的应用数据是如何保证完整性的">HTTPS 的应用数据是如何保证完整性的？<a hidden class="anchor" aria-hidden="true" href="#https-的应用数据是如何保证完整性的">#</a></h4>
<p>TLS 在实现上分为<strong>握手协议</strong>和<strong>记录协议</strong>两层：</p>
<ul>
<li>TLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）；</li>
<li>TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议；</li>
</ul>
<p>TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282013733.png" alt="img"  />
</p>
<p>具体过程如下：</p>
<ul>
<li>首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。</li>
<li>接下来，经过压缩的片段会被<strong>加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证</strong>。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。</li>
<li>再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。</li>
<li>最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。</li>
</ul>
<p>记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。</p>
<p>如果你想详细了解记录协议是如何分片、压缩、计算 MAC 值、分组加密，可以看这篇：<a href="https://blog.csdn.net/zhanyiwp/article/details/105627799">理解SSL/TLS系列 (四) 记录协议</a></p>
<h3 id="http11http2http3-演变">HTTP/1.1、HTTP/2、HTTP/3 演变<a hidden class="anchor" aria-hidden="true" href="#http11http2http3-演变">#</a></h3>
<h4 id="http11-相比-http10-提高了什么性能">HTTP/1.1 相比 HTTP/1.0 提高了什么性能？<a hidden class="anchor" aria-hidden="true" href="#http11-相比-http10-提高了什么性能">#</a></h4>
<p>HTTP/1.1 相比 HTTP/1.0 性能上的改进：</p>
<ul>
<li>使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。</li>
<li>支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。</li>
</ul>
<p>但 HTTP/1.1 还是有性能瓶颈：</p>
<ul>
<li>请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 <code>Body</code> 的部分；</li>
<li>发送冗长的首部。每次互相发送相同的首部造成的浪费较多；</li>
<li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；</li>
<li>没有请求优先级控制；</li>
<li>请求只能从客户端开始，服务器只能被动响应。</li>
</ul>
<h4 id="http2-做了什么优化">HTTP/2 做了什么优化？<a hidden class="anchor" aria-hidden="true" href="#http2-做了什么优化">#</a></h4>
<p>HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282133726.jpeg" alt="HTT/1 ~ HTTP/2"  />
</p>
<p>那 HTTP/2 相比 HTTP/1.1 性能上的改进：</p>
<ul>
<li>头部压缩</li>
<li>二进制格式</li>
<li>并发传输</li>
<li>服务器主动推送资源</li>
</ul>
<p><em>1. 头部压缩</em></p>
<p>HTTP/2 会<strong>压缩头</strong>（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你<strong>消除重复的部分</strong>。</p>
<p>这就是所谓的 <code>HPACK</code> 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就<strong>提高速度</strong>了。</p>
<p><em>2. 二进制格式</em></p>
<p>HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了<strong>二进制格式</strong>，头信息和数据体都是二进制，并且统称为帧（frame）：<strong>头信息帧（Headers Frame）和数据帧（Data Frame）</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282211548.png" alt="HTTP/1 与 HTTP/2 "  />
</p>
<p>这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这<strong>增加了数据传输的效率</strong>。</p>
<p><em>3. 并发传输</em></p>
<p>我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了<strong>队头阻塞</strong>的问题。</p>
<p>而 HTTP/2 就很牛逼了，引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282212126.png" alt="img"  />
</p>
<p>从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。</p>
<p><strong>针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应</strong>。</p>
<p><em>4、服务器推送</em></p>
<p>HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以<strong>主动</strong>向客户端发送消息。</p>
<p>客户端和服务器<strong>双方都可以建立 Stream</strong>， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。</p>
<h5 id="http2-有什么缺陷">HTTP/2 有什么缺陷？<a hidden class="anchor" aria-hidden="true" href="#http2-有什么缺陷">#</a></h5>
<p>HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。</p>
<p><strong>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。</strong></p>
<p>一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的<strong>所有的 HTTP 请求都必须等待这个丢了的包被重传回来</strong>。</p>
<h4 id="http3-做了哪些优化">HTTP/3 做了哪些优化？<a hidden class="anchor" aria-hidden="true" href="#http3-做了哪些优化">#</a></h4>
<p>前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：</p>
<ul>
<li>HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是<strong>没有解决响应的队头阻塞</strong>，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。</li>
<li>HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是<strong>一旦发生丢包，就会阻塞住所有的 HTTP 请求</strong>，这属于 TCP 层队头阻塞。</li>
</ul>
<p>HTTP/2 队头阻塞的问题是因为 TCP，所以 <strong>HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！</strong></p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282232979.jpeg" alt="HTTP/1 ~ HTTP/3"  />
</p>
<p>UDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC 协议</strong> 可以实现类似 TCP 的可靠性传输。</p>
<p>QUIC 有以下 3 个特点。</p>
<ul>
<li>无队头阻塞</li>
<li>更快的连接建立</li>
<li>连接迁移</li>
</ul>
<p><em>1、无队头阻塞</em></p>
<p>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p>
<p>QUIC 有自己的一套机制可以保证传输的可靠性的。<strong>当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题</strong>。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p>
<p>所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。</p>
<p><em>2、更快的连接建立</em></p>
<p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p>
<p>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p>
<p>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282305426.jpeg" alt="TCP HTTPS（TLS/1.3） 和 QUIC HTTPS "  />
</p>
<p>甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</p>
<p>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212282305987.png" alt="img"  />
</p>
<p><em>3、连接迁移</em></p>
<p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p>
<p>那么<strong>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</strong>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p>
<p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<strong>连接 ID</strong>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<strong>连接迁移</strong>的功能。</p>
<p>所以， QUIC 是一个在 UDP 之上的<strong>伪</strong> TCP + TLS + HTTP/2 的多路复用的协议。</p>
<p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。</p>
<p>HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。</p>
<h2 id="tcp篇">TCP篇<a hidden class="anchor" aria-hidden="true" href="#tcp篇">#</a></h2>
<h3 id="什么是-tcp-">什么是 TCP ？<a hidden class="anchor" aria-hidden="true" href="#什么是-tcp-">#</a></h3>
<p>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</p>
<ul>
<li><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；</li>
<li><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；</li>
<li><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</li>
</ul>
<h3 id="tcp-头格式有哪些">TCP 头格式有哪些？<a hidden class="anchor" aria-hidden="true" href="#tcp-头格式有哪些">#</a></h3>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301458397.png" alt="TCP 头格式"  />
</p>
<p><strong>序列号</strong>：在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。<strong>用来解决网络包乱序问题。</strong></p>
<p><strong>确认应答号</strong>：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。<strong>用来解决丢包的问题。</strong></p>
<p><strong>控制位：</strong></p>
<ul>
<li><em>ACK</em>：该位为 <code>1</code> 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 <code>SYN</code> 包之外该位必须设置为 <code>1</code> 。</li>
<li><em>RST</em>：该位为 <code>1</code> 时，表示 TCP 连接中出现异常必须强制断开连接。</li>
<li><em>SYN</em>：该位为 <code>1</code> 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。</li>
<li><em>FIN</em>：该位为 <code>1</code> 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 <code>FIN</code> 位为 1 的 TCP 段。</li>
</ul>
<h3 id="udp-和-tcp-有什么区别呢分别的应用场景是">UDP 和 TCP 有什么区别呢？分别的应用场景是？<a hidden class="anchor" aria-hidden="true" href="#udp-和-tcp-有什么区别呢分别的应用场景是">#</a></h3>
<p>UDP 不提供复杂的控制机制，利用 IP 提供面向「无连接」的通信服务。</p>
<p>UDP 协议真的非常简单，头部只有 <code>8</code> 个字节（ 64 位），UDP 的头部格式如下：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301507892.png" alt="UDP 头部格式"  />
</p>
<ul>
<li>目标和源端口：主要是告诉 UDP 协议应该把报文发给哪个进程。</li>
<li>包长度：该字段保存了 UDP 首部的长度跟数据的长度之和。</li>
<li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP包。</li>
</ul>
<p><strong>TCP 和 UDP 区别：</strong></p>
<p><em>1. 连接</em></p>
<ul>
<li>TCP 是面向连接的传输层协议，传输数据前先要建立连接。</li>
<li>UDP 是不需要连接，即刻传输数据。</li>
</ul>
<p><em>2. 服务对象</em></p>
<ul>
<li>TCP 是一对一的两点服务，即一条连接只有两个端点。</li>
<li>UDP 支持一对一、一对多、多对多的交互通信</li>
</ul>
<p><em>3. 可靠性</em></p>
<ul>
<li>TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。</li>
<li>UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议，具体可以参见这篇文章：<a href="https://xiaolincoding.com/network/3_tcp/quic.html">如何基于 UDP 协议实现可靠传输？</a></li>
</ul>
<p><em>4. 拥塞控制、流量控制</em></p>
<ul>
<li>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。</li>
<li>UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。</li>
</ul>
<p><em>5. 首部开销</em></p>
<ul>
<li>TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 <code>20</code> 个字节，如果使用了「选项」字段则会变长的。</li>
<li>UDP 首部只有 8 个字节，并且是固定不变的，开销较小。</li>
</ul>
<p><em>6. 传输方式</em></p>
<ul>
<li>TCP 是流式传输，没有边界，但保证顺序和可靠。</li>
<li>UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。</li>
</ul>
<p><em>7. 分片不同</em></p>
<ul>
<li>TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。</li>
<li>UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。</li>
</ul>
<p><strong>TCP 和 UDP 应用场景：</strong></p>
<p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p>
<ul>
<li><code>FTP</code> 文件传输；</li>
<li>HTTP / HTTPS；</li>
</ul>
<p>由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：</p>
<ul>
<li>包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等；</li>
<li>视频、音频等多媒体通信；</li>
<li>广播通信；</li>
</ul>
<h3 id="tcp-连接建立">TCP 连接建立<a hidden class="anchor" aria-hidden="true" href="#tcp-连接建立">#</a></h3>
<h4 id="tcp-三次握手过程是怎样的">TCP 三次握手过程是怎样的？<a hidden class="anchor" aria-hidden="true" href="#tcp-三次握手过程是怎样的">#</a></h4>
<p>TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而<strong>建立连接是通过三次握手来进行的</strong>。三次握手的过程如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301608737.png" alt="TCP 三次握手"  />
</p>
<ul>
<li>一开始，客户端和服务端都处于 <code>CLOSE</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301609571.png" alt="第一个报文—— SYN 报文"  />
</p>
<ul>
<li>客户端会随机初始化序号（<code>client_isn</code>），将此序号置于 TCP 首部的「序号」字段中，同时把 <code>SYN</code> 标志位置为 <code>1</code> ，表示 <code>SYN</code> 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 <code>SYN-SENT</code> 状态。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301619207.png" alt="第二个报文 —— SYN &#43; ACK 报文"  />
</p>
<ul>
<li>服务端收到客户端的 <code>SYN</code> 报文后，首先服务端也随机初始化自己的序号（<code>server_isn</code>），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 <code>client_isn + 1</code>, 接着把 <code>SYN</code> 和 <code>ACK</code> 标志位置为 <code>1</code>。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 <code>SYN-RCVD</code> 状态。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301622678.png" alt="第三个报文 —— ACK 报文"  />
</p>
<ul>
<li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 <code>ACK</code> 标志位置为 <code>1</code> ，其次「确认应答号」字段填入 <code>server_isn + 1</code> ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 <code>ESTABLISHED</code> 状态。</li>
<li>服务端收到客户端的应答报文后，也进入 <code>ESTABLISHED</code> 状态。</li>
</ul>
<p>从上面的过程可以发现<strong>第三次握手是可以携带数据的，前两次握手是不可以携带数据的</strong>，这也是面试常问的题。</p>
<p>一旦完成三次握手，双方都处于 <code>ESTABLISHED</code> 状态，此时连接就已建立完成，客户端和服务端就可以相互发送数据了。</p>
<h3 id="为什么是三次握手不是两次四次">为什么是三次握手？不是两次、四次？<a hidden class="anchor" aria-hidden="true" href="#为什么是三次握手不是两次四次">#</a></h3>
<p>在前面我们知道了什么是 <strong>TCP 连接</strong>：</p>
<ul>
<li>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括<strong>Socket、序列号和窗口大小</strong>称为连接。</li>
</ul>
<p>所以，重要的是<strong>为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接。</strong></p>
<p>接下来，以三个方面分析三次握手的原因：</p>
<ul>
<li>三次握手才可以阻止重复历史连接的初始化（主要原因）</li>
<li>三次握手才可以同步双方的初始序列号</li>
<li>三次握手才可以避免资源浪费</li>
</ul>
<p><em><strong>原因一：避免历史连接</strong></em></p>
<p>我们来看看 RFC 793 指出的 TCP 连接使用三次握手的<strong>首要原因</strong>：</p>
<p><em>The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.</em></p>
<p>简单来说，三次握手的<strong>首要原因是为了防止旧的重复连接初始化造成混乱。</strong></p>
<p>我们考虑一个场景，客户端先发送了 SYN（seq = 90） 报文，然后客户端宕机了，而且这个 SYN 报文还被网络阻塞了，服务端并没有收到，接着客户端重启后，又重新向服务端建立连接，发送了 SYN（seq = 100） 报文（<em>注意！不是重传 SYN，重传的 SYN 的序列号是一样的</em>）。</p>
<p>看看三次握手是如何阻止历史连接的：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301629854.png" alt="三次握手避免历史连接"  />
</p>
<p>客户端连续发送多次 SYN （都是同一个四元组）建立连接的报文，在<strong>网络拥堵</strong>情况下：</p>
<ul>
<li>一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个 <code>SYN + ACK</code> 报文给客户端，此报文中的确认号是 91（90+1）。</li>
<li>客户端收到后，发现自己期望收到的确认号应该是 100+1，而不是 90 + 1，于是就会回 RST 报文。</li>
<li>服务端收到 RST 报文后，就会释放连接。</li>
<li>后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。</li>
</ul>
<p>上述中的「旧 SYN 报文」称为历史连接，TCP 使用三次握手建立连接的<strong>最主要原因就是防止「历史连接」初始化了连接</strong>。</p>
<p><strong>如果是两次握手连接，就无法阻止历史连接</strong>，主要是因为<strong>在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费</strong>。（就是说首先发起连接是由客户端发起，最后确认连接还是要客户端确认）</p>
<p>（但是这样的情况还是比较少见的吧？为什么不直接两次握手，如果遇到这种情况再由客户端把服务端把连接中断？）</p>
<p><em><strong>原因二：同步双方初始序列号</strong></em></p>
<p>TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：</p>
<ul>
<li>接收方可以去除重复的数据；</li>
<li>接收方可以根据数据包的序列号按序接收；</li>
<li>可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；</li>
</ul>
<p>可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 <code>SYN</code> 报文的时候，需要服务端回一个 <code>ACK</code> 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，<strong>这样一来一回，才能确保双方的初始序列号能被可靠的同步。</strong></p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212301856813.png" alt="四次握手与三次握手"  />
</p>
<p>四次握手其实也能够可靠的同步双方的初始化序号，但由于<strong>第二步和第三步可以优化成一步</strong>，所以就成了「三次握手」。</p>
<p>而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。</p>
<p><em><strong>原因三：避免资源浪费</strong></em></p>
<p>如果只有「两次握手」，当客户端发生的 <code>SYN</code> 报文在网络中阻塞，客户端没有接收到 <code>ACK</code> 报文，就会重新发送 <code>SYN</code> ，<strong>由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 <code>ACK</code> 报文，所以服务端每收到一个 <code>SYN</code> 就只能先主动建立一个连接</strong>，这会造成什么情况呢？</p>
<p>如果客户端发送的 <code>SYN</code> 报文在网络中阻塞了，重复发送多次 <code>SYN</code> 报文，那么服务端在收到请求后就会**建立多个冗余的无效链接，造成不必要的资源浪费。**即两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 <code>SYN</code> 报文，而造成重复分配资源。</p>
<p>（哦原来是服务端比较牛，资源比较珍贵，不会轻易建立连接，需要舔狗客户端多舔两口才行）</p>
<p><em><strong>小结</strong></em></p>
<p>TCP 建立连接时，通过三次握手<strong>能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号</strong>。序列号能够保证数据包不重复、不丢弃和按序传输。</p>
<p>不使用「两次握手」和「四次握手」的原因：</p>
<ul>
<li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；</li>
<li>「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。</li>
</ul>
<h3 id="为什么每次建立-tcp-连接时初始化的序列号都要求不一样呢">为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？<a hidden class="anchor" aria-hidden="true" href="#为什么每次建立-tcp-连接时初始化的序列号都要求不一样呢">#</a></h3>
<p>主要原因有两个方面：</p>
<ul>
<li>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；</li>
<li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</li>
</ul>
<h3 id="既然-ip-层会分片为什么-tcp-层还需要-mss-呢">既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？<a hidden class="anchor" aria-hidden="true" href="#既然-ip-层会分片为什么-tcp-层还需要-mss-呢">#</a></h3>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212302116474.png" alt="MTU 与 MSS"  />
</p>
<ul>
<li><code>MTU</code>：一个网络包的最大长度，以太网中一般为 <code>1500</code> 字节；</li>
<li><code>MSS</code>：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；</li>
</ul>
<p>如果在 TCP 的整个报文（头部 + 数据）交给 IP 层进行分片，会有什么异常呢？</p>
<p>当 IP 层有一个超过 <code>MTU</code> 大小的数据（TCP 头部 + TCP 数据）要发送，那么 IP 层就要进行分片，把数据分片成若干片，保证每一个分片都小于 MTU。把一份 IP 数据报进行分片以后，由目标主机的 IP 层来进行重新组装后，再交给上一层 TCP 传输层。</p>
<p>这看起来井然有序，但这存在隐患的，<strong>那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传</strong>。</p>
<p>因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</p>
<p>当某一个 IP 分片丢失后，接收方的 IP 层就无法组装成一个完整的 TCP 报文（头部 + 数据），也就无法将数据报文送到 TCP 层，所以接收方不会响应 ACK 给发送方，因为发送方迟迟收不到 ACK 确认报文，所以会触发超时重传，就会重发「整个 TCP 报文（头部 + 数据）」。</p>
<p>因此，可以得知由 IP 层进行分片传输，是非常没有效率的。</p>
<p>所以，为了达到最佳的传输效能 TCP 协议在<strong>建立连接的时候通常要协商双方的 MSS 值</strong>，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。</p>
<p>经过 TCP 层分片后，如果一个 TCP 分片丢失后，<strong>进行重发时也是以 MSS 为单位</strong>，而不用重传所有的分片，大大增加了重传的效率。</p>
<h3 id="tcp-连接断开">TCP 连接断开<a hidden class="anchor" aria-hidden="true" href="#tcp-连接断开">#</a></h3>
<h4 id="tcp-四次挥手">TCP 四次挥手<a hidden class="anchor" aria-hidden="true" href="#tcp-四次挥手">#</a></h4>
<p>TCP 断开连接是通过<strong>四次挥手</strong>方式，双方都可以主动断开连接，断开连接后主机中的「资源」将被释放，四次挥手的过程如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212302141541.png" alt="客户端主动关闭连接 —— TCP 四次挥手"  />
</p>
<ul>
<li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li>
<li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。</li>
<li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li>
<li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li>
<li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li>
<li>服务端收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。</li>
<li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭。</li>
</ul>
<p>你可以看到，每个方向都需要<strong>一个 FIN 和一个 ACK</strong>，因此通常被称为<strong>四次挥手</strong>。</p>
<p>这里一点需要注意是：<strong>主动关闭连接的，才有 TIME_WAIT 状态。</strong></p>
<p>（相当于服务端要发还 SYN+ACK ，但由于数据可能还没发送或者处理完，所以需要分开发送，因此是四次）</p>
<h3 id="socket-编程">Socket 编程<a hidden class="anchor" aria-hidden="true" href="#socket-编程">#</a></h3>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301101616519.png" alt="基于 TCP 协议的客户端和服务端工作"  />
</p>
<ul>
<li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li>
<li>服务端调用 <code>bind</code>，将 socket 绑定在指定的 IP 地址和端口;</li>
<li>服务端调用 <code>listen</code>，进行监听；</li>
<li>服务端调用 <code>accept</code>，等待客户端连接；</li>
<li>客户端调用 <code>connect</code>，向服务端端的地址和端口发起连接请求；</li>
<li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li>
<li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li>
<li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li>
</ul>
<p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p>
<p>所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p>
<p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p>
<h4 id="客户端连接服务端时发送了什么">客户端连接服务端时，发送了什么？<a hidden class="anchor" aria-hidden="true" href="#客户端连接服务端时发送了什么">#</a></h4>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202212310027288.png" alt="socket 三次握手"  />
</p>
<ul>
<li>客户端的协议栈向服务端端发送了 SYN 包，并告诉服务端当前发送序列号 client_isn，客户端进入 SYN_SENT 状态；</li>
<li>服务端端的协议栈收到这个包之后，和客户端进行 ACK 应答，应答的值为 client_isn+1，表示对 SYN 包 client_isn 的确认，同时服务端也发送一个 SYN 包，告诉客户端当前我的发送序列号为 server_isn，服务端端进入 SYN_RCVD 状态；</li>
<li>客户端协议栈收到 ACK 之后，使得应用程序从 <code>connect</code> 调用返回，表示客户端到服务端端的单向连接建立成功，客户端的状态为 ESTABLISHED，同时客户端协议栈也会对服务端端的 SYN 包进行应答，应答数据为 server_isn+1；</li>
<li>ACK 应答包到达服务端端后，服务端端的 TCP 连接进入 ESTABLISHED 状态，同时服务端端协议栈使得 <code>accept</code> 阻塞调用返回，这个时候服务端端到客户端的单向连接也建立成功。至此，客户端与服务端两个方向的连接都建立成功。</li>
</ul>
<p>从上面的描述过程，我们可以得知<strong>客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。</strong></p>
<h4 id="客户端调用-close-了连接是断开的流程是什么">客户端调用 close 了，连接是断开的流程是什么？<a hidden class="anchor" aria-hidden="true" href="#客户端调用-close-了连接是断开的流程是什么">#</a></h4>
<p>我们看看客户端主动调用了 <code>close</code>，会发生什么？</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301101616702.png" alt="客户端调用 close 过程"  />
</p>
<ul>
<li>客户端调用 <code>close</code>，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；</li>
<li>服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 <code>EOF</code> 到接收缓冲区中，应用程序可以通过 <code>read</code> 调用来感知这个 FIN 包。这个 <code>EOF</code> 会被<strong>放在已排队等候的其他已接收的数据之后</strong>，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；</li>
<li>接着，当处理完数据后，自然就会读到 <code>EOF</code>，于是也调用 <code>close</code> 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；</li>
<li>客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；</li>
<li>服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；</li>
<li>客户端经过 <code>2MSL</code> 时间之后，也进入 CLOSE 状态；</li>
</ul>
<h3 id="同时开同时关是什么东东">同时开，同时关是什么东东？<a hidden class="anchor" aria-hidden="true" href="#同时开同时关是什么东东">#</a></h3>
<h3 id="tcp重传滑动窗口流量控制拥塞控制">TCP重传、滑动窗口、流量控制、拥塞控制<a hidden class="anchor" aria-hidden="true" href="#tcp重传滑动窗口流量控制拥塞控制">#</a></h3>
<p>TCP 是一个可靠传输的协议，是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。</p>
<h4 id="重传机制">重传机制<a hidden class="anchor" aria-hidden="true" href="#重传机制">#</a></h4>
<h5 id="超时重传">超时重传<a hidden class="anchor" aria-hidden="true" href="#超时重传">#</a></h5>
<p>TCP 会在以下两种情况发生超时重传：</p>
<ul>
<li>数据包丢失</li>
<li>确认应答丢失</li>
</ul>
<p><code>RTT</code> 指的是<strong>数据发送时刻到接收到确认的时刻的差值</strong>，也就是包的往返时间。</p>
<p>超时重传时间是以 <code>RTO</code> （Retransmission Timeout 超时重传时间）表示。</p>
<p>假设在重传的情况下，超时时间 <code>RTO</code> 「较长或较短」时，会发生什么事情呢？</p>
<p>有两种超时时间不同的情况：</p>
<ul>
<li>当超时时间 <strong>RTO 较大</strong>时，重发就慢，丢了老半天才重发，没有效率，性能差；</li>
<li>当超时时间 <strong>RTO 较小</strong>时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。</li>
</ul>
<p><strong>结论：超时重传时间 RTO 的值应该略大于报文往返 RTT 的值</strong></p>
<p>但实际上「报文往返 RTT 的值」是经常变化的，所以「超时重传时间 RTO 的值」应该是一个<strong>动态变化的值</strong>。</p>
<p>估计往返时间，通常需要采样以下两个：</p>
<ul>
<li>需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。</li>
<li>除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。</li>
</ul>
<p><strong>每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</strong></p>
<p>超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？于是就可以用「快速重传」机制来解决超时重发的时间等待。</p>
<h5 id="快速重传">快速重传<a hidden class="anchor" aria-hidden="true" href="#快速重传">#</a></h5>
<p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301021908385.jpg" alt="快速重传机制"  />
</p>
<p>在上图，发送方发出了 1，2，3，4，5 份数据：</p>
<ul>
<li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li>
<li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li>
<li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li>
<li><strong>发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</strong></li>
<li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li>
</ul>
<p>所以，快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。</p>
<p>快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是<strong>重传的时候，是重传一个，还是重传所有的问题。</strong></p>
<h5 id="sack方法">SACK方法<a hidden class="anchor" aria-hidden="true" href="#sack方法">#</a></h5>
<p>还有一种实现重传机制的方式叫：<code>SACK</code>（ Selective Acknowledgment）， <strong>选择性确认</strong>。</p>
<p>这种方式需要在 TCP 头部「选项」字段里加一个 <code>SACK</code> 的东西，它<strong>可以将已收到的数据的信息发送给「发送方」</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301101615425.jpg" alt="选择性确认"  />
</p>
<h5 id="duplicate-sack">Duplicate SACK<a hidden class="anchor" aria-hidden="true" href="#duplicate-sack">#</a></h5>
<p>Duplicate SACK 又称 <code>D-SACK</code>，其主要<strong>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</strong></p>
<p><strong>1. 网络延时</strong></p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301101615673.jpg" alt="网络延时"  />
</p>
<ul>
<li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li>
<li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li>
<li><strong>所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</strong></li>
<li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li>
</ul>
<p><strong>2. ACK丢包</strong></p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301101614727.jpg" alt="ACK 丢包"  />
</p>
<ul>
<li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li>
<li><strong>于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500</strong>，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 <code>D-SACK</code>。</li>
<li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li>
</ul>
<p>可见，<code>D-SACK</code> 有这么几个<strong>好处</strong>：</p>
<ol>
<li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li>
<li>可以知道是不是「发送方」的数据包被网络延迟了;</li>
<li>可以知道网络中是不是把「发送方」的数据包给复制了;</li>
</ol>
<h4 id="滑动窗口">滑动窗口<a hidden class="anchor" aria-hidden="true" href="#滑动窗口">#</a></h4>
<p>我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。</p>
<p>所以，这样的传输方式有一个缺点：数据包的<strong>往返时间越长，通信的效率就越低</strong>。</p>
<p>为解决这个问题，TCP 引入了<strong>窗口</strong>这个概念。即使在往返时间较长的情况下，它也不会降低网络通信的效率。</p>
<p>那么有了窗口，就可以指定窗口大小，窗口大小就是指<strong>无需等待确认应答，而可以继续发送数据的最大值</strong>。</p>
<p><strong>窗口大小由哪一方决定？</strong></p>
<p>TCP 头里有一个字段叫 <code>Window</code>，也就是窗口大小。</p>
<p><strong>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。</strong></p>
<p>所以，通常窗口的大小是由接收方的窗口大小来决定的。</p>
<p>发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。</p>
<p><strong>接收窗口和发送窗口的大小是相等的吗？</strong></p>
<p>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。</p>
<p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p>
<h4 id="流量控制">流量控制<a hidden class="anchor" aria-hidden="true" href="#流量控制">#</a></h4>
<p>**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。**流量控制是避免「发送方」的数据填满「接收方」的缓存。</p>
<p>下面举个栗子，为了简单起见，假设以下场景：</p>
<ul>
<li>客户端是接收方，服务端是发送方</li>
<li>假设接收窗口和发送窗口相同，都为 <code>200</code></li>
<li>假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301101614983.png" alt="流量控制"  />
</p>
<p>根据上图的流量控制，说明下每个过程：</p>
<ol>
<li>客户端向服务端发送请求数据报文。这里要说明下，本次例子是把服务端作为发送方，所以没有画出服务端的接收窗口。</li>
<li>服务端收到请求报文后，发送确认报文和 80 字节的数据，于是可用窗口 <code>Usable</code> 减少为 120 字节，同时 <code>SND.NXT</code> 指针也向右偏移 80 字节后，指向 321，<strong>这意味着下次发送数据的时候，序列号是 321。</strong></li>
<li>客户端收到 80 字节数据后，于是接收窗口往右移动 80 字节，<code>RCV.NXT</code> 也就指向 321，<strong>这意味着客户端期望的下一个报文的序列号是 321</strong>，接着发送确认报文给服务端。</li>
<li>服务端再次发送了 120 字节数据，于是可用窗口耗尽为 0，服务端无法再继续发送数据。</li>
<li>客户端收到 120 字节的数据后，于是接收窗口往右移动 120 字节，<code>RCV.NXT</code> 也就指向 441，接着发送确认报文给服务端。</li>
<li>服务端收到对 80 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 321，于是可用窗口 <code>Usable</code> 增大到 80。</li>
<li>服务端收到对 120 字节数据的确认报文后，<code>SND.UNA</code> 指针往右偏移后指向 441，于是可用窗口 <code>Usable</code> 增大到 200。</li>
<li>服务端可以继续发送了，于是发送了 160 字节的数据后，<code>SND.NXT</code> 指向 601，于是可用窗口 <code>Usable</code> 减少到 40。</li>
<li>客户端收到 160 字节后，接收窗口往右移动了 160 字节，<code>RCV.NXT</code> 也就是指向了 601，接着发送确认报文给服务端。</li>
<li>服务端收到对 160 字节数据的确认报文后，发送窗口往右移动了 160 字节，于是 <code>SND.UNA</code> 指针偏移了 160 后指向 601，可用窗口 <code>Usable</code> 也就增大至了 200。</li>
</ol>
<h4 id="拥塞控制">拥塞控制<a hidden class="anchor" aria-hidden="true" href="#拥塞控制">#</a></h4>
<p>流量控制是避免「发送方」的数据填满「接收方」的缓存，但在网络出现拥堵时，流量控制感觉不到，如果此时继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大&hellip;.所以，TCP 不能忽略网络上发生的事，当网络发送拥塞时，于是就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络</strong></p>
<p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p>
<p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p>
<p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p>
<p>拥塞窗口 <code>cwnd</code> 变化的规则：</p>
<ul>
<li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li>
<li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li>
</ul>
<p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p>
<p>拥塞控制主要是四个算法：</p>
<ul>
<li>慢启动</li>
<li>拥塞避免</li>
<li>拥塞发生</li>
<li>快速恢复</li>
</ul>
<h2 id="ip篇">IP篇<a hidden class="anchor" aria-hidden="true" href="#ip篇">#</a></h2>
<p><strong>源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化。</strong></p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301012327985.jpg" alt="IP 地址分类"  />
</p>
<ul>
<li>
<p>主机号全为 1 指定某个网络下的所有主机，用于广播。广播地址用于在<strong>同一个链路中相互连接的主机之间发送数据包</strong>。</p>
</li>
<li>
<p><strong>在本网络内广播的叫做本地广播</strong>。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。</p>
</li>
<li>
<p><strong>在不同网络之间的广播叫做直接广播</strong>。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发。） 。</p>
</li>
<li>
<p>主机号全为 0 指定某个网络（子网掩码时用）。</p>
</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202301112240285.jpg" alt="本地广播与直接广播"  />
</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://perhapzz.github.io/tags/basics/">basics</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://perhapzz.github.io">perhapzz</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
