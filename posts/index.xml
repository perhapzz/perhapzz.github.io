<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on perhapzz</title>
    <link>https://perhapzz.github.io/posts/</link>
    <description>Recent content in Posts on perhapzz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Mar 2023 21:19:02 +0800</lastBuildDate><atom:link href="https://perhapzz.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>医疗影像网络架构学习</title>
      <link>https://perhapzz.github.io/posts/medicalimage/</link>
      <pubDate>Wed, 22 Mar 2023 21:19:02 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/medicalimage/</guid>
      <description>ViT Title: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale Paper: arXiv:2010.11929
 把最重要的说在最前面，ViT原论文中最核心的结论是，当拥有足够多的数据进行预训练的时候，ViT的表现就会超过CNN，突破transformer缺少归纳偏置的限制，可以在下游任务中获得较好的迁移效果。
ViT 结构 按照上面的流程图，一个 ViT block 可以分为以下几个步骤:
 patch embedding：例如输入图片大小为 224x224，将图片分为固定大小的 patch，patch 大小为 16x16，则每张图像会生成 224x224/16x16=196 个 patch，即输入序列长度为 196，每个patch维度 16x16x3=768，线性投射层的维度为 768xN (N=768)，因此输入通过线性投射层之后的维度依然为 196x768，即一共有 196 个 token，每个 token 的维度是 768。这里还需要加上一个特殊字符 cls（类似 BERT），因此最终的维度是 197x768。到目前为止，已经通过 patch embedding 将一个视觉问题转化为了一个 seq2seq 问题。 positional encoding（standard learnable 1D position embeddings）：ViT 同样需要加入位置编码，位置编码可以理解为一张表，表一共有 N 行，N 的大小和输入序列长度相同，每一行代表一个向量，向量的维度和输入序列 embedding 的维度相同（768）。注意位置编码的操作是 sum，而不是 concat。加入位置编码信息之后，维度依然是 197x768。 LN/multi-head attention/LN：LN输出维度依然是 197x768。多头自注意力时，先将输入映射到 q，k，v，如果只有一个头，qkv 的维度都是197x768，如果有 12 个头（768/12=64），则 qkv 的维度是 197x64，一共有 12 组 qkv，最后再将 12 组 qkv 的输出拼接起来，输出维度是 197x768，然后在过一层 LN，维度依然是197x768。 MLP：将维度放大再缩小回去，197x768 放大为 197x3072，再缩小变为 197x768。  一个 block 之后维度依然和输入相同，都是 197x768，因此可以堆叠多个 block。最后会将特殊字符 cls 对应的输出 $Z_L^0$ 作为 encoder 的最终输出 ，代表最终的 image presentation（另一种做法是不加cls字符，对所有的tokens的输出做一个平均），如下公式(4)，后面接一个MLP进行图片分类：</description>
    </item>
    
    <item>
      <title>数据库笔记</title>
      <link>https://perhapzz.github.io/posts/mysql/</link>
      <pubDate>Wed, 22 Feb 2023 16:00:51 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/mysql/</guid>
      <description>数据库 MySQL 一条指令是怎么执行的？ MySQL 的架构共分为两层：Server 层和存储引擎层：
 Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。 存储引擎层负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。  各个模块的作用：
1. 连接器  与客户端进行 TCP 三次握手建立连接； 校验客户端的用户名和密码，如果用户名或密码不对，则会报错； 如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；  2. 查询缓存  如果查询的语句命中查询缓存，那么就会直接返回 value 给客户端。如果查询的语句没有命中查询缓存中，那么就要往下继续执行，等执行完后，查询的结果就会被存入查询缓存中。 MySQL 8.0 版本直接将查询缓存删掉了，也就是说 MySQL 8.0 开始，执行一条 SQL 查询语句，不会再走到查询缓存这个阶段了。  3. 解析 SQL  词法分析。MySQL 会根据你输入的字符串识别出关键字出来，构建出 SQL 语法树，这样方便后面模块获取 SQL 类型、表名、字段名、 where 条件等等。 语法分析。根据词法分析的结果，语法解析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 如果我们输入的 SQL 语句语法不对，就会在解析器这个阶段报错。  4.</description>
    </item>
    
    <item>
      <title>操作系统笔记</title>
      <link>https://perhapzz.github.io/posts/operatingsystem/</link>
      <pubDate>Sat, 18 Feb 2023 20:59:17 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/operatingsystem/</guid>
      <description>操作系统 内核 内核作为应用连接硬件设备的桥梁，一般会提供 4 个基本能力：
 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。  大多数操作系统，把内存分成了两个区域：
 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；  应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：
内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。
Linux 的设计 Linux 内核设计的理念主要有这几个点：
 MultiTask，多任务 SMP，对称多处理 ELF，可执行文件链接格式 Monolithic Kernel，宏内核  MultiTask MultiTask 的意思是多任务，代表着 Linux 是一个多任务的操作系统。
多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：
 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。  SMP SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。
这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。
ELF ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：</description>
    </item>
    
    <item>
      <title>青训营项目复盘</title>
      <link>https://perhapzz.github.io/posts/centrareview/</link>
      <pubDate>Thu, 16 Feb 2023 22:58:06 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/centrareview/</guid>
      <description>第五届字节跳动青训营简易抖音大项目复盘总结</description>
    </item>
    
    <item>
      <title>gorm-gen 学习笔记</title>
      <link>https://perhapzz.github.io/posts/gorm-gen/</link>
      <pubDate>Thu, 26 Jan 2023 00:24:03 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/gorm-gen/</guid>
      <description>gen 通过代码生成，让 GORM 更加友好（针对复杂SQL场景也能处理），也更加安全（增加类型校验）</description>
    </item>
    
    <item>
      <title>JWT 学习笔记</title>
      <link>https://perhapzz.github.io/posts/jwt/</link>
      <pubDate>Tue, 24 Jan 2023 00:46:44 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/jwt/</guid>
      <description>JSON Web Token（JWT）是一个轻量级的认证规范，这个规范允许我们使用 JWT 在用户和服务器之间传递安全可靠的信息</description>
    </item>
    
    <item>
      <title>SRE学习笔记</title>
      <link>https://perhapzz.github.io/posts/srenote/</link>
      <pubDate>Sun, 22 Jan 2023 21:19:02 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/srenote/</guid>
      <description>sre 学习 可观测性体系的相关产品及组件 CAT OpenTelemetry SkyWalking Prometheus ELK 　ELK是Elasticsearch、Logstash、Kibana三大开源框架首字母大写简称(但是后期出现的filebeat(beats中的一种)可以用来替代logstash的数据收集功能，比较轻量级)。市面上也被成为Elastic Stack。
　Filebeat是用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或 Logstash进行索引。Filebeat的工作方式如下：启动Filebeat时，它将启动一个或多个输入，这些输入将在为日志数据指定的位置中查找。对于Filebeat所找到的每个日志，Filebeat都会启动收集器。每个收集器都读取单个日志以获取新内容，并将新日志数据发送到libbeat，libbeat将聚集事件，并将聚集的数据发送到为Filebeat配置的输出。
　Logstash是免费且开放的服务器端数据处理管道，能够从多个来源采集数据，转换数据，然后将数据发送到您最喜欢的“存储库”中。Logstash能够动态地采集、转换和传输数据，不受格式或复杂度的影响。利用Grok从非结构化数据中派生出结构，从IP地址解码出地理坐标，匿名化或排除敏感字段，并简化整体处理过程。
　Elasticsearch是Elastic Stack核心的分布式搜索和分析引擎,是一个基于Lucene、分布式、通过Restful方式进行交互的近实时搜索平台框架。Elasticsearch为所有类型的数据提供近乎实时的搜索和分析。无论您是结构化文本还是非结构化文本，数字数据或地理空间数据，Elasticsearch都能以支持快速搜索的方式有效地对其进行存储和索引。
　Kibana是一个针对Elasticsearch的开源分析及可视化平台，用来搜索、查看交互存储在Elasticsearch索引中的数据。使用Kibana，可以通过各种图表进行高级数据分析及展示。并且可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以汇总、分析和搜索重要数据日志。还可以让海量数据更容易理解。它操作简单，基于浏览器的用户界面可以快速创建仪表板（dashboard）实时显示Elasticsearch查询动态
Why ELK 　日志主要包括系统日志、应用程序日志和安全日志。系统运维和开发人员可以通过日志了解服务器软硬件信息、检查配置过程中的错误及错误发生的原因。经常分析日志可以了解服务器的负荷，性能安全性，从而及时采取措施纠正错误。
　往往单台机器的日志我们使用grep、awk等工具就能基本实现简单分析，但是当日志被分散的储存不同的设备上。如果你管理数十上百台服务器，你还在使用依次登录每台机器的传统方法查阅日志。这样是不是感觉很繁琐和效率低下。当务之急我们使用集中化的日志管理，例如：开源的syslog，将所有服务器上的日志收集汇总。集中化管理日志后，日志的统计和检索又成为一件比较麻烦的事情，一般我们使用grep、awk和wc等Linux命令能实现检索和统计，但是对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。
　一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。
完整日志系统基本特征  收集：能够采集多种来源的日志数据 传输：能够稳定的把日志数据解析过滤并传输到存储系统 存储：存储日志数据 分析：支持 UI 分析 警告：能够提供错误报告，监控机制  架构 1. beats+elasticsearch+kibana 如上图所示，该ELK框架由beats（日志分析我们通常使用filebeat）+elasticsearch+kibana构成，这个框架比较简单，入门级的框架。其中filebeat也能通过module对日志进行简单的解析和索引。并查看预建的Kibana仪表板。
该框架适合简单的日志数据，一般可以用来玩玩，生产环境建议接入logstash
2. beats+logstash+elasticsearch+kibana 该框架是在上面的框架的基础上引入了logstash，引入logstash带来的好处如下：
 通Logstash具有基于磁盘的自适应缓冲系统，该系统将吸收传入的吞吐量，从而减轻背压 从其他数据源（例如数据库，S3或消息传递队列）中提取 将数据发送到多个目的地，例如S3，HDFS或写入文件 使用条件数据流逻辑组成更复杂的处理管道  3. beats+缓存/消息队列+logstash+elasticsearch+kibana 在如上的基础上我们可以在beats和logstash中间添加一些组件redis、kafka、RabbitMQ等，添加中间件将会有如下好处： 第一，降低对日志所在机器的影响，这些机器上一般都部署着反向代理或应用服务，本身负载就很重了，所以尽可能的在这些机器上少做事； 第二，如果有很多台机器需要做日志收集，那么让每台机器都向Elasticsearch持续写入数据，必然会对Elasticsearch造成压力，因此需要对数据进行缓冲，同时，这样的缓冲也可以一定程度的保护数据不丢失； 第三，将日志数据的格式化与处理放到Indexer中统一做，可以在一处修改代码、部署，避免需要到多台机器上去修改配置
Kubernetes </description>
    </item>
    
    <item>
      <title>WSL 实操笔记</title>
      <link>https://perhapzz.github.io/posts/wsl/</link>
      <pubDate>Fri, 20 Jan 2023 00:39:18 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/wsl/</guid>
      <description>Windows Subsystem for Linux（简称WSL）是适用于Windows的Linux子系统</description>
    </item>
    
    <item>
      <title>Redis 笔记</title>
      <link>https://perhapzz.github.io/posts/redis/</link>
      <pubDate>Sun, 25 Dec 2022 22:21:20 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/redis/</guid>
      <description>Redis Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。
Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是原子性的，因为执行命令由单线程负责的，不存在并发竞争的问题。
除此之外，Redis 还支持事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制等等。
为什么用 Redis 作为 MySQL 的缓存？ 主要是因为 Redis 具备「高性能」和「高并发」两种特性。
1、Redis 具备高性能
假如用户第一次访问 MySQL 中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据缓存在 Redis 中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作 Redis 缓存就是直接操作内存，所以速度相当快。
如果 MySQL 中的对应数据改变的之后，同步改变 Redis 缓存中相应的数据即可，不过这里会有 Redis 和 MySQL 双写一致性的问题，后面我们会提到。
2、 Redis 具备高并发
单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。
所以，直接访问 Redis 能够承受的请求是远远大于直接访问 MySQL 的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。
Redis 持久化 Redis 如何实现数据不丢失？ Redis 共有三种数据持久化的方式：</description>
    </item>
    
    <item>
      <title>计算机网络笔记</title>
      <link>https://perhapzz.github.io/posts/computernetwork/</link>
      <pubDate>Sat, 24 Dec 2022 22:31:05 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/computernetwork/</guid>
      <description>计算机网络 基础篇 1. TCP/IP 网络模型有哪几层？ 应用层 我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。
应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP 等（什么东东..）。
传输层 给应用层提供网络支持的。
有两个传输协议，分别是 TCP 和 UDP。
TCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。
UDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。（那为什么不直接用TCP呢？：因为系统要求低、开销小）
网络层 传输层协议只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层（Internet Layer）。
网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。
  寻址   我们一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。
因此，需要将 IP 地址分成两种意义：</description>
    </item>
    
    <item>
      <title>纸上谈Git</title>
      <link>https://perhapzz.github.io/posts/git/</link>
      <pubDate>Sat, 17 Dec 2022 10:04:52 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/git/</guid>
      <description>Git学习笔记</description>
    </item>
    
    <item>
      <title>CodeTop 刷题笔记</title>
      <link>https://perhapzz.github.io/posts/codetop/</link>
      <pubDate>Tue, 13 Dec 2022 19:48:31 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/codetop/</guid>
      <description>用 golang 刷 codetop</description>
    </item>
    
    <item>
      <title>迈出Go RPC的一小步</title>
      <link>https://perhapzz.github.io/posts/firststepofrpc/</link>
      <pubDate>Tue, 13 Dec 2022 10:52:29 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/firststepofrpc/</guid>
      <description>记Go语言远程过程调用RPC学习过程</description>
    </item>
    
    <item>
      <title>个人博客搭建笔记</title>
      <link>https://perhapzz.github.io/posts/personalblogsetupnote/</link>
      <pubDate>Mon, 12 Dec 2022 12:52:25 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/personalblogsetupnote/</guid>
      <description>记用hugo搭建个人博客的全过程</description>
    </item>
    
    <item>
      <title>golang学习笔记</title>
      <link>https://perhapzz.github.io/posts/golang/</link>
      <pubDate>Mon, 17 Jan 2022 10:04:52 +0800</pubDate>
      
      <guid>https://perhapzz.github.io/posts/golang/</guid>
      <description>Git学习笔记</description>
    </item>
    
  </channel>
</rss>
