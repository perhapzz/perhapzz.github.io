<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>操作系统笔记 | perhapzz</title>
<meta name="keywords" content="basics">
<meta name="description" content="操作系统 内核 内核作为应用连接硬件设备的桥梁，一般会提供 4 个基本能力：
 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。  大多数操作系统，把内存分成了两个区域：
 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；  应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：
内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。
Linux 的设计 Linux 内核设计的理念主要有这几个点：
 MultiTask，多任务 SMP，对称多处理 ELF，可执行文件链接格式 Monolithic Kernel，宏内核  MultiTask MultiTask 的意思是多任务，代表着 Linux 是一个多任务的操作系统。
多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：
 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。  SMP SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。
这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。
ELF ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：">
<meta name="author" content="">
<link rel="canonical" href="https://perhapzz.github.io/posts/operatingsystem/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.2c5d624023ca4f39285dc8ad242509c565a0c0e820fc61724b2a58620dfdafbe.css" integrity="sha256-LF1iQCPKTzkoXcitJCUJxWWgwOgg/GFySypYYg39r74=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://perhapzz.github.io/favicon/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://perhapzz.github.io/favicon/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://perhapzz.github.io/favicon/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://perhapzz.github.io/favicon/apple-touch-icon.png">
<link rel="mask-icon" href="https://perhapzz.github.io/favicon/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="操作系统笔记" />
<meta property="og:description" content="操作系统 内核 内核作为应用连接硬件设备的桥梁，一般会提供 4 个基本能力：
 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。  大多数操作系统，把内存分成了两个区域：
 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；  应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：
内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。
Linux 的设计 Linux 内核设计的理念主要有这几个点：
 MultiTask，多任务 SMP，对称多处理 ELF，可执行文件链接格式 Monolithic Kernel，宏内核  MultiTask MultiTask 的意思是多任务，代表着 Linux 是一个多任务的操作系统。
多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：
 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。  SMP SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。
这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。
ELF ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://perhapzz.github.io/posts/operatingsystem/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-18T20:59:17+08:00" />
<meta property="article:modified_time" content="2023-02-18T20:59:17+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="操作系统笔记"/>
<meta name="twitter:description" content="操作系统 内核 内核作为应用连接硬件设备的桥梁，一般会提供 4 个基本能力：
 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。  大多数操作系统，把内存分成了两个区域：
 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；  应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：
内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。
Linux 的设计 Linux 内核设计的理念主要有这几个点：
 MultiTask，多任务 SMP，对称多处理 ELF，可执行文件链接格式 Monolithic Kernel，宏内核  MultiTask MultiTask 的意思是多任务，代表着 Linux 是一个多任务的操作系统。
多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：
 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。  SMP SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。
这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。
ELF ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构："/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://perhapzz.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "操作系统笔记",
      "item": "https://perhapzz.github.io/posts/operatingsystem/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "操作系统笔记",
  "name": "操作系统笔记",
  "description": "操作系统 内核 内核作为应用连接硬件设备的桥梁，一般会提供 4 个基本能力：\n 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。  大多数操作系统，把内存分成了两个区域：\n 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；  应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：\n内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。\nLinux 的设计 Linux 内核设计的理念主要有这几个点：\n MultiTask，多任务 SMP，对称多处理 ELF，可执行文件链接格式 Monolithic Kernel，宏内核  MultiTask MultiTask 的意思是多任务，代表着 Linux 是一个多任务的操作系统。\n多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：\n 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。  SMP SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。\n这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。\nELF ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：",
  "keywords": [
    "basics"
  ],
  "articleBody": "操作系统 内核 内核作为应用连接硬件设备的桥梁，一般会提供 4 个基本能力：\n 管理进程、线程，决定哪个进程、线程使用 CPU，也就是进程调度的能力； 管理内存，决定内存的分配和回收，也就是内存管理的能力； 管理硬件设备，为进程与硬件设备之间提供通信能力，也就是硬件通信能力； 提供系统调用，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。  大多数操作系统，把内存分成了两个区域：\n 内核空间，这个内存空间只有内核程序可以访问； 用户空间，这个内存空间专门给应用程序使用；  应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：\n内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。\nLinux 的设计 Linux 内核设计的理念主要有这几个点：\n MultiTask，多任务 SMP，对称多处理 ELF，可执行文件链接格式 Monolithic Kernel，宏内核  MultiTask MultiTask 的意思是多任务，代表着 Linux 是一个多任务的操作系统。\n多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：\n 对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。 对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。  SMP SMP 的意思是对称多处理，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。\n这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。\nELF ELF 的意思是可执行文件链接格式，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：\nELF 把文件分成了一个个分段，每一个段都有自己的作用。ELF 文件有两种索引，Program header table 中记录了「运行时」所需的段，而 Section header table 记录了二进制文件中各个「段的首地址」。\n那 ELF 文件怎么生成的呢？\n我们编写的代码，首先通过「编译器」编译成汇编代码，接着通过「汇编器」变成目标代码，也就是目标文件，最后通过「链接器」把多个目标文件以及调用的各种函数库链接起来，形成一个可执行文件，也就是 ELF 文件。\n那 ELF 文件是怎么被执行的呢？\n执行 ELF 文件的时候，会通过「装载器」把 ELF 文件装载到内存里，CPU 读取内存中的指令和数据，于是程序就被执行起来了。\nMonolithic Kernel Monolithic Kernel 的意思是宏内核，Linux 内核架构就是宏内核，意味着 Linux 的内核是一个完整的可执行程序，且拥有最高的权限。\n宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等，都运行在内核态。\n不过，Linux 也实现了动态加载内核模块的功能，例如大部分设备驱动是以可加载模块的形式存在的，与内核其他模块解藕，让驱动开发和驱动加载更为方便、灵活。\n与宏内核相反的是微内核，微内核架构的内核只保留最基本的能力，比如进程调度、虚拟机内存、中断等，把一些应用放到了用户空间，比如驱动程序、文件系统等。这样服务与服务之间是隔离的，单个服务出现故障或者完全攻击，也不会导致整个操作系统挂掉，提高了操作系统的稳定性和可靠性。\n微内核内核功能少，可移植性高，相比宏内核有一点不好的地方在于，由于驱动程序不在内核中，而且驱动程序一般会频繁调用底层能力的，于是驱动和硬件设备交互就需要频繁切换到内核态，这样会带来性能损耗。华为的鸿蒙操作系统的内核架构就是微内核。\n还有一种内核叫混合类型内核，它的架构有点像微内核，内核里面会有一个最小版本的内核，然后其他模块会在这个基础上搭建，然后实现的时候会跟宏内核类似，也就是把整个内核做成一个完整的程序，大部分服务都在内核中，这就像是宏内核的方式包裹着一个微内核。\nWindows 设计 当今 Windows 7、Windows 10 使用的内核叫 Windows NT，NT 全称叫 New Technology。下图是 Windows NT 的结构图片：\nWindows 和 Linux 一样，同样支持 MultiTask 和 SMP，但不同的是，Window 的内核设计是混合型内核，在上图你可以看到内核中有一个 MicroKernel 模块，这个就是最小版本的内核，而整个内核实现是一个完整的程序，含有非常多模块。\nWindows 的可执行文件的格式与 Linux 也不同，所以这两个系统的可执行文件是不可以在对方上运行的。\nWindows 的可执行文件格式叫 PE，称为可移植执行文件，扩展名通常是.exe、.dll、.sys等。\nPE 的结构你可以从下图中看到，它与 ELF 结构有一点相似。\n总结 对于内核的架构一般有这三种类型：\n 宏内核，包含多个模块，整个内核像一个完整的程序； 微内核，有一个最小版本的内核，一些模块和服务则由用户态管理； 混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；  内存管理 虚拟内存 单片机的 CPU 是直接操作内存的「物理地址」。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的。\n操作系统为每个进程分配独立的一套「虚拟地址」，虚拟地址最终怎么落到物理内存里，对进程来说是透明的。\n**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。\n于是，这里就引出了两种地址的概念：\n 我们程序所使用的内存地址叫做虚拟内存地址（Virtual Memory Address） 实际存在硬件里面的空间地址叫物理内存地址（Physical Memory Address）  操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：\n操作系统是如何管理虚拟地址与物理地址之间的关系？\n主要有两种方式，分别是内存分段和内存分页，分段是比较早提出的，我们先来看看内存分段。\n内存分段 程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。\n分段机制下，虚拟地址和物理地址是如何映射的？\n分段机制下的虚拟地址由两部分组成，段选择因子和段内偏移量。\n段选择因子和段内偏移量：\n 段选择因子就保存在段寄存器里面。段选择因子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。  在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：\n如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。\n分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：\n 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。  分段为什么会产生内存碎片的问题？\n由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以会出现外部内存碎片的问题。\n解决「外部内存碎片」的问题就是内存交换。\n可以把其他程序占用的内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着其他内存后面。\n分段为什么会导致内存交换效率低的问题？\n出现内存碎片问题时不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。\n为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。\n内存分页 要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存分页（Paging）。\n分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。\n虚拟地址与物理地址之间通过页表来映射，如下图：\n页表是存储在内存里的，内存管理单元 （MMU）就做将虚拟内存地址转换成物理地址的工作。\n而当进程访问的虚拟地址在页表中查不到时，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。\n采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。\n但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有内部内存碎片的现象。\n如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。\n更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。\n分页机制下，虚拟地址和物理地址是如何映射的？\n在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。\n总结一下，对于一个内存地址转换，其实就是这样三个步骤：\n 把虚拟内存地址，切分成页号和偏移量； 根据页号，从页表里面，查询对应的物理页号； 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。  简单的分页有什么缺陷吗？\n有空间上的缺陷。因为操作系统是可以同时运行非常多的进程的，那就意味着页表会非常的庞大。\n多级页表 要解决上面的问题，就需要采用一种叫作多级页表（Multi-Level Page Table）的解决方案。\n页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。\n对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：\n 全局页目录项 PGD（Page Global Directory） 上层页目录项 PUD（Page Upper Directory） 中间页目录项 PMD（Page Middle Directory） 页表项 PTE（Page Table Entry）  TLB 多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。\n程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。\n我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。\n在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。\n有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。\n段页式内存管理 内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。\n段页式内存管理实现的方式：\n 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；  这样，地址结构就由段号、段内页号和页内位移三部分组成。\n用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：\n段页式地址变换中要得到物理地址须经过三次内存访问：\n 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。  可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。\n总结 为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。\n每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。\n那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。\n那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。\n内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。\n于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。\n再来，为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。\nLinux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。\n另外，Linux 系统中虚拟空间分布可分为用户态和内核态两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。\nLinux 进程的内存分布 在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：\n 32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间； 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。  内核空间与用户空间的区别：\n 进程在用户态时，只能访问用户空间内存； 只有进入内核态后，才可以访问内核空间的内存；  虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。\n用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：\n通过这张图你可以看到，用户空间内存从低到高分别是 6 种不同的内存段：\n 代码段，包括二进制可执行代码； 数据段，包括已初始化的静态常量和全局变量； BSS 段，包括未初始化的静态变量和全局变量； 堆段，包括动态分配的内存，从低地址开始向上增长； 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关 (opens new window)）； 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；  在这 6 个内存段中，堆和文件映射段的内存是动态分配的。\n内存满了，内存分配过程 应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。\n当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生缺页中断，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。\n如果没有空闲的物理内存，那么内核就会开始进行回收内存的工作，回收的方式主要是两种：直接内存回收和后台内存回收。\n 后台内存回收（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。 直接内存回收（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。  如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。\nOOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。\n申请物理内存的过程如下图：\n哪些内存可以被回收？ 主要有两类内存可以被回收，而且它们的回收方式也不同。\n 文件页（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存。 匿名页（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。  文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：\n active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页； inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；  越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。\nSwap 机制 当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间会被临时保存到磁盘，等到那些程序要运行时，再从磁盘中恢复保存的数据到内存中。\n另外，当内存使用存在压力的时候，会开始触发内存回收行为，会把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。\n这种，将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是 Swap 机制负责的。\nSwap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：\n 换出（Swap Out）：是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存； 换入（Swap In）：是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；  Swap 换入换出的过程如下图：\n使用 Swap 机制优点是，应用程序实际可以使用的内存空间将远远超过系统的物理内存。由于硬盘空间的价格远比内存要低，因此这种方式无疑是经济实惠的。当然，频繁地读写硬盘，会显著降低操作系统的运行速率，这也是 Swap 的弊端。\nLinux 中的 Swap 机制会在内存不足和内存闲置的场景下触发：\n 内存不足：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会阻塞当前申请内存的进程。 内存闲置：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程（kSwapd），我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在内存低于一定水位时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。  Linux 提供了两种不同的方法启用 Swap，分别是 Swap 分区（Swap Partition）和 Swap 文件（Swapfile）：\n Swap 分区是硬盘上的独立区域，该区域只会用于交换分区，其他的文件不能存储在该区域上，我们可以使用 swapon -s 命令查看当前系统上的交换分区； Swap 文件是文件系统中的特殊文件，它与文件系统中的其他文件也没有太多的区别；  Swap 换入换出的是什么类型的内存？\n内核缓存的文件数据，因为都有对应的磁盘文件，所以在回收文件数据的时候， 直接写回到对应的文件就可以了。\n但是像进程的堆、栈数据等，它们是没有实际载体，这部分内存被称为匿名页。而且这部分内存很可能还要再次被访问，所以不能直接释放内存，于是就需要有一个能保存匿名页的磁盘载体，这个载体就是 Swap 分区。\n匿名页回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。\n回收内存带来的性能影响 在前面我们知道了回收内存有两种方式。\n 一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。 一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。  可被回收的内存类型有文件页和匿名页：\n 文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。 匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。  回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。\n针对回收内存导致的性能影响常见的解决方式 调整文件页和匿名页的回收倾向 从文件页和匿名页的回收操作来看，文件页的回收操作对系统的影响相比匿名页的回收操作会少一点，因为文件页对于干净页回收是不会发生磁盘 I/O 的，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O。\n在回收内存的时候，会更倾向于文件页的回收，可以提升性能，这个有参数在 Linux 里调整。\n尽早触发 kswapd 内核线程异步回收内存 什么条件下才能触发 kswapd 内核线程回收内存呢？\n内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是：\n 页最小阈值（pages_min）； 页低阈值（pages_low）； 页高阈值（pages_high）；  这三个内存阈值会划分为四种内存使用情况，如下图：\n 图中橙色部分：如果剩余内存（pages_free）在页低阈值（pages_low）和页最小阈值（pages_min）之间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值（pages_high）为止。虽然会触发内存回收，但是不会阻塞应用程序，因为两者关系是异步的。 图中红色部分：如果剩余内存（pages_free）小于页最小阈值（pages_min），说明用户可用内存都耗尽了，此时就会触发直接内存回收，这时应用程序就会被阻塞，因为两者关系是同步的。  也就是说 kswapd 的活动空间只有 pages_low 与 pages_min 之间的这段区域，如果剩余内存低于了 pages_min 会触发直接内存回收，高于了 pages_high 又不会唤醒 kswapd。\n如何保护一个进程不被 OOM 杀掉 Linux 到底是根据 oom_badness() 得分的结果受下面这两个方面影响：\n 第一，进程已经使用的物理内存页面数。 第二，每个进程的 OOM 校准值 oom_score_adj。它是可以通过 /proc/[pid]/oom_score_adj 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。  计算方法如下： $$ 得分=进程已经使用的物理内存页面数+\\frac{OOM\\ 校准值 * 系统总的可用页面数}{1000} $$ 我们可以将一些很重要的系统服务的 oom_score_adj 配置为 -1000，比如 sshd，因为这些系统服务一旦被杀掉，我们就很难再登陆进系统了。但是不建议将我们自己的业务程序的 oom_score_adj 设置为 -1000，因为业务程序一旦发生了内存泄漏，而它又不能被杀掉，这就会导致随着它的内存开销变大，OOM killer 不停地被唤醒，从而把其他进程一个个给杀掉。\n进程管理 进程 我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」（Process）。\n在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。\n上图中各个状态的意义：\n 运行状态（Running）：该时刻进程占用 CPU； 就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行； 阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；  当然，进程还有另外两个基本状态：\n 创建状态（new）：进程正在被创建时的状态； 结束状态（Exit）：进程正在从系统中消失时的状态；  于是，一个完整的进程状态的变迁如下图：\n再来详细说明一下进程的状态变迁：\n NULL - 创建状态：一个新进程被创建时的第一个状态； 创建状态 - 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的； 就绪态 - 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程； 运行状态 - 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理； 运行状态 - 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行； 运行状态 - 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件； 阻塞状态 - 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；  为了防止阻塞中的进程一直占用物理内存空间，在虚拟内存管理的操作系统中通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。\n挂起状态可以分为两种：\n 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；  导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：\n 通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。 用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程；  进程的控制结构 在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的。PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。\nPCB 具体包含什么信息呢？\n进程描述信息：\n 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；  进程控制和管理信息：\n 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级；  资源分配清单：\n 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。  CPU 相关信息：\n CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。  每个 PCB 通常是通过链表的方式进行组织（也有索引方式），把具有相同状态的进程链在一起，组成各种队列。比如：\n 将所有处于就绪状态的进程链在一起，称为就绪队列； 把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列； 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。  进程的控制 01 创建进程\n操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。\n创建进程的过程如下：\n 申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等； 为该进程分配运行时所必需的资源，比如内存资源； 将 PCB 插入到就绪队列，等待被调度运行；  02 终止进程\n进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。\n当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。\n终止进程的过程如下：\n 查找需要终止的进程的 PCB； 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程； 如果其还有子进程，则应将该进程的子进程交给 1 号进程接管； 将该进程所拥有的全部资源都归还给操作系统； 将其从 PCB 所在队列中删除；  03 阻塞进程\n当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。\n阻塞进程的过程如下：\n 找到将要被阻塞进程标识号对应的 PCB； 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行； 将该 PCB 插入到阻塞队列中去；  04 唤醒进程\n进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。\n如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。\n唤醒进程的过程如下：\n 在该事件的阻塞队列中找到相应进程的 PCB； 将其从阻塞队列中移出，并置其状态为就绪状态； 把该 PCB 插入到就绪队列中，等待调度程序调度；  进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。\n进程的上下文切换 各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。\n进程是由内核管理和调度的，所以进程的切换只能发生在内核态。\n所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行。\n线程 线程是进程当中的一条执行流程，线程之间可以并发运行且共享相同的地址空间。\n同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。\n线程的优缺点？\n线程的优点：\n 一个进程中可以同时存在多个线程； 各个线程之间可以并发执行； 各个线程之间可以共享地址空间和文件等资源；  线程的缺点：\n 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃，具体分析原因可以看这篇：线程崩溃了，进程也会崩溃吗？ (opens new window)）。  线程的上下文切换 在前面我们知道了，线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。\n所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。\n对于线程和进程，我们可以这么理解：\n 当进程只有一个线程时，可以认为进程就等于线程； 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；  另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。\n线程上下文切换的是什么？\n这还得看线程是不是属于同一个进程：\n 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；  所以，线程的上下文切换相比进程，开销要小很多。\n线程的实现 主要有三种线程的实现方式：\n 用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理 内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程 轻量级进程（LightWeight Process）：在内核中来支持用户线程  用户线程 用户线程是基于用户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。\n所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。\n优点：\n TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统； 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；  缺点：\n 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢。  内核线程 内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。\n优点：\n 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行； 分配给线程，多线程的进程获得更多的 CPU 运行时间；  缺点：\n 在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB； 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大。  轻量级进程 轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。\n线程与进程的比较 线程与进程的比较如下：\n 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销；  对于，线程相比进程能减少开销，体现在：\n 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；  所以，不管是时间效率，还是空间效率线程比进程都要高。\n调度 选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（scheduler）。\n调度时机 在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。\n比如，以下状态的变化都会触发操作系统的调度：\n 从就绪态 - 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行； 从运行态 - 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行； 从运行态 - 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；  因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。\n另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：\n 非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。 抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。  调度原则 原则一：如果运行的程序，发生了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。\n原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。\n原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。\n原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。\n原则五：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。\n针对上面的五种调度原则，总结成如下：\n CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率； 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量； 周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好； 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。  调度算法 单核 CPU 系统中常见的调度算法 01 先来先服务调度算法\n非抢占式的先来先服务（First Come First Serve, FCFS）算法\n每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n02 最短作业优先调度算法\n最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。\n03 高响应比优先调度算法\n高响应比优先 （Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。\n每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式： $$ 优先权 = \\frac{等待时间\\ +\\ 要求服务时间}{要求服务时间} $$ 从上面的公式，可以发现：\n 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行； 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；  因为进程要求服务时间不可预知，所以高响应比优先调度算法是实现不了的。\n04 时间片轮转调度算法\n每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。\n 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；  另外，时间片的长度就是一个很关键的点：\n 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长。  一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值。\n最为公平、使用最为广泛。\n05 最高优先级调度算法\n从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法\n进程的优先级可以分为，静态优先级和动态优先级：\n 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。  该算法也有两种处理优先级高的方法，非抢占式和抢占式：\n 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。  但是依然有缺点，可能会导致低优先级的进程永远不会运行。\n06 多级反馈队列调度算法\n多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。\n 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；  如何工作的：\n 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；  可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。\n进程之间的通信方式 管道 遵循先进先出原则，不支持 lseek 之类的文件定位操作。\n匿名管道：它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。\n命名管道：它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。\n不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核中。**管道这种通信方式效率低，不适合进程间频繁地交换数据。\n消息队列 消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。\n消息队列不适合比较大数据的传输，消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销。\n共享内存 共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。\n信号量 信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。\n信号 对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。\n信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。\n1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。\n2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。\n3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。\n有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。\nSocket 前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。\n本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。\n总结 由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。\nLinux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。\n匿名管道顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「|」竖线就是匿名管道，通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来匿名管道是只能用于存在父子关系的进程间通信，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。\n命名管道突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。\n消息队列克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。\n共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，它直接分配一个共享空间，每个进程都可以直接访问，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有最快的进程间通信方式之名。但是便捷高效的共享内存通信，带来新的问题，多进程竞争同个共享资源会造成数据的错乱。\n那么，就需要信号量来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。信号量不仅可以实现访问的互斥性，还可以实现进程间的同步，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 P 操作和 V 操作。\n与信号量名字很相似的叫信号，它俩名字虽然相似，但功能一点儿都不一样。信号是异步通信机制，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SIGSTOP，这是为了方便我们能在任何时候结束或停止某个进程。\n前面说到的通信机制，都是工作于同一台主机，如果要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。\n以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？\n同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：\n 互斥的方式，可保证任意时刻只有一个线程访问共享资源； 同步的方式，可保证线程 A 应在线程 B 之前执行；  互斥和同步 当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，称为竞争条件（race condition）。\n由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。\n互斥的概念 互斥（mutualexclusion），就是保证一个线程在临界区执行时，其他线程应该被阻止进入临界区。\n另外，互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使用互斥的方式来避免资源竞争造成的资源混乱。\n同步的概念 同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。\n注意，同步与互斥是两种不同的概念：\n 同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等； 互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」；  互斥与同步的实现和使用 为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：\n 锁：加锁、解锁操作； 信号量：P、V 操作；  这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步。\n忙等待锁 先介绍现代 CPU 体系结构提供的特殊原子操作指令 —— 测试和置位（Test-and-Set）指令。\n测试并设置指令做了下述事情:\n 把 old_ptr 更新为 new 的新值 返回 old_ptr 的旧值；  关键是这些代码是原子执行。\n我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下：\n我们来确保理解为什么这个锁能工作：\n 第一个场景是，首先假设一个线程在运行，调用 lock()，没有其他线程持有锁，所以 flag 是 0。当调用 TestAndSet(flag, 1) 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 unlock() 将 flag 清理为 0。 第二种场景是，当某一个线程已经持有锁（即 flag 为1）。本线程调用 lock()，然后调用 TestAndSet(flag, 1)，这一次返回 1。只要另一个线程一直持有锁，TestAndSet() 会重复返回 1，本线程会一直忙等。当 flag 终于被改为 0，本线程会调用 TestAndSet()，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。  很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁（spin lock）。\n无等待锁 无等待锁把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。\n信号量 信号量是操作系统提供的一种协调共享资源访问的方法。\n通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。\n另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：\n P 操作：将 sem 减 1，相减后，如果 sem ，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞； V 操作：将 sem 加 1，相加后，如果 sem ，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；  P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。\n生产者-消费者问题 生产者-消费者问题描述：\n 生产者在生成数据后，放在一个缓冲区中； 消费者从缓冲区取出数据处理； 任何时刻，只能有一个生产者或消费者可以访问缓冲区；  那么我们需要三个信号量，分别是：\n 互斥信号量 mutex：用于互斥访问缓冲区，初始化值为 1； 资源信号量 fullBuffers：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）； 资源信号量 emptyBuffers：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；  如果消费者线程一开始执行 P(fullBuffers)，由于信号量 fullBuffers 初始值为 0，则此时 fullBuffers 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。\n接着，轮到生产者执行 P(emptyBuffers)，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 V(fullBuffers) ，信号量 fullBuffers 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。\n消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。\n死锁 死锁：两个线程都在等待对方释放锁\n死锁只有同时满足以下四个条件才会发生：\n 互斥条件：多个线程不能同时使用同一个资源 持有并等待条件：线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1 不可剥夺条件：当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取 环路等待条件：两个线程获取资源的顺序构成了环形链  避免死锁问题的发生 使用资源有序分配法，来破环环路等待条件。\n常见的锁 最底层的两种就是「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基。简单来说，遇到加锁失败，互斥锁会切走，自旋锁会再等等。\n互斥锁 互斥锁加锁失败后，线程会释放 CPU ，给其他线程；对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。\n自旋锁 自旋锁加锁失败后，线程会忙等待，直到它拿到锁；自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换。\n需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n读写锁 读写锁由「读锁」和「写锁」两部分构成，其工作原理是：\n 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。  读写锁在读多写少的场景，能发挥出优势。\n悲观锁 多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。\n乐观锁 乐观锁全程并没有加锁，所以它也叫无锁编程。\n调度算法 进程调度算法 当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。\n什么时候会发生 CPU 调度呢？通常有以下情况：\n 当进程从运行状态转到等待状态； 当进程从运行状态转到就绪状态； 当进程从等待状态转到就绪状态； 当进程从运行状态转到终止状态；  其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。\n非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。\n抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。\n第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。\n第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。\n进程调度算法前面已经学习过了，这边简单再重复一遍。\n先来先服务调度算法 非抢占式的先来先服务（First Come First Severd, FCFS）算法：每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n最短作业优先调度算法 最短作业优先（*Shortest Job First, SJF*）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行。\n高响应比优先调度算法 高响应比优先 （Highest Response Ratio Next, HRRN）调度算法：每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行 $$ 优先权=\\frac{等待时间\\ +\\ 要求服务时间}{要求服务时间} $$ 因为不知道要求服务时间大概为多少，所以是比较理想的调度算法。\n时间片轮转调度算法 时间片轮转（Round Robin, RR）调度算法：每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。\n最高优先级调度算法 最高优先级（Highest Priority First，HPF）调度算法：从就绪队列中选择最高优先级的进程进行运行。\n多级反馈队列调度算法 多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。\n 算法设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；  内存页面置换算法 缺页异常（缺页中断）：当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。\n它与一般中断的主要区别在于：\n 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。  缺页中断的处理流程如下图：\n第 4 步中如果找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。\n页表项通常有如下图的字段：\n 状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。 访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。 修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。 硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。  虚拟内存的管理整个流程：\n页面置换算法的功能是，当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。\n页面置换算法有如下几种：\n最佳页面置换算法 最佳页面置换算法基本思路是置换在「未来」最长时间不访问的页面。\n这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。\n最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。\n先进先出置换算法 先进先出置换基本思路是选择在内存驻留时间很长的页面进行中置换。\n最近最久未使用的置换算法 最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。\n效果虽好，但是要维护所有页面的链表，开销比较大。\n时钟页面置换算法 时钟页面置换算法跟 LRU 近似，又是对 FIFO 的一种改进。算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。\n当发生缺页中断时，算法首先检查表针指向的页面：\n 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置； 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；  最不常用算法 最不常用（LFU）算法：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。\n磁盘调度算法 磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。\n先来先服务算法 先来先服务（First-Come，First-Served，FCFS），顾名思义，先到来的请求，先被服务。\n最短寻道时间 最短寻道时间优先（Shortest Seek First，SSF）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求。\n但这个算法可能存在某些请求的饥饿，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里产生饥饿的原因是磁头在一小块区域来回移动。\n扫描算法 扫描（Scan）算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。\n扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。\n循环扫描算法 循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。\n循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。\nLOOK 与 C-LOOK算法 LOOK 算法：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。\nC-LOOK算法：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。\n网络系统 零拷贝 DMA 技术 没有 DMA 技术前，I/O 的过程是这样的：\n CPU 发出对应的指令给磁盘控制器，然后返回； 磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断； CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。  可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。\nDMA 技术简单理解就是，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。\n具体过程：\n 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态； 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务； DMA 进一步将 I/O 请求发送给磁盘； 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满； DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务； 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU； CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；  可以看到， CPU 不再参与「将数据从磁盘控制器缓冲区搬运到内核空间」的工作，这部分工作全程由 DMA 完成。但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。\n传统的文件传输 如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。\n传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。\n首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。\n上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。\n其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：\n 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。  要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。\nI/O 多路复用 ",
  "wordCount" : "1558",
  "inLanguage": "en",
  "datePublished": "2023-02-18T20:59:17+08:00",
  "dateModified": "2023-02-18T20:59:17+08:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://perhapzz.github.io/posts/operatingsystem/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "perhapzz",
    "logo": {
      "@type": "ImageObject",
      "url": "https://perhapzz.github.io/favicon/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://perhapzz.github.io" accesskey="h" title="perhapzz (Alt + H)">perhapzz</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://perhapzz.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://perhapzz.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://perhapzz.github.io">Home</a>&nbsp;»&nbsp;<a href="https://perhapzz.github.io/posts/">Posts</a></div>
    <h1 class="post-title">
      操作系统笔记
    </h1>
    <div class="post-meta"><span title='2023-02-18 20:59:17 +0800 CST'>February 18, 2023</span>

</div>
  </header> 
  <div class="post-content"><h1 id="操作系统">操作系统<a hidden class="anchor" aria-hidden="true" href="#操作系统">#</a></h1>
<h2 id="内核">内核<a hidden class="anchor" aria-hidden="true" href="#内核">#</a></h2>
<p><strong>内核作为应用连接硬件设备的桥梁</strong>，一般会提供 4 个基本能力：</p>
<ul>
<li><strong>管理进程、线程</strong>，决定哪个进程、线程使用 CPU，也就是进程调度的能力；</li>
<li><strong>管理内存</strong>，决定内存的分配和回收，也就是内存管理的能力；</li>
<li><strong>管理硬件设备</strong>，为进程与硬件设备之间提供通信能力，也就是硬件通信能力；</li>
<li><strong>提供系统调用</strong>，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口。</li>
</ul>
<p>大多数操作系统，把内存分成了两个区域：</p>
<ul>
<li><strong>内核空间</strong>，这个内存空间只有内核程序可以访问；</li>
<li><strong>用户空间</strong>，这个内存空间专门给应用程序使用；</li>
</ul>
<p>应用程序如果需要进入内核空间，就需要通过系统调用，下面来看看系统调用的过程：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181117471.png" alt="img"  />
</p>
<p>内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后， CPU 会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把 CPU 执行权限交回给用户程序，回到用户态继续工作。</p>
<h3 id="linux-的设计">Linux 的设计<a hidden class="anchor" aria-hidden="true" href="#linux-的设计">#</a></h3>
<p>Linux 内核设计的理念主要有这几个点：</p>
<ul>
<li><em>MultiTask</em>，多任务</li>
<li><em>SMP</em>，对称多处理</li>
<li><em>ELF</em>，可执行文件链接格式</li>
<li><em>Monolithic Kernel</em>，宏内核</li>
</ul>
<h4 id="multitask">MultiTask<a hidden class="anchor" aria-hidden="true" href="#multitask">#</a></h4>
<p>MultiTask 的意思是<strong>多任务</strong>，代表着 Linux 是一个多任务的操作系统。</p>
<p>多任务意味着可以有多个任务同时执行，这里的「同时」可以是并发或并行：</p>
<ul>
<li>对于单核 CPU 时，可以让每个任务执行一小段时间，时间到就切换另外一个任务，从宏观角度看，一段时间内执行了多个任务，这被称为并发。</li>
<li>对于多核 CPU 时，多个任务可以同时被不同核心的 CPU 同时执行，这被称为并行。</li>
</ul>
<h4 id="smp">SMP<a hidden class="anchor" aria-hidden="true" href="#smp">#</a></h4>
<p>SMP 的意思是<strong>对称多处理</strong>，代表着每个 CPU 的地位是相等的，对资源的使用权限也是相同的，多个 CPU 共享同一个内存，每个 CPU 都可以访问完整的内存和硬件资源。</p>
<p>这个特点决定了 Linux 操作系统不会有某个 CPU 单独服务应用程序或内核程序，而是每个程序都可以被分配到任意一个 CPU 上被执行。</p>
<h4 id="elf">ELF<a hidden class="anchor" aria-hidden="true" href="#elf">#</a></h4>
<p>ELF 的意思是<strong>可执行文件链接格式</strong>，它是 Linux 操作系统中可执行文件的存储格式，你可以从下图看到它的结构：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181129041.png" alt="ELF 文件格式"  />
</p>
<p>ELF 把文件分成了一个个分段，每一个段都有自己的作用。ELF 文件有两种索引，Program header table 中记录了「运行时」所需的段，而 Section header table 记录了二进制文件中各个「段的首地址」。</p>
<p><strong>那 ELF 文件怎么生成的呢？</strong></p>
<p>我们编写的代码，首先通过「编译器」编译成汇编代码，接着通过「汇编器」变成目标代码，也就是目标文件，最后通过「链接器」把多个目标文件以及调用的各种函数库链接起来，形成一个可执行文件，也就是 ELF 文件。</p>
<p><strong>那 ELF 文件是怎么被执行的呢？</strong></p>
<p>执行 ELF 文件的时候，会通过「装载器」把 ELF 文件装载到内存里，CPU 读取内存中的指令和数据，于是程序就被执行起来了。</p>
<h4 id="monolithic-kernel">Monolithic Kernel<a hidden class="anchor" aria-hidden="true" href="#monolithic-kernel">#</a></h4>
<p>Monolithic Kernel 的意思是<strong>宏内核</strong>，Linux 内核架构就是宏内核，意味着 Linux 的内核是一个完整的可执行程序，且拥有最高的权限。</p>
<p>宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等，都运行在内核态。</p>
<p>不过，Linux 也实现了动态加载内核模块的功能，例如大部分设备驱动是以可加载模块的形式存在的，与内核其他模块解藕，让驱动开发和驱动加载更为方便、灵活。</p>
<p>与宏内核相反的是<strong>微内核</strong>，微内核架构的内核只保留最基本的能力，比如进程调度、虚拟机内存、中断等，把一些应用放到了用户空间，比如驱动程序、文件系统等。这样服务与服务之间是隔离的，单个服务出现故障或者完全攻击，也不会导致整个操作系统挂掉，提高了操作系统的稳定性和可靠性。</p>
<p>微内核内核功能少，可移植性高，相比宏内核有一点不好的地方在于，由于驱动程序不在内核中，而且驱动程序一般会频繁调用底层能力的，于是驱动和硬件设备交互就需要频繁切换到内核态，这样会带来性能损耗。华为的鸿蒙操作系统的内核架构就是微内核。</p>
<p>还有一种内核叫<strong>混合类型内核</strong>，它的架构有点像微内核，内核里面会有一个最小版本的内核，然后其他模块会在这个基础上搭建，然后实现的时候会跟宏内核类似，也就是把整个内核做成一个完整的程序，大部分服务都在内核中，这就像是宏内核的方式包裹着一个微内核。</p>
<h3 id="windows-设计">Windows 设计<a hidden class="anchor" aria-hidden="true" href="#windows-设计">#</a></h3>
<p>当今 Windows 7、Windows 10 使用的内核叫 Windows NT，NT 全称叫 New Technology。下图是 Windows NT 的结构图片：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181411264.png" alt="Windows NT 的结构"  />
</p>
<p>Windows 和 Linux 一样，同样支持 MultiTask 和 SMP，但不同的是，<strong>Window 的内核设计是混合型内核</strong>，在上图你可以看到内核中有一个 <em>MicroKernel</em> 模块，这个就是最小版本的内核，而整个内核实现是一个完整的程序，含有非常多模块。</p>
<p>Windows 的可执行文件的格式与 Linux 也不同，所以这两个系统的可执行文件是不可以在对方上运行的。</p>
<p>Windows 的可执行文件格式叫 PE，称为<strong>可移植执行文件</strong>，扩展名通常是<code>.exe</code>、<code>.dll</code>、<code>.sys</code>等。</p>
<p>PE 的结构你可以从下图中看到，它与 ELF 结构有一点相似。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181412541.png" alt="PE 文件结构"  />
</p>
<h3 id="总结">总结<a hidden class="anchor" aria-hidden="true" href="#总结">#</a></h3>
<p>对于内核的架构一般有这三种类型：</p>
<ul>
<li>宏内核，包含多个模块，整个内核像一个完整的程序；</li>
<li>微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；</li>
<li>混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；</li>
</ul>
<h2 id="内存管理">内存管理<a hidden class="anchor" aria-hidden="true" href="#内存管理">#</a></h2>
<h3 id="虚拟内存">虚拟内存<a hidden class="anchor" aria-hidden="true" href="#虚拟内存">#</a></h3>
<p><strong>单片机的 CPU 是直接操作内存的「物理地址」</strong>。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的。</p>
<p>操作系统为每个进程分配独立的一套「<strong>虚拟地址</strong>」，虚拟地址最终怎么落到物理内存里，对进程来说是透明的。</p>
<p>**操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。**如果程序要访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。</p>
<p>于是，这里就引出了两种地址的概念：</p>
<ul>
<li>我们程序所使用的内存地址叫做<strong>虚拟内存地址</strong>（<em>Virtual Memory Address</em>）</li>
<li>实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（<em>Physical Memory Address</em>）</li>
</ul>
<p>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181418165.png" alt="img"  />
</p>
<p><strong>操作系统是如何管理虚拟地址与物理地址之间的关系？</strong></p>
<p>主要有两种方式，分别是<strong>内存分段和内存分页</strong>，分段是比较早提出的，我们先来看看内存分段。</p>
<h3 id="内存分段">内存分段<a hidden class="anchor" aria-hidden="true" href="#内存分段">#</a></h3>
<p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。<strong>不同的段是有不同的属性的，所以就用分段（<em>Segmentation</em>）的形式把这些段分离出来。</strong></p>
<p><strong>分段机制下，虚拟地址和物理地址是如何映射的？</strong></p>
<p>分段机制下的虚拟地址由两部分组成，<strong>段选择因子</strong>和<strong>段内偏移量</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181516085.png" alt="img"  />
</p>
<p>段选择因子和段内偏移量：</p>
<ul>
<li><strong>段选择因子</strong>就保存在段寄存器里面。段选择因子里面最重要的是<strong>段号</strong>，用作段表的索引。<strong>段表</strong>里面保存的是这个<strong>段的基地址、段的界限和特权等级</strong>等。</li>
<li>虚拟地址中的<strong>段内偏移量</strong>应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。</li>
</ul>
<p>在上面，知道了虚拟地址是通过<strong>段表</strong>与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181527189.png" alt="img"  />
</p>
<p>如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。</p>
<p>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：</p>
<ul>
<li>第一个就是<strong>内存碎片</strong>的问题。</li>
<li>第二个就是<strong>内存交换的效率低</strong>的问题。</li>
</ul>
<p><strong>分段为什么会产生内存碎片的问题？</strong></p>
<p>由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以<strong>会出现外部内存碎片</strong>的问题。</p>
<p>解决「外部内存碎片」的问题就是<strong>内存交换</strong>。</p>
<p>可以把其他程序占用的内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着其他内存后面。</p>
<p><strong>分段为什么会导致内存交换效率低的问题？</strong></p>
<p>出现内存碎片问题时不得不重新 <code>Swap</code> 内存区域，这个过程会产生性能瓶颈。<strong>如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。</strong></p>
<p>为了解决内存分段的「外部内存碎片和内存交换效率低」的问题，就出现了内存分页。</p>
<h3 id="内存分页">内存分页<a hidden class="anchor" aria-hidden="true" href="#内存分页">#</a></h3>
<p>要解决这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是<strong>内存分页</strong>（<em>Paging</em>）。</p>
<p><strong>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小</strong>。这样一个连续并且尺寸固定的内存空间，我们叫<strong>页</strong>（<em>Page</em>）。在 Linux 下，每一页的大小为 <code>4KB</code>。</p>
<p>虚拟地址与物理地址之间通过<strong>页表</strong>来映射，如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181544703.png" alt="img"  />
</p>
<p>页表是存储在内存里的，<strong>内存管理单元</strong> （<em>MMU</em>）就做将虚拟内存地址转换成物理地址的工作。</p>
<p>而当进程访问的虚拟地址在页表中查不到时，系统会产生一个<strong>缺页异常</strong>，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</p>
<p><strong>采用了分页，页与页之间是紧密排列的，所以不会有外部碎片。</strong></p>
<p>但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对<strong>内存分页机制会有内部内存碎片</strong>的现象。</p>
<p>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为<strong>换出</strong>（<em>Swap Out</em>）。一旦需要的时候，再加载进来，称为<strong>换入</strong>（<em>Swap In</em>）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，<strong>内存交换的效率就相对比较高。</strong></p>
<p>更进一步地，分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是<strong>只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。</strong></p>
<p><strong>分页机制下，虚拟地址和物理地址是如何映射的？</strong></p>
<p>在分页机制下，虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，<strong>页表</strong>包含物理页每页所在<strong>物理内存的基地址</strong>，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181551071.png" alt="img"  />
</p>
<p>总结一下，对于一个内存地址转换，其实就是这样三个步骤：</p>
<ul>
<li>把虚拟内存地址，切分成页号和偏移量；</li>
<li>根据页号，从页表里面，查询对应的物理页号；</li>
<li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li>
</ul>
<p><strong>简单的分页有什么缺陷吗？</strong></p>
<p>有空间上的缺陷。因为操作系统是可以同时运行非常多的进程的，那就意味着页表会非常的庞大。</p>
<h4 id="多级页表">多级页表<a hidden class="anchor" aria-hidden="true" href="#多级页表">#</a></h4>
<p>要解决上面的问题，就需要采用一种叫作<strong>多级页表</strong>（<em>Multi-Level Page Table</em>）的解决方案。</p>
<p><strong>页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项</strong>（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。</p>
<p>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：</p>
<ul>
<li>全局页目录项 PGD（<em>Page Global Directory</em>）</li>
<li>上层页目录项 PUD（<em>Page Upper Directory</em>）</li>
<li>中间页目录项 PMD（<em>Page Middle Directory</em>）</li>
<li>页表项 PTE（<em>Page Table Entry</em>）</li>
</ul>
<h4 id="tlb">TLB<a hidden class="anchor" aria-hidden="true" href="#tlb">#</a></h4>
<p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。</p>
<p>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。</p>
<p>我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB（<em>Translation Lookaside Buffer</em>） ，通常称为页表缓存、转址旁路缓存、快表等。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181605324.png" alt="img"  />
</p>
<p>在 CPU 芯片里面，封装了内存管理单元（<em>Memory Management Unit</em>）芯片，它用来完成地址转换和 TLB 的访问与交互。</p>
<p>有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。</p>
<h3 id="段页式内存管理">段页式内存管理<a hidden class="anchor" aria-hidden="true" href="#段页式内存管理">#</a></h3>
<p>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为<strong>段页式内存管理</strong>。</p>
<p>段页式内存管理实现的方式：</p>
<ul>
<li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；</li>
<li>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；</li>
</ul>
<p>这样，地址结构就由<strong>段号、段内页号和页内位移</strong>三部分组成。</p>
<p>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181607169.png" alt="img"  />
</p>
<p>段页式地址变换中要得到物理地址须经过三次内存访问：</p>
<ul>
<li>第一次访问段表，得到页表起始地址；</li>
<li>第二次访问页表，得到物理页号；</li>
<li>第三次将物理页号与页内位移组合，得到物理地址。</li>
</ul>
<p>可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。</p>
<h3 id="总结-1">总结<a hidden class="anchor" aria-hidden="true" href="#总结-1">#</a></h3>
<p>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套<strong>虚拟地址空间</strong>，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。</p>
<p>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过<strong>内存交换</strong>技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。</p>
<p>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。</p>
<p>那么对于虚拟地址与物理地址的映射关系，可以有<strong>分段</strong>和<strong>分页</strong>的方式，同时两者结合都是可以的。</p>
<p>内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。</p>
<p>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 <code>4KB</code>。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。</p>
<p>再来，为了解决简单分页产生的页表过大的问题，就有了<strong>多级页表</strong>，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的<strong>局部性原理</strong>，在 CPU 芯片中加入了 <strong>TLB</strong>，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。</p>
<p><strong>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理</strong>。于是 Linux 就把所有段的基地址设为 <code>0</code>，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。</p>
<p>另外，Linux 系统中虚拟空间分布可分为<strong>用户态</strong>和<strong>内核态</strong>两部分，其中用户态的分布：代码段、全局变量、BSS、函数栈、堆内存、映射区。</p>
<h3 id="linux-进程的内存分布">Linux 进程的内存分布<a hidden class="anchor" aria-hidden="true" href="#linux-进程的内存分布">#</a></h3>
<p>在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302202102844.jpeg" alt="图片"  />
</p>
<ul>
<li><code>32</code> 位系统的内核空间占用 <code>1G</code>，位于最高处，剩下的 <code>3G</code> 是用户空间；</li>
<li><code>64</code> 位系统的内核空间和用户空间都是 <code>128T</code>，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。</li>
</ul>
<p>内核空间与用户空间的区别：</p>
<ul>
<li>进程在用户态时，只能访问用户空间内存；</li>
<li>只有进入内核态后，才可以访问内核空间的内存；</li>
</ul>
<p>虽然每个进程都各自有独立的虚拟内存，但是<strong>每个虚拟内存中的内核地址，其实关联的都是相同的物理内存</strong>。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302202103097.jpeg" alt="图片"  />
</p>
<p>用户空间分布的情况，以 32 位系统为例，我画了一张图来表示它们的关系：</p>
<p>通过这张图你可以看到，用户空间内存从<strong>低到高</strong>分别是 6 种不同的内存段：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302202103812.png" alt="虚拟内存空间划分"  />
</p>
<ul>
<li>代码段，包括二进制可执行代码；</li>
<li>数据段，包括已初始化的静态常量和全局变量；</li>
<li>BSS 段，包括未初始化的静态变量和全局变量；</li>
<li>堆段，包括动态分配的内存，从低地址开始向上增长；</li>
<li>文件映射段，包括动态库、共享内存等，从低地址开始向上增长（<a href="http://lishiwen4.github.io/linux/linux-process-memory-location">跟硬件和内核版本有关 (opens new window)</a>）；</li>
<li>栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 <code>8 MB</code>。当然系统也提供了参数，以便我们自定义大小；</li>
</ul>
<p>在这 6 个内存段中，堆和文件映射段的内存是动态分配的。</p>
<h3 id="内存满了内存分配过程">内存满了，内存分配过程<a hidden class="anchor" aria-hidden="true" href="#内存满了内存分配过程">#</a></h3>
<p>应用程序通过 malloc 函数申请内存的时候，实际上申请的是虚拟内存，此时并不会分配物理内存。</p>
<p>当应用程序读写了这块虚拟内存，CPU 就会去访问这个虚拟内存， 这时会发现这个虚拟内存没有映射到物理内存， CPU 就会产生<strong>缺页中断</strong>，进程会从用户态切换到内核态，并将缺页中断交给内核的 Page Fault Handler （缺页中断函数）处理。</p>
<p>如果没有空闲的物理内存，那么内核就会开始进行<strong>回收内存</strong>的工作，回收的方式主要是两种：直接内存回收和后台内存回收。</p>
<ul>
<li><strong>后台内存回收</strong>（kswapd）：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程<strong>异步</strong>的，不会阻塞进程的执行。</li>
<li><strong>直接内存回收</strong>（direct reclaim）：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是<strong>同步</strong>的，会阻塞进程的执行。</li>
</ul>
<p>如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——<strong>触发 OOM （Out of Memory）机制</strong>。</p>
<p>OOM Killer 机制会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。</p>
<p>申请物理内存的过程如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302202131928.png" alt="img"  />
</p>
<h4 id="哪些内存可以被回收">哪些内存可以被回收？<a hidden class="anchor" aria-hidden="true" href="#哪些内存可以被回收">#</a></h4>
<p>主要有两类内存可以被回收，而且它们的回收方式也不同。</p>
<ul>
<li><strong>文件页</strong>（File-backed Page）：内核缓存的磁盘数据（Buffer）和内核缓存的文件数据（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。所以，<strong>回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存</strong>。</li>
<li><strong>匿名页</strong>（Anonymous Page）：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们<strong>回收的方式是通过 Linux 的 Swap 机制</strong>，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。</li>
</ul>
<p>文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。LRU 回收算法，实际上维护着 active 和 inactive 两个双向链表，其中：</p>
<ul>
<li><strong>active_list</strong> 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；</li>
<li><strong>inactive_list</strong> 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；</li>
</ul>
<p>越接近链表尾部，就表示内存页越不常访问。这样，在回收内存时，系统就可以根据活跃程度，优先回收不活跃的内存。</p>
<h4 id="swap-机制">Swap 机制<a hidden class="anchor" aria-hidden="true" href="#swap-机制">#</a></h4>
<p>当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间会被临时保存到磁盘，等到那些程序要运行时，再从磁盘中恢复保存的数据到内存中。</p>
<p>另外，当内存使用存在压力的时候，会开始触发内存回收行为，会把这些不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。</p>
<p>这种，将内存数据换出磁盘，又从磁盘中恢复数据到内存的过程，就是 Swap 机制负责的。</p>
<p>Swap 就是把一块磁盘空间或者本地文件，当成内存来使用，它包含换出和换入两个过程：</p>
<ul>
<li><strong>换出（Swap Out）</strong>：是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存；</li>
<li><strong>换入（Swap In）</strong>：是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来；</li>
</ul>
<p>Swap 换入换出的过程如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302202302209.png" alt="img"  />
</p>
<p>使用 Swap 机制优点是，应用程序实际可以使用的内存空间将远远超过系统的物理内存。由于硬盘空间的价格远比内存要低，因此这种方式无疑是经济实惠的。当然，频繁地读写硬盘，会显著降低操作系统的运行速率，这也是 Swap 的弊端。</p>
<p>Linux 中的 Swap 机制会在内存不足和内存闲置的场景下触发：</p>
<ul>
<li><strong>内存不足</strong>：当系统需要的内存超过了可用的物理内存时，内核会将内存中不常使用的内存页交换到磁盘上为当前进程让出内存，保证正在执行的进程的可用性，这个内存回收的过程是强制的直接内存回收（Direct Page Reclaim）。直接内存回收是同步的过程，会阻塞当前申请内存的进程。</li>
<li><strong>内存闲置</strong>：应用程序在启动阶段使用的大量内存在启动后往往都不会使用，通过后台运行的守护进程（kSwapd），我们可以将这部分只使用一次的内存交换到磁盘上为其他内存的申请预留空间。kSwapd 是 Linux 负责页面置换（Page replacement）的守护进程，它也是负责交换闲置内存的主要进程，它会在内存低于一定水位时，回收内存页中的空闲内存保证系统中的其他进程可以尽快获得申请的内存。kSwapd 是后台进程，所以回收内存的过程是异步的，不会阻塞当前申请内存的进程。</li>
</ul>
<p>Linux 提供了两种不同的方法启用 Swap，分别是 Swap 分区（Swap Partition）和 Swap 文件（Swapfile）：</p>
<ul>
<li>Swap 分区是硬盘上的独立区域，该区域只会用于交换分区，其他的文件不能存储在该区域上，我们可以使用 <code>swapon -s</code> 命令查看当前系统上的交换分区；</li>
<li>Swap 文件是文件系统中的特殊文件，它与文件系统中的其他文件也没有太多的区别；</li>
</ul>
<p><strong>Swap 换入换出的是什么类型的内存？</strong></p>
<p>内核缓存的文件数据，因为都有对应的磁盘文件，所以在回收文件数据的时候， 直接写回到对应的文件就可以了。</p>
<p>但是像进程的堆、栈数据等，它们是没有实际载体，这部分内存被称为匿名页。而且这部分内存很可能还要再次被访问，所以不能直接释放内存，于是就需要有一个能保存匿名页的磁盘载体，这个载体就是 Swap 分区。</p>
<p>匿名页回收的方式是通过 Linux 的 Swap 机制，Swap 会把不常访问的内存先写到磁盘中，然后释放这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。</p>
<h4 id="回收内存带来的性能影响">回收内存带来的性能影响<a hidden class="anchor" aria-hidden="true" href="#回收内存带来的性能影响">#</a></h4>
<p>在前面我们知道了回收内存有两种方式。</p>
<ul>
<li>一种是后台内存回收，也就是唤醒 kswapd 内核线程，这种方式是异步回收的，不会阻塞进程。</li>
<li>一种是直接内存回收，这种方式是同步回收的，会阻塞进程，这样就会造成很长时间的延迟，以及系统的 CPU 利用率会升高，最终引起系统负荷飙高。</li>
</ul>
<p>可被回收的内存类型有文件页和匿名页：</p>
<ul>
<li>文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。</li>
<li>匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。</li>
</ul>
<p>回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能，整个系统给人的感觉就是很卡。</p>
<h4 id="针对回收内存导致的性能影响常见的解决方式">针对回收内存导致的性能影响常见的解决方式<a hidden class="anchor" aria-hidden="true" href="#针对回收内存导致的性能影响常见的解决方式">#</a></h4>
<h5 id="调整文件页和匿名页的回收倾向">调整文件页和匿名页的回收倾向<a hidden class="anchor" aria-hidden="true" href="#调整文件页和匿名页的回收倾向">#</a></h5>
<p>从文件页和匿名页的回收操作来看，文件页的回收操作对系统的影响相比匿名页的回收操作会少一点，因为文件页对于干净页回收是不会发生磁盘 I/O 的，而匿名页的 Swap 换入换出这两个操作都会发生磁盘 I/O。</p>
<p>在回收内存的时候，会更倾向于文件页的回收，可以提升性能，这个有参数在 Linux 里调整。</p>
<h5 id="尽早触发-kswapd-内核线程异步回收内存">尽早触发 kswapd 内核线程异步回收内存<a hidden class="anchor" aria-hidden="true" href="#尽早触发-kswapd-内核线程异步回收内存">#</a></h5>
<p><strong>什么条件下才能触发 kswapd 内核线程回收内存呢？</strong></p>
<p>内核定义了三个内存阈值（watermark，也称为水位），用来衡量当前剩余内存（pages_free）是否充裕或者紧张，分别是：</p>
<ul>
<li>页最小阈值（pages_min）；</li>
<li>页低阈值（pages_low）；</li>
<li>页高阈值（pages_high）；</li>
</ul>
<p>这三个内存阈值会划分为四种内存使用情况，如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302202245327.png" alt="img"  />
</p>
<ul>
<li>图中橙色部分：如果剩余内存（pages_free）在页低阈值（pages_low）和页最小阈值（pages_min）之间，说明内存压力比较大，剩余内存不多了。<strong>这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值（pages_high）为止</strong>。虽然会触发内存回收，但是不会阻塞应用程序，因为两者关系是异步的。</li>
<li>图中红色部分：如果剩余内存（pages_free）小于页最小阈值（pages_min），说明用户可用内存都耗尽了，此时就会<strong>触发直接内存回收</strong>，这时应用程序就会被阻塞，因为两者关系是同步的。</li>
</ul>
<p>也就是说 kswapd 的活动空间只有 pages_low 与 pages_min 之间的这段区域，如果剩余内存低于了 pages_min 会触发直接内存回收，高于了 pages_high 又不会唤醒 kswapd。</p>
<h5 id="如何保护一个进程不被-oom-杀掉">如何保护一个进程不被 OOM 杀掉<a hidden class="anchor" aria-hidden="true" href="#如何保护一个进程不被-oom-杀掉">#</a></h5>
<p>Linux 到底是根据 <code>oom_badness()</code> 得分的结果受下面这两个方面影响：</p>
<ul>
<li>第一，进程已经使用的物理内存页面数。</li>
<li>第二，每个进程的 OOM 校准值 oom_score_adj。它是可以通过 <code>/proc/[pid]/oom_score_adj</code> 来配置的。我们可以在设置 -1000 到 1000 之间的任意一个数值，调整进程被 OOM Kill 的几率。</li>
</ul>
<p>计算方法如下：
$$
得分=进程已经使用的物理内存页面数+\frac{OOM\ 校准值 * 系统总的可用页面数}{1000}
$$
我们可以将一些很重要的系统服务的 oom_score_adj 配置为 -1000，比如 sshd，因为这些系统服务一旦被杀掉，我们就很难再登陆进系统了。但是不建议将我们自己的业务程序的 oom_score_adj 设置为 -1000，因为业务程序一旦发生了内存泄漏，而它又不能被杀掉，这就会导致随着它的内存开销变大，OOM killer 不停地被唤醒，从而把其他进程一个个给杀掉。</p>
<h2 id="进程管理">进程管理<a hidden class="anchor" aria-hidden="true" href="#进程管理">#</a></h2>
<h3 id="进程">进程<a hidden class="anchor" aria-hidden="true" href="#进程">#</a></h3>
<p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个<strong>运行中的程序，就被称为「进程」（Process）</strong>。</p>
<p><strong>在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。</strong></p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181632218.jpg" alt="进程的三种基本状态"  />
</p>
<p>上图中各个状态的意义：</p>
<ul>
<li>运行状态（<em>Running</em>）：该时刻进程占用 CPU；</li>
<li>就绪状态（<em>Ready</em>）：可运行，由于其他进程处于运行状态而暂时停止运行；</li>
<li>阻塞状态（<em>Blocked</em>）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；</li>
</ul>
<p>当然，进程还有另外两个基本状态：</p>
<ul>
<li>创建状态（<em>new</em>）：进程正在被创建时的状态；</li>
<li>结束状态（<em>Exit</em>）：进程正在从系统中消失时的状态；</li>
</ul>
<p>于是，一个完整的进程状态的变迁如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181634677.jpg" alt="进程五种状态的变迁"  />
</p>
<p>再来详细说明一下进程的状态变迁：</p>
<ul>
<li><em>NULL -&gt; 创建状态</em>：一个新进程被创建时的第一个状态；</li>
<li><em>创建状态 -&gt; 就绪状态</em>：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；</li>
<li><em>就绪态 -&gt; 运行状态</em>：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；</li>
<li><em>运行状态 -&gt; 结束状态</em>：当进程已经运行完成或出错时，会被操作系统作结束状态处理；</li>
<li><em>运行状态 -&gt; 就绪状态</em>：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；</li>
<li><em>运行状态 -&gt; 阻塞状态</em>：当进程请求某个事件且必须等待时，例如请求 I/O 事件；</li>
<li><em>阻塞状态 -&gt; 就绪状态</em>：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；</li>
</ul>
<p>为了防止阻塞中的进程一直占用物理内存空间，在虚拟内存管理的操作系统中通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。那么，就需要一个新的状态，来<strong>描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态</strong>。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。</p>
<p>挂起状态可以分为两种：</p>
<ul>
<li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li>
<li>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302181638265.jpg" alt="七种状态变迁"  />
</p>
<p>导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p>
<ul>
<li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>
<li>用户希望挂起一个程序的执行，比如在 Linux 中用 <code>Ctrl+Z</code> 挂起进程；</li>
</ul>
<h4 id="进程的控制结构">进程的控制结构<a hidden class="anchor" aria-hidden="true" href="#进程的控制结构">#</a></h4>
<p>在操作系统中，是用<strong>进程控制块</strong>（<em>process control block，PCB</em>）数据结构来描述进程的。<strong>PCB 是进程存在的唯一标识</strong>，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p>
<p><strong>PCB 具体包含什么信息呢？</strong></p>
<p><strong>进程描述信息：</strong></p>
<ul>
<li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li>
<li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li>
</ul>
<p><strong>进程控制和管理信息：</strong></p>
<ul>
<li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li>
<li>进程优先级：进程抢占 CPU 时的优先级；</li>
</ul>
<p><strong>资源分配清单：</strong></p>
<ul>
<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。</li>
</ul>
<p><strong>CPU 相关信息：</strong></p>
<ul>
<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>
</ul>
<p>每个 PCB 通常是通过<strong>链表</strong>的方式进行组织（也有索引方式），把具有<strong>相同状态的进程链在一起，组成各种队列</strong>。比如：</p>
<ul>
<li>将所有处于就绪状态的进程链在一起，称为<strong>就绪队列</strong>；</li>
<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种<strong>阻塞队列</strong>；</li>
<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>
</ul>
<h4 id="进程的控制">进程的控制<a hidden class="anchor" aria-hidden="true" href="#进程的控制">#</a></h4>
<p><strong>01 创建进程</strong></p>
<p>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。</p>
<p>创建进程的过程如下：</p>
<ul>
<li>申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；</li>
<li>为该进程分配运行时所必需的资源，比如内存资源；</li>
<li>将 PCB 插入到就绪队列，等待被调度运行；</li>
</ul>
<p><strong>02 终止进程</strong></p>
<p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 <code>kill</code> 掉）。</p>
<p>当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。</p>
<p>终止进程的过程如下：</p>
<ul>
<li>查找需要终止的进程的 PCB；</li>
<li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li>
<li>如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；</li>
<li>将该进程所拥有的全部资源都归还给操作系统；</li>
<li>将其从 PCB 所在队列中删除；</li>
</ul>
<p><strong>03 阻塞进程</strong></p>
<p>当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。</p>
<p>阻塞进程的过程如下：</p>
<ul>
<li>找到将要被阻塞进程标识号对应的 PCB；</li>
<li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li>
<li>将该 PCB 插入到阻塞队列中去；</li>
</ul>
<p><strong>04 唤醒进程</strong></p>
<p>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。</p>
<p>如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。</p>
<p>唤醒进程的过程如下：</p>
<ul>
<li>在该事件的阻塞队列中找到相应进程的 PCB；</li>
<li>将其从阻塞队列中移出，并置其状态为就绪状态；</li>
<li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li>
</ul>
<p>进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。</p>
<h4 id="进程的上下文切换">进程的上下文切换<a hidden class="anchor" aria-hidden="true" href="#进程的上下文切换">#</a></h4>
<p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个<strong>一个进程切换到另一个进程运行，称为进程的上下文切换</strong>。</p>
<p>进程是由内核管理和调度的，所以进程的切换只能发生在<strong>内核态</strong>。</p>
<p>所以，<strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</strong></p>
<p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行。</p>
<h3 id="线程">线程<a hidden class="anchor" aria-hidden="true" href="#线程">#</a></h3>
<p><strong>线程是进程当中的一条执行流程</strong>，线程之间可以并发运行且共享相同的地址空间。</p>
<p>同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p>
<p><strong>线程的优缺点？</strong></p>
<p>线程的优点：</p>
<ul>
<li>一个进程中可以同时存在多个线程；</li>
<li>各个线程之间可以并发执行；</li>
<li>各个线程之间可以共享地址空间和文件等资源；</li>
</ul>
<p>线程的缺点：</p>
<ul>
<li>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃，具体分析原因可以看这篇：<a href="https://xiaolincoding.com/os/4_process/thread_crash.html">线程崩溃了，进程也会崩溃吗？ (opens new window)</a>）。</li>
</ul>
<h4 id="线程的上下文切换">线程的上下文切换<a hidden class="anchor" aria-hidden="true" href="#线程的上下文切换">#</a></h4>
<p>在前面我们知道了，线程与进程最大的区别在于：<strong>线程是调度的基本单位，而进程则是资源拥有的基本单位</strong>。</p>
<p>所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。</p>
<p>对于线程和进程，我们可以这么理解：</p>
<ul>
<li>当进程只有一个线程时，可以认为进程就等于线程；</li>
<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；</li>
</ul>
<p>另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。</p>
<p><strong>线程上下文切换的是什么？</strong></p>
<p>这还得看线程是不是属于同一个进程：</p>
<ul>
<li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；</li>
<li><strong>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据</strong>；</li>
</ul>
<p>所以，线程的上下文切换相比进程，开销要小很多。</p>
<h4 id="线程的实现">线程的实现<a hidden class="anchor" aria-hidden="true" href="#线程的实现">#</a></h4>
<p>主要有三种线程的实现方式：</p>
<ul>
<li><strong>用户线程（<em>User Thread</em>）</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理</li>
<li><strong>内核线程（<em>Kernel Thread</em>）</strong>：在内核中实现的线程，是由内核管理的线程</li>
<li><strong>轻量级进程（<em>LightWeight Process</em>）</strong>：在内核中来支持用户线程</li>
</ul>
<h5 id="用户线程">用户线程<a hidden class="anchor" aria-hidden="true" href="#用户线程">#</a></h5>
<p>用户线程是基于用户态的线程管理库来实现的，那么<strong>线程控制块（<em>Thread Control Block, TCB</em>）</strong> 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。</p>
<p>所以，<strong>用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。</strong></p>
<p><strong>优点</strong>：</p>
<ul>
<li>TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li>
<li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</li>
<li>当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</li>
<li>由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢。</li>
</ul>
<h5 id="内核线程">内核线程<a hidden class="anchor" aria-hidden="true" href="#内核线程">#</a></h5>
<p><strong>内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。</strong></p>
<p><strong>优点</strong>：</p>
<ul>
<li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li>
<li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li>
<li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大。</li>
</ul>
<h5 id="轻量级进程">轻量级进程<a hidden class="anchor" aria-hidden="true" href="#轻量级进程">#</a></h5>
<p><strong>轻量级进程（<em>Light-weight process，LWP</em>）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度</strong>。</p>
<h3 id="线程与进程的比较">线程与进程的比较<a hidden class="anchor" aria-hidden="true" href="#线程与进程的比较">#</a></h3>
<p>线程与进程的比较如下：</p>
<ul>
<li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>对于，线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
<p>所以，不管是时间效率，还是空间效率线程比进程都要高。</p>
<h3 id="调度">调度<a hidden class="anchor" aria-hidden="true" href="#调度">#</a></h3>
<p>选择一个进程运行这一功能是在操作系统中完成的，通常称为<strong>调度程序</strong>（<em>scheduler</em>）。</p>
<h4 id="调度时机">调度时机<a hidden class="anchor" aria-hidden="true" href="#调度时机">#</a></h4>
<p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p>
<p>比如，以下状态的变化都会触发操作系统的调度：</p>
<ul>
<li><em>从就绪态 -&gt; 运行态</em>：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li>
<li><em>从运行态 -&gt; 阻塞态</em>：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行；</li>
<li><em>从运行态 -&gt; 结束态</em>：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；</li>
</ul>
<p>因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。</p>
<p>另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p>
<ul>
<li><strong>非抢占式调度算法</strong>挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li>
<li><strong>抢占式调度算法</strong>挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生<strong>时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片机制</strong>。</li>
</ul>
<h4 id="调度原则">调度原则<a hidden class="anchor" aria-hidden="true" href="#调度原则">#</a></h4>
<p><em>原则一</em>：如果运行的程序，发生了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，<strong>为了提高 CPU 利用率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。</strong></p>
<p><em>原则二</em>：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，<strong>要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。</strong></p>
<p><em>原则三</em>：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，<strong>如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。</strong></p>
<p><em>原则四</em>：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，<strong>就绪队列中进程的等待时间也是调度程序所需要考虑的原则。</strong></p>
<p><em>原则五</em>：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，<strong>对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。</strong></p>
<p>针对上面的五种调度原则，总结成如下：</p>
<ul>
<li><strong>CPU 利用率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>
<li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li><strong>周转时间</strong>：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>
<li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li>
<li><strong>响应时间</strong>：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ul>
<h4 id="调度算法">调度算法<a hidden class="anchor" aria-hidden="true" href="#调度算法">#</a></h4>
<h5 id="单核-cpu-系统中常见的调度算法">单核 CPU 系统中常见的调度算法<a hidden class="anchor" aria-hidden="true" href="#单核-cpu-系统中常见的调度算法">#</a></h5>
<p><strong>01 先来先服务调度算法</strong></p>
<p>非抢占式的<strong>先来先服务（<em>First Come First Serve, FCFS</em>）算法</strong></p>
<p><strong>每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</strong></p>
<p><strong>02 最短作业优先调度算法</strong></p>
<p><strong>最短作业优先（<em>Shortest Job First, SJF</em>）调度算法</strong>同样也是顾名思义，它会<strong>优先选择运行时间最短的进程来运行</strong>，这有助于提高系统的吞吐量。</p>
<p><strong>03 高响应比优先调度算法</strong></p>
<p><strong>高响应比优先 （<em>Highest Response Ratio Next, HRRN</em>）调度算法</strong>主要是权衡了短作业和长作业。</p>
<p><strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行</strong>，「响应比优先级」的计算公式：
$$
优先权 = \frac{等待时间\ +\ 要求服务时间}{要求服务时间}
$$
从上面的公式，可以发现：</p>
<ul>
<li>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；</li>
<li>如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；</li>
</ul>
<p>因为进程要求服务时间不可预知，所以高响应比优先调度算法是实现不了的。</p>
<p><strong>04 时间片轮转调度算法</strong></p>
<p><strong>每个进程被分配一个时间段，称为时间片（<em>Quantum</em>），即允许该进程在该时间段中运行。</strong></p>
<ul>
<li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li>
<li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li>
</ul>
<p>另外，时间片的长度就是一个很关键的点：</p>
<ul>
<li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li>
<li>如果设得太长又可能引起对短作业进程的响应时间变长。</li>
</ul>
<p>一般来说，时间片设为 <code>20ms~50ms</code> 通常是一个比较合理的折中值。</p>
<p>最为公平、使用最为广泛。</p>
<p><strong>05 最高优先级调度算法</strong></p>
<p><strong>从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（<em>Highest Priority First，HPF</em>）调度算法</strong></p>
<p>进程的优先级可以分为，静态优先级和动态优先级：</p>
<ul>
<li>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li>
<li>动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是<strong>随着时间的推移增加等待进程的优先级</strong>。</li>
</ul>
<p>该算法也有两种处理优先级高的方法，非抢占式和抢占式：</p>
<ul>
<li>非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。</li>
<li>抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。</li>
</ul>
<p>但是依然有缺点，可能会导致低优先级的进程永远不会运行。</p>
<p><strong>06 多级反馈队列调度算法</strong></p>
<p><strong>多级反馈队列（<em>Multilevel Feedback Queue</em>）调度算法</strong>是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>
<ul>
<li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li>
<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；</li>
</ul>
<p>如何工作的：</p>
<ul>
<li>设置了多个队列，赋予每个队列不同的优先级，每个<strong>队列优先级从高到低</strong>，同时<strong>优先级越高时间片越短</strong>；</li>
<li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li>
<li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li>
</ul>
<p>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的<strong>兼顾了长短作业，同时有较好的响应时间。</strong></p>
<h3 id="进程之间的通信方式">进程之间的通信方式<a hidden class="anchor" aria-hidden="true" href="#进程之间的通信方式">#</a></h3>
<h4 id="管道">管道<a hidden class="anchor" aria-hidden="true" href="#管道">#</a></h4>
<p>遵循<strong>先进先出</strong>原则，不支持 lseek 之类的文件定位操作。</p>
<p><strong>匿名管道</strong>：<strong>它的通信范围是存在父子关系的进程</strong>。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。</p>
<p><strong>命名管道</strong>：<strong>它可以在不相关的进程间也能相互通信</strong>。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。</p>
<p>不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核中。**管道这种通信方式效率低，不适合进程间频繁地交换数据。</p>
<h4 id="消息队列">消息队列<a hidden class="anchor" aria-hidden="true" href="#消息队列">#</a></h4>
<p><strong>消息队列是保存在内核中的消息链表</strong>，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</p>
<p><strong>消息队列不适合比较大数据的传输</strong>，<strong>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</strong>。</p>
<h4 id="共享内存">共享内存<a hidden class="anchor" aria-hidden="true" href="#共享内存">#</a></h4>
<p><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。</p>
<h4 id="信号量">信号量<a hidden class="anchor" aria-hidden="true" href="#信号量">#</a></h4>
<p><strong>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong>。</p>
<h4 id="信号">信号<a hidden class="anchor" aria-hidden="true" href="#信号">#</a></h4>
<p><strong>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</strong></p>
<p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p>
<p><strong>1.执行默认操作</strong>。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p>
<p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p>
<p><strong>3.忽略信号</strong>。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。</p>
<p>有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p>
<h4 id="socket">Socket<a hidden class="anchor" aria-hidden="true" href="#socket">#</a></h4>
<p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></p>
<p>本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是<strong>绑定一个本地文件</strong>，这也就是它们之间的最大区别。</p>
<h4 id="总结-2">总结<a hidden class="anchor" aria-hidden="true" href="#总结-2">#</a></h4>
<p>由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。</p>
<p>Linux 内核提供了不少进程间通信的方式，其中最简单的方式就是管道，管道分为「匿名管道」和「命名管道」。</p>
<p><strong>匿名管道</strong>顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「<code>|</code>」竖线就是匿名管道，通信的数据是<strong>无格式的流并且大小受限</strong>，通信的方式是<strong>单向</strong>的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来<strong>匿名管道是只能用于存在父子关系的进程间通信</strong>，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。</p>
<p><strong>命名管道</strong>突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是<strong>缓存在内核</strong>中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循<strong>先进先出</strong>原则，不支持 lseek 之类的文件定位操作。</p>
<p><strong>消息队列</strong>克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟<strong>每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。</strong></p>
<p><strong>共享内存</strong>可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，<strong>它直接分配一个共享空间，每个进程都可以直接访问</strong>，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有<strong>最快</strong>的进程间通信方式之名。但是便捷高效的共享内存通信，<strong>带来新的问题，多进程竞争同个共享资源会造成数据的错乱。</strong></p>
<p>那么，就需要<strong>信号量</strong>来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。<strong>信号量不仅可以实现访问的互斥性，还可以实现进程间的同步</strong>，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 <strong>P 操作和 V 操作</strong>。</p>
<p>与信号量名字很相似的叫<strong>信号</strong>，它俩名字虽然相似，但功能一点儿都不一样。信号是<strong>异步通信机制</strong>，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，<strong>进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号</strong>。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SIGSTOP</code>，这是为了方便我们能在任何时候结束或停止某个进程。</p>
<p>前面说到的通信机制，都是工作于同一台主机，如果<strong>要与不同主机的进程间通信，那么就需要 Socket 通信了</strong>。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。</p>
<p>以上，就是进程间通信的主要机制了。你可能会问了，那线程通信间的方式呢？</p>
<p>同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：</p>
<ul>
<li>互斥的方式，可保证任意时刻只有一个线程访问共享资源；</li>
<li>同步的方式，可保证线程 A 应在线程 B 之前执行；</li>
</ul>
<h3 id="互斥和同步">互斥和同步<a hidden class="anchor" aria-hidden="true" href="#互斥和同步">#</a></h3>
<p>当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，称为<strong>竞争条件（<em>race condition</em>）</strong>。</p>
<p>由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为<strong>临界区（<em>critical section</em>），它是访问共享资源的代码片段，一定不能给多线程同时执行。</strong></p>
<h4 id="互斥的概念">互斥的概念<a hidden class="anchor" aria-hidden="true" href="#互斥的概念">#</a></h4>
<p><strong>互斥（<em>mutualexclusion</em>），就是保证一个线程在临界区执行时，其他线程应该被阻止进入临界区</strong>。</p>
<p>另外，互斥也并不是只针对多线程。在多进程竞争共享资源的时候，也同样是可以使用互斥的方式来避免资源竞争造成的资源混乱。</p>
<h4 id="同步的概念">同步的概念<a hidden class="anchor" aria-hidden="true" href="#同步的概念">#</a></h4>
<p><strong>同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302191058347.jpg" alt="吃饭与做菜的同步关系"  />
</p>
<p>注意，同步与互斥是两种不同的概念：</p>
<ul>
<li>同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；</li>
<li>互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」；</li>
</ul>
<h4 id="互斥与同步的实现和使用">互斥与同步的实现和使用<a hidden class="anchor" aria-hidden="true" href="#互斥与同步的实现和使用">#</a></h4>
<p>为了实现进程/线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p>
<ul>
<li><em>锁</em>：加锁、解锁操作；</li>
<li><em>信号量</em>：P、V 操作；</li>
</ul>
<p>这两个都可以方便地实现进程/线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程/线程同步。</p>
<h5 id="忙等待锁">忙等待锁<a hidden class="anchor" aria-hidden="true" href="#忙等待锁">#</a></h5>
<p>先介绍现代 CPU 体系结构提供的特殊<strong>原子操作指令 —— 测试和置位（<em>Test-and-Set</em>）指令</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302191107242.jpg" alt="img"  />
</p>
<p>测试并设置指令做了下述事情:</p>
<ul>
<li>把 <code>old_ptr</code> 更新为 <code>new</code> 的新值</li>
<li>返回 <code>old_ptr</code> 的旧值；</li>
</ul>
<p><strong>关键是这些代码是原子执行</strong>。</p>
<p>我们可以运用 Test-and-Set 指令来实现「忙等待锁」，代码如下：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302191107346.jpg" alt="img"  />
</p>
<p>我们来确保理解为什么这个锁能工作：</p>
<ul>
<li>第一个场景是，首先假设一个线程在运行，调用 <code>lock()</code>，没有其他线程持有锁，所以 <code>flag</code> 是 0。当调用 <code>TestAndSet(flag, 1)</code> 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 <code>unlock()</code> 将 <code>flag</code> 清理为 0。</li>
<li>第二种场景是，当某一个线程已经持有锁（即 <code>flag</code> 为1）。本线程调用 <code>lock()</code>，然后调用 <code>TestAndSet(flag, 1)</code>，这一次返回 1。只要另一个线程一直持有锁，<code>TestAndSet()</code> 会重复返回 1，本线程会一直<strong>忙等</strong>。当 <code>flag</code> 终于被改为 0，本线程会调用 <code>TestAndSet()</code>，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。</li>
</ul>
<p>很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为<strong>自旋锁（<em>spin lock</em>）</strong>。</p>
<h5 id="无等待锁">无等待锁<a hidden class="anchor" aria-hidden="true" href="#无等待锁">#</a></h5>
<p><strong>无等待锁</strong>把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302191109442.jpg" alt="img"  />
</p>
<h5 id="信号量-1">信号量<a hidden class="anchor" aria-hidden="true" href="#信号量-1">#</a></h5>
<p>信号量是操作系统提供的一种协调共享资源访问的方法。</p>
<p>通常<strong>信号量表示资源的数量</strong>，对应的变量是一个整型（<code>sem</code>）变量。</p>
<p>另外，还有<strong>两个原子操作的系统调用函数来控制信号量的</strong>，分别是：</p>
<ul>
<li><em>P 操作</em>：将 <code>sem</code> 减 <code>1</code>，相减后，如果 <code>sem &lt; 0</code>，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；</li>
<li><em>V 操作</em>：将 <code>sem</code> 加 <code>1</code>，相加后，如果 <code>sem &lt;= 0</code>，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；</li>
</ul>
<p>P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。</p>
<h4 id="生产者-消费者问题">生产者-消费者问题<a hidden class="anchor" aria-hidden="true" href="#生产者-消费者问题">#</a></h4>
<p>生产者-消费者问题描述：</p>
<ul>
<li><strong>生产者</strong>在生成数据后，放在一个缓冲区中；</li>
<li><strong>消费者</strong>从缓冲区取出数据处理；</li>
<li>任何时刻，<strong>只能有一个</strong>生产者或消费者可以访问缓冲区；</li>
</ul>
<p>那么我们需要三个信号量，分别是：</p>
<ul>
<li>互斥信号量 <code>mutex</code>：用于互斥访问缓冲区，初始化值为 1；</li>
<li>资源信号量 <code>fullBuffers</code>：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；</li>
<li>资源信号量 <code>emptyBuffers</code>：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302191257260.jpg" alt="img"  />
</p>
<p>如果消费者线程一开始执行 <code>P(fullBuffers)</code>，由于信号量 <code>fullBuffers</code> 初始值为 0，则此时 <code>fullBuffers</code> 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。</p>
<p>接着，轮到生产者执行 <code>P(emptyBuffers)</code>，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 <code>V(fullBuffers)</code> ，信号量 <code>fullBuffers</code> 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。</p>
<p>消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。</p>
<h3 id="死锁">死锁<a hidden class="anchor" aria-hidden="true" href="#死锁">#</a></h3>
<p><strong>死锁：两个线程都在等待对方释放锁</strong></p>
<p>死锁只有<strong>同时满足</strong>以下四个条件才会发生：</p>
<ul>
<li>互斥条件：多个线程不能同时使用同一个资源</li>
<li>持有并等待条件：线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1</li>
<li>不可剥夺条件：当线程已经持有了资源 ，<strong>在自己使用完之前不能被其他线程获取</strong></li>
<li>环路等待条件：<strong>两个线程获取资源的顺序构成了环形链</strong></li>
</ul>
<h4 id="避免死锁问题的发生">避免死锁问题的发生<a hidden class="anchor" aria-hidden="true" href="#避免死锁问题的发生">#</a></h4>
<p><strong>使用资源有序分配法，来破环环路等待条件</strong>。</p>
<h3 id="常见的锁">常见的锁<a hidden class="anchor" aria-hidden="true" href="#常见的锁">#</a></h3>
<p>最底层的两种就是「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基。简单来说，遇到加锁失败，互斥锁会切走，自旋锁会再等等。</p>
<h4 id="互斥锁">互斥锁<a hidden class="anchor" aria-hidden="true" href="#互斥锁">#</a></h4>
<p><strong>互斥锁</strong>加锁失败后，线程会<strong>释放 CPU</strong> ，给其他线程；<strong>对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong>。</p>
<h4 id="自旋锁">自旋锁<a hidden class="anchor" aria-hidden="true" href="#自旋锁">#</a></h4>
<p><strong>自旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁；自旋锁是通过 CPU 提供的 <code>CAS</code> 函数（<em>Compare And Swap</em>），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换。</p>
<p><strong>需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</strong></p>
<h4 id="读写锁">读写锁<a hidden class="anchor" aria-hidden="true" href="#读写锁">#</a></h4>
<p>读写锁由「读锁」和「写锁」两部分构成，其工作原理是：</p>
<ul>
<li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li>
<li>但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。</li>
</ul>
<p><strong>读写锁在读多写少的场景，能发挥出优势</strong>。</p>
<h4 id="悲观锁">悲观锁<a hidden class="anchor" aria-hidden="true" href="#悲观锁">#</a></h4>
<p><strong>多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁</strong>。</p>
<h4 id="乐观锁">乐观锁<a hidden class="anchor" aria-hidden="true" href="#乐观锁">#</a></h4>
<p><strong>乐观锁全程并没有加锁，所以它也叫无锁编程</strong>。</p>
<h2 id="调度算法-1">调度算法<a hidden class="anchor" aria-hidden="true" href="#调度算法-1">#</a></h2>
<h3 id="进程调度算法">进程调度算法<a hidden class="anchor" aria-hidden="true" href="#进程调度算法">#</a></h3>
<p>当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。</p>
<p>什么时候会发生 CPU 调度呢？通常有以下情况：</p>
<ol>
<li>当进程从运行状态转到等待状态；</li>
<li>当进程从运行状态转到就绪状态；</li>
<li>当进程从等待状态转到就绪状态；</li>
<li>当进程从运行状态转到终止状态；</li>
</ol>
<p>其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。</p>
<p>非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。</p>
<p>抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。</p>
<p>第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。</p>
<p>第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。</p>
<p>进程调度算法前面已经学习过了，这边简单再重复一遍。</p>
<h4 id="先来先服务调度算法">先来先服务调度算法<a hidden class="anchor" aria-hidden="true" href="#先来先服务调度算法">#</a></h4>
<p>非抢占式的<strong>先来先服务（<em>First Come First Severd, FCFS</em>）算法</strong>：<strong>每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</strong></p>
<h4 id="最短作业优先调度算法">最短作业优先调度算法<a hidden class="anchor" aria-hidden="true" href="#最短作业优先调度算法">#</a></h4>
<p><strong>最短作业优先（*Shortest Job First, SJF*）调度算法</strong>同样也是顾名思义，它会<strong>优先选择运行时间最短的进程来运行</strong>。</p>
<h4 id="高响应比优先调度算法">高响应比优先调度算法<a hidden class="anchor" aria-hidden="true" href="#高响应比优先调度算法">#</a></h4>
<p><strong>高响应比优先 （<em>Highest Response Ratio Next, HRRN</em>）调度算法</strong>：<strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行</strong>
$$
优先权=\frac{等待时间\ +\ 要求服务时间}{要求服务时间}
$$
因为不知道要求服务时间大概为多少，所以是比较理想的调度算法。</p>
<h4 id="时间片轮转调度算法">时间片轮转调度算法<a hidden class="anchor" aria-hidden="true" href="#时间片轮转调度算法">#</a></h4>
<p><strong>时间片轮转（<em>Round Robin, RR</em>）调度算法</strong>：<strong>每个进程被分配一个时间段，称为时间片（<em>Quantum</em>），即允许该进程在该时间段中运行。</strong></p>
<h4 id="最高优先级调度算法">最高优先级调度算法<a hidden class="anchor" aria-hidden="true" href="#最高优先级调度算法">#</a></h4>
<p><strong>最高优先级（<em>Highest Priority First，HPF</em>）调度算法</strong>：<strong>从就绪队列中选择最高优先级的进程进行运行</strong>。</p>
<h4 id="多级反馈队列调度算法">多级反馈队列调度算法<a hidden class="anchor" aria-hidden="true" href="#多级反馈队列调度算法">#</a></h4>
<p><strong>多级反馈队列（<em>Multilevel Feedback Queue</em>）调度算法</strong>是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>
<ul>
<li>算法设置了多个队列，赋予每个队列不同的优先级，每个<strong>队列优先级从高到低</strong>，同时<strong>优先级越高时间片越短</strong>；</li>
<li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li>
<li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li>
</ul>
<h3 id="内存页面置换算法">内存页面置换算法<a hidden class="anchor" aria-hidden="true" href="#内存页面置换算法">#</a></h3>
<p><strong>缺页异常（缺页中断）</strong>：当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。</p>
<p>它与一般中断的主要区别在于：</p>
<ul>
<li>缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。</li>
<li>缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。</li>
</ul>
<p>缺页中断的处理流程如下图：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302201656168.png" alt="缺页中断的处理流程"  />
</p>
<p>第 4 步中如果找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。</p>
<p>页表项通常有如下图的字段：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302201702204.png" alt="img"  />
</p>
<ul>
<li><em>状态位</em>：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。</li>
<li><em>访问字段</em>：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。</li>
<li><em>修改位</em>：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。</li>
<li><em>硬盘地址</em>：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。</li>
</ul>
<p>虚拟内存的管理整个流程：</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302201700817.png" alt="虚拟内存的流程"  />
</p>
<p>页面置换算法的功能是，<strong>当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面</strong>，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。</p>
<p>页面置换算法有如下几种：</p>
<h4 id="最佳页面置换算法">最佳页面置换算法<a hidden class="anchor" aria-hidden="true" href="#最佳页面置换算法">#</a></h4>
<p><strong>最佳页面置换算法</strong>基本思路是<strong>置换在「未来」最长时间不访问的页面</strong>。</p>
<p>这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。</p>
<p>最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。</p>
<h4 id="先进先出置换算法">先进先出置换算法<a hidden class="anchor" aria-hidden="true" href="#先进先出置换算法">#</a></h4>
<p><strong>先进先出置换</strong>基本思路是<strong>选择在内存驻留时间很长的页面进行中置换</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302201708739.png" alt="先进先出置换算法"  />
</p>
<h4 id="最近最久未使用的置换算法">最近最久未使用的置换算法<a hidden class="anchor" aria-hidden="true" href="#最近最久未使用的置换算法">#</a></h4>
<p>最近最久未使用（<em>LRU</em>）的置换算法的基本思路是，发生缺页时，<strong>选择最长时间没有被访问的页面进行置换</strong>，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。</p>
<p>效果虽好，但是要维护所有页面的链表，开销比较大。</p>
<h4 id="时钟页面置换算法">时钟页面置换算法<a hidden class="anchor" aria-hidden="true" href="#时钟页面置换算法">#</a></h4>
<p>时钟页面置换算法跟 LRU 近似，又是对 FIFO 的一种改进。算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。</p>
<p>当发生缺页中断时，算法首先检查表针指向的页面：</p>
<ul>
<li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li>
<li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302201716750.png" alt="时钟页面置换算法"  />
</p>
<h4 id="最不常用算法">最不常用算法<a hidden class="anchor" aria-hidden="true" href="#最不常用算法">#</a></h4>
<p><strong>最不常用（<em>LFU</em>）算法</strong>：<strong>当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰</strong>。</p>
<h3 id="磁盘调度算法">磁盘调度算法<a hidden class="anchor" aria-hidden="true" href="#磁盘调度算法">#</a></h3>
<p>磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。</p>
<h4 id="先来先服务算法">先来先服务算法<a hidden class="anchor" aria-hidden="true" href="#先来先服务算法">#</a></h4>
<p>先来先服务（<em>First-Come，First-Served，FCFS</em>），顾名思义，先到来的请求，先被服务。</p>
<h4 id="最短寻道时间">最短寻道时间<a hidden class="anchor" aria-hidden="true" href="#最短寻道时间">#</a></h4>
<p>最短寻道时间优先（<em>Shortest Seek First，SSF</em>）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求。</p>
<p>但这个算法可能存在某些请求的<strong>饥饿</strong>，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里<strong>产生饥饿的原因是磁头在一小块区域来回移动</strong>。</p>
<h4 id="扫描算法">扫描算法<a hidden class="anchor" aria-hidden="true" href="#扫描算法">#</a></h4>
<p><strong>扫描（<em>Scan</em>）算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。</strong></p>
<p>扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。</p>
<h4 id="循环扫描算法">循环扫描算法<a hidden class="anchor" aria-hidden="true" href="#循环扫描算法">#</a></h4>
<p><strong>循环扫描（<em>Circular Scan, CSCAN</em> ）规定</strong>：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且<strong>返回中途不处理任何请求</strong>，该算法的特点，就是<strong>磁道只响应一个方向上的请求</strong>。</p>
<p>循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。</p>
<h4 id="look-与-c-look算法">LOOK 与 C-LOOK算法<a hidden class="anchor" aria-hidden="true" href="#look-与-c-look算法">#</a></h4>
<p><strong>LOOK 算法</strong>：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中会响应请求</strong>。</p>
<p><strong>C-LOOK算法</strong>：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，<strong>反向移动的途中不会响应请求</strong>。</p>
<h2 id="网络系统">网络系统<a hidden class="anchor" aria-hidden="true" href="#网络系统">#</a></h2>
<h3 id="零拷贝">零拷贝<a hidden class="anchor" aria-hidden="true" href="#零拷贝">#</a></h3>
<h4 id="dma-技术">DMA 技术<a hidden class="anchor" aria-hidden="true" href="#dma-技术">#</a></h4>
<p>没有 DMA 技术前，I/O 的过程是这样的：</p>
<ul>
<li>CPU 发出对应的指令给磁盘控制器，然后返回；</li>
<li>磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个<strong>中断</strong>；</li>
<li>CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。</li>
</ul>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302241632596.png" alt="img"  />
</p>
<p>可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。</p>
<p><strong>DMA 技术</strong>简单理解就是，<strong>在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong>。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302241634203.png" alt="img"  />
</p>
<p>具体过程：</p>
<ul>
<li>用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li>
<li>操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；</li>
<li>DMA 进一步将 I/O 请求发送给磁盘；</li>
<li>磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；</li>
<li><strong>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务</strong>；</li>
<li>当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；</li>
<li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；</li>
</ul>
<p>可以看到， <strong>CPU 不再参与「将数据从磁盘控制器缓冲区搬运到内核空间」的工作，这部分工作全程由 DMA 完成</strong>。但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。</p>
<h4 id="传统的文件传输">传统的文件传输<a hidden class="anchor" aria-hidden="true" href="#传统的文件传输">#</a></h4>
<p>如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。</p>
<p>传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/perhapzz/ImageBed/main/blog-images/202302241727648.png" alt="img"  />
</p>
<p>首先，期间共<strong>发生了 4 次用户态与内核态的上下文切换</strong>，因为发生了两次系统调用，一次是 <code>read()</code> ，一次是 <code>write()</code>，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p>
<p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。</p>
<p>其次，还<strong>发生了 4 次数据拷贝</strong>，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p>
<ul>
<li><em>第一次拷贝</em>，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li>
<li><em>第二次拷贝</em>，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。</li>
<li><em>第三次拷贝</em>，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。</li>
<li><em>第四次拷贝</em>，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li>
</ul>
<p><strong>要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数</strong>。</p>
<h3 id="io-多路复用">I/O 多路复用<a hidden class="anchor" aria-hidden="true" href="#io-多路复用">#</a></h3>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://perhapzz.github.io/tags/basics/">basics</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://perhapzz.github.io">perhapzz</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
